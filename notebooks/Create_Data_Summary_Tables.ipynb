{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "351af9ba",
   "metadata": {},
   "source": [
    "# Recreate data summary tables from gao et al paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b55418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dr = os.path.split(os.getcwd())[0]\n",
    "if parent_dr not in sys.path:\n",
    "    sys.path.append(parent_dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a87487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabulate\n",
    "from core.data.gao_data import *\n",
    "from core.data.util import get_classification_data_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378d79c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: ../resources/metaphor-in-context/data\n"
     ]
    }
   ],
   "source": [
    "# gao et all data directory\n",
    "data_dir = os.path.join(\"..\",\"resources\", \"metaphor-in-context\", \"data\")\n",
    "print(f\"Data directory: {data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a4865a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_container = ExperimentData(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17fa901a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOH formatted nrow: 1603\n",
      "MOH train nrow: 1283\n",
      "MOH test nrow: 160\n",
      "MOH val nrow: 160\n",
      "MOH-X formatted svo nrow: 647\n",
      "MOH-X formatted svo cleaned nrow: 647\n",
      "TroFi formatted_all3737 nrow: 3737\n",
      "TroFi-X formatted svo nrow: 1444\n",
      "VUA formatted nrow: 23113\n",
      "VUA train nrow: 15516\n",
      "VUA train augmented nrow: 116622\n",
      "VUA train no val nrow: 12541\n",
      "VUA test nrow: 5873\n",
      "VUA val nrow: 1724\n",
      "VUA_seq train nrow: 6323\n",
      "VUA_seq test nrow: 2694\n",
      "VUA_seq val nrow: 1550\n"
     ]
    }
   ],
   "source": [
    "data_container.read_all_data(to_pandas=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e12a4",
   "metadata": {},
   "source": [
    "## CLASSIFICATION\n",
    "### Datasets to summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "913c2f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_data = {\n",
    "    MOH_X: data_container.moh_x_formatted_svo_cleaned,\n",
    "    MOH: data_container.moh_formatted,\n",
    "    TROFI_X: data_container.trofi_x_formatted_svo,\n",
    "    TROFI: data_container.trofi_formatted_all,\n",
    "    VUA: data_container.vua_formatted}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "509b0bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>Perc Metaphor</th>\n",
       "      <th>Uniq Verb</th>\n",
       "      <th>Avg Sentence Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MOH-X</td>\n",
       "      <td>647</td>\n",
       "      <td>0.486862</td>\n",
       "      <td>214</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MOH</td>\n",
       "      <td>1603</td>\n",
       "      <td>0.248908</td>\n",
       "      <td>436</td>\n",
       "      <td>7.426076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TroFi-X</td>\n",
       "      <td>1444</td>\n",
       "      <td>0.416205</td>\n",
       "      <td>857</td>\n",
       "      <td>29.346953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TroFi</td>\n",
       "      <td>3737</td>\n",
       "      <td>0.435376</td>\n",
       "      <td>50</td>\n",
       "      <td>28.351351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VUA</td>\n",
       "      <td>23113</td>\n",
       "      <td>0.283563</td>\n",
       "      <td>2298</td>\n",
       "      <td>26.113226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                n  Perc Metaphor  Uniq Verb  Avg Sentence Len\n",
       "0    MOH-X    647       0.486862        214          8.000000\n",
       "1      MOH   1603       0.248908        436          7.426076\n",
       "2  TroFi-X   1444       0.416205        857         29.346953\n",
       "3    TroFi   3737       0.435376         50         28.351351\n",
       "4      VUA  23113       0.283563       2298         26.113226"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_data_summary = get_classification_data_summary(classification_data)\n",
    "pd.DataFrame(classification_data_summary[1:],\n",
    "             columns = classification_data_summary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdd890bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tabulate Latex:\n",
      "\\begin{tabular}{lrrrr}\n",
      "\\hline\n",
      "         &     n &   Perc Metaphor &   Uniq Verb &   Avg Sentence Len \\\\\n",
      "\\hline\n",
      " MOH-X   &   647 &        0.486862 &         214 &            8       \\\\\n",
      " MOH     &  1603 &        0.248908 &         436 &            7.42608 \\\\\n",
      " TroFi-X &  1444 &        0.416205 &         857 &           29.347   \\\\\n",
      " TroFi   &  3737 &        0.435376 &          50 &           28.3514  \\\\\n",
      " VUA     & 23113 &        0.283563 &        2298 &           26.1132  \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print('\\nTabulate Latex:')\n",
    "print(tabulate.tabulate(\n",
    "    classification_data_summary,\n",
    "    headers=\"firstrow\", tablefmt=\"latex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d0d278",
   "metadata": {},
   "source": [
    "## Sequence Labeling\n",
    "### Datasets to summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832ef8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequencing_data = {\n",
    "    \"TRAIN\": data_container.vua_seq_formatted_train,\n",
    "    \"DEV\": data_container.vua_seq_formatted_test,\n",
    "    \"TEST\": data_container.vua_seq_formatted_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b94246cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ########## TRAIN ########## \n",
      "            txt_id sen_ix                                           sentence  \\\n",
      "0  a1k-fragment02     41                   Ca n't fail to be entertaining .   \n",
      "1  cdb-fragment04    907                How much was he going to tell her ?   \n",
      "2  ac2-fragment06   1520  Up until that news hit the Committee , Don had...   \n",
      "3  kbc-fragment13   5871  Could go on to the rugby and go with them coul...   \n",
      "4  ahb-fragment51    734  Finally , we went to the office and they gave ...   \n",
      "\n",
      "                                           label_seq  \\\n",
      "0                              [0, 0, 0, 0, 0, 0, 0]   \n",
      "1                        [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
      "2  [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
      "3         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                             pos_seq  \\\n",
      "0  ['VERB', 'ADV', 'VERB', 'PART', 'VERB', 'ADJ',...   \n",
      "1  ['ADV', 'ADJ', 'VERB', 'PRON', 'VERB', 'PART',...   \n",
      "2  ['ADP', 'ADP', 'DET', 'NOUN', 'VERB', 'DET', '...   \n",
      "3  ['VERB', 'VERB', 'PART', 'ADP', 'DET', 'NOUN',...   \n",
      "4  ['ADV', 'PUNCT', 'PRON', 'VERB', 'ADP', 'DET',...   \n",
      "\n",
      "                                    labeled_sentence         genre  \n",
      "0                   Ca n't fail to be entertaining .          news  \n",
      "1                How much was he going to tell her ?       fiction  \n",
      "2  Up until M_that news M_hit the Committee , Don...       fiction  \n",
      "3  Could go on to the rugby and go with them coul...  conversation  \n",
      "4  Finally , we went to the office and M_they M_g...          news  \n",
      "\n",
      " ########## DEV ########## \n",
      "            txt_id  sen_ix                                           sentence  \\\n",
      "0  a3m-fragment02      45  Design : Crossed lines over the toytown tram :...   \n",
      "1  a3m-fragment02      47  MODERN trams , as most continental Europeans k...   \n",
      "2  a3m-fragment02      48  Sleek , solidly built , gentle on the environm...   \n",
      "3  a3m-fragment02      49  They also exert a fascination very much of the...   \n",
      "4  a3m-fragment02      50  Single-car , articulated or double-decker , tr...   \n",
      "\n",
      "                                           label_seq  \\\n",
      "0  [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
      "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "2  [1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "3  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                             pos_seq  \\\n",
      "0  ['NOUN', 'PUNCT', 'ADJ', 'NOUN', 'ADP', 'DET',...   \n",
      "1  ['PROPN', 'NOUN', 'PUNCT', 'ADP', 'ADJ', 'ADJ'...   \n",
      "2  ['ADJ', 'PUNCT', 'ADV', 'VERB', 'PUNCT', 'ADJ'...   \n",
      "3  ['PRON', 'ADV', 'VERB', 'DET', 'NOUN', 'ADV', ...   \n",
      "4  ['NOUN', 'PUNCT', 'VERB', 'CCONJ', 'NOUN', 'PU...   \n",
      "\n",
      "                                    labeled_sentence genre  \n",
      "0  Design : M_Crossed M_lines M_over the toytown ...  news  \n",
      "1  MODERN trams , as most continental Europeans k...  news  \n",
      "2  M_Sleek , solidly built , M_gentle M_on the en...  news  \n",
      "3  They also M_exert a fascination very much of t...  news  \n",
      "4  Single-car , articulated or double-decker , tr...  news  \n",
      "\n",
      " ########## TEST ########## \n",
      "            txt_id  sen_ix                                           sentence  \\\n",
      "0  acj-fragment01     148  Four alternative approaches have been describe...   \n",
      "1  ab9-fragment03     908  I wanted to say , you see , that I know you th...   \n",
      "2  kbw-fragment42   14929  The one with you chop the chop and then there ...   \n",
      "3  b1g-fragment02     772  Given that most GIS are rather dumb systems , ...   \n",
      "4  a1n-fragment18     350  Lacking a goal that might have altered its che...   \n",
      "\n",
      "                                           label_seq  \\\n",
      "0         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
      "1  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "2            [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                             pos_seq  \\\n",
      "0  ['NUM', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB',...   \n",
      "1  ['PRON', 'VERB', 'PART', 'VERB', 'PUNCT', 'PRO...   \n",
      "2  ['DET', 'NOUN', 'ADP', 'PRON', 'VERB', 'DET', ...   \n",
      "3  ['VERB', 'ADP', 'ADJ', 'PROPN', 'VERB', 'ADV',...   \n",
      "4  ['VERB', 'DET', 'NOUN', 'ADJ', 'VERB', 'VERB',...   \n",
      "\n",
      "                                    labeled_sentence         genre  \n",
      "0  Four alternative M_approaches have been descri...      academic  \n",
      "1  I wanted to say , you M_see , that I know you ...       fiction  \n",
      "2  The M_one M_with you chop the chop and then th...  conversation  \n",
      "3  Given that most GIS are rather dumb systems , ...      academic  \n",
      "4  Lacking a goal that might have altered its M_c...          news  \n",
      "[None, None, None]\n"
     ]
    }
   ],
   "source": [
    "print([print(\"\\n\", \"#\"*10, f\"{name}\", \"#\"*10, \"\\n\", data.head()) \n",
    "       for name, data in sequencing_data.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e6a2bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequencing_data_summary = get_data_summary(sequencing_data)\n",
    "# pd.DataFrame(sequencing_data_summary [1:],\n",
    "#              columns = sequencing_data_summary [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2fb71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
