{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"replicate_trofi_cls_model_for_classification.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Code for replicating gao et al research on TroFi Sequence Model"],"metadata":{"id":"Do_SM5Ta8XQ_"}},{"cell_type":"code","source":["# mount drive\n","from google.colab import drive\n","ROOT = '/content/drive'\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iPjBa6KG8YpX","executionInfo":{"status":"ok","timestamp":1646887310171,"user_tz":360,"elapsed":15700,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"29b76769-e767-421f-96bc-ad4e58833bf3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# add repo directory to path\n","import os\n","import sys\n","from os.path import join \n","repo_dir = '/content/drive/MyDrive/Repos/metaphor-detection'\n","if repo_dir not in sys.path:\n","    sys.path.append(repo_dir)\n","print(sys.path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yvkSQr2wCqwJ","executionInfo":{"status":"ok","timestamp":1646887312003,"user_tz":360,"elapsed":92,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"cb3baec1-0933-4d2c-f6f3-a45515be88e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/MyDrive/Repos/metaphor-detection']\n"]}]},{"cell_type":"code","source":["# directories\n","# to download glove and elmo vectors see: notebooks/Download_large_data.ipynb\n","data_dir = repo_dir + '/resources/metaphor-in-context/data/'\n","glove_dir = repo_dir + '/resources/glove/'\n","elmo_dir = repo_dir + '/resources/elmo/'"],"metadata":{"id":"Ljz6YD2jCvJO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# cd to working directory here if neccesary\n","%cd $repo_dir\n","%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jpMIULEVCyHz","executionInfo":{"status":"ok","timestamp":1646887316683,"user_tz":360,"elapsed":381,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"dfa79f58-0706-4af9-a1f5-71ae31f99b06"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Repos/metaphor-detection\n","\u001b[0m\u001b[01;34mcore\u001b[0m/  gao-g-requirements.txt  install.sh  \u001b[01;34mnotebooks\u001b[0m/  README.md  \u001b[01;34mresources\u001b[0m/\n"]}]},{"cell_type":"code","source":["# pip install requirements (takes a while)\n","!cd drive/MyDrive/Repos/metaphor-detection/; pip install -r gao-g-requirements.txt\n","!pip install --upgrade google-cloud-storage"],"metadata":{"collapsed":true,"id":"j8SQdTVGDOLS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2"],"metadata":{"id":"HJrKul5xEWC8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from core.gao_files.classification.util import get_num_lines, get_vocab, embed_sequence, \\\n","    get_word2idx_idx2word, get_embedding_matrix\n","from core.gao_files.classification.util import TextDatasetWithGloveElmoSuffix as TextDataset\n","from core.gao_files.classification.util import evaluate\n","from core.gao_files.classification.model import RNNSequenceClassifier\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","\n","\n","import csv\n","import h5py\n","import random\n","import math\n","import numpy as np\n","import pandas as pd"],"metadata":{"id":"IXG7W5R9EYt9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"PyTorch version:\")\n","print(torch.__version__)\n","print(\"GPU Detected:\")\n","print(torch.cuda.is_available())\n","using_GPU = True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a7j6NB1TFhzv","executionInfo":{"status":"ok","timestamp":1646887462620,"user_tz":360,"elapsed":176,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"cbb2bc84-af6a-4753-98c9-f99edc26179e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch version:\n","1.10.0+cu111\n","GPU Detected:\n","True\n"]}]},{"cell_type":"code","source":["\"\"\"\n","1. Data pre-processing\n","\"\"\"\n","'''\n","roFi\n","get raw dataset as a list:\n","  Each element is a triple:\n","    a sentence: string\n","    a index: int: idx of the focus verb\n","    a label: int 1 or 0\n","'''\n","raw_trofi = []\n","\n","# normal version\n","with open(data_dir + 'TroFi/TroFi_formatted_all3737.csv') as f:\n","    lines = csv.reader(f)\n","    next(lines)\n","    for line in lines:\n","        raw_trofi.append([line[1].strip(), int(line[2]), int(line[3])])\n","print('TroFi dataset size: ', len(raw_trofi))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MftreTD4FlnK","executionInfo":{"status":"ok","timestamp":1646887466317,"user_tz":360,"elapsed":857,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"222074d2-05a9-44f1-fa0f-f9b5269b22a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TroFi dataset size:  3737\n"]}]},{"cell_type":"code","source":["raw_trofi[87]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M3_WodbcGYC_","executionInfo":{"status":"ok","timestamp":1646887469719,"user_tz":360,"elapsed":85,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"5a1fd435-ed44-4902-db6a-d54febc61082"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Anyone can dance the hokey - pokey', 2, 0]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["\"\"\"\n","2. Data preparation\n","\"\"\"\n","'''\n","2. 1\n","get vocabulary and glove embeddings in raw dataset \n","'''\n","# vocab is a set of words\n","vocab = get_vocab(raw_trofi)\n","# two dictionaries. <PAD>: 0, <UNK>: 1\n","word2idx, idx2word = get_word2idx_idx2word(vocab)\n","# glove_embeddings a nn.Embeddings\n","glove_embeddings = get_embedding_matrix(glove_dir + 'glove.840B.300d.txt', word2idx,\n","                                        idx2word, normalization=False)\n","# elmo_embeddings\n","# set elmos_mohx=None to exclude elmo vectors\n","elmos_trofi = h5py.File(elmo_dir + 'TroFi3737.hdf5', 'r')\n","# suffix_embeddings: number of suffix tag is 2, and the suffix embedding dimension is 50\n","suffix_embeddings = nn.Embedding(2, 50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gn8LCM3zGjk9","executionInfo":{"status":"ok","timestamp":1646887618560,"user_tz":360,"elapsed":146446,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"167698c5-f9cd-4ac8-b5e1-10b7e3f42aad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["vocab size:  14881\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2196017/2196017 [01:04<00:00, 33925.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of pre-trained word vectors loaded:  14674\n","Embeddings mean:  0.0016923490911722183\n","Embeddings stdev:  0.3751399517059326\n"]}]},{"cell_type":"code","source":["'''\n","2. 2\n","embed the datasets\n","'''\n","random.seed(0)\n","random.shuffle(raw_trofi)\n","\n","embedded_trofi = [[embed_sequence(example[0], example[1], word2idx,\n","                                 glove_embeddings, elmos_trofi, suffix_embeddings), example[2]]\n","                 for example in raw_trofi]"],"metadata":{"id":"8dBcYdHWG-fl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","2. 3\n","set up Dataloader for batching\n","'''\n","'''\n","2. 3 10-fold cross validation\n","'''\n","# separate the embedded_sentences and labels into 2 list, in order to pass into the TextDataset as argument\n","sentences = [example[0] for example in embedded_trofi]\n","labels = [example[1] for example in embedded_trofi]\n","# ten_folds is a list of 10 tuples, each tuple is (list_of_embedded_sentences, list_of_corresponding_labels)\n","ten_folds = []\n","fold_size = int(3737/10)\n","for i in range(10):\n","    ten_folds.append((sentences[i*fold_size:(i+1)*fold_size], \n","                      labels[i*fold_size:(i+1)*fold_size]))\n","\n","optimal_f1s = []\n","optimal_ps = []\n","optimal_rs = []\n","optimal_accs = []\n","predictions_all = []\n","for i in range(10):\n","    '''\n","    2. 3\n","    set up Dataloader for batching\n","    '''\n","    training_sentences = []\n","    training_labels = []\n","    for j in range(10):\n","        if j != i:\n","            training_sentences.extend(ten_folds[j][0])\n","            training_labels.extend(ten_folds[j][1])\n","    training_dataset_trofi = TextDataset(training_sentences, training_labels)\n","    val_dataset_trofi = TextDataset(ten_folds[i][0], ten_folds[i][1])\n","\n","    # Data-related hyperparameters\n","    batch_size = 10\n","    # Set up a DataLoader for the training, validation, and test dataset\n","    train_dataloader_trofi = DataLoader(dataset=training_dataset_trofi, batch_size=batch_size, shuffle=True,\n","                                      collate_fn=TextDataset.collate_fn)\n","    val_dataloader_trofi = DataLoader(dataset=val_dataset_trofi, batch_size=batch_size, shuffle=False,\n","                                      collate_fn=TextDataset.collate_fn)\n","    \"\"\"\n","    3. Model training\n","    \"\"\"\n","    '''\n","    3. 1 \n","    set up model, loss criterion, optimizer\n","    '''\n","    # Instantiate the model\n","    # embedding_dim = glove + elmo + suffix indicator\n","    # dropout1: dropout on input to RNN\n","    # dropout2: dropout in RNN; would be used if num_layers=1\n","    # dropout3: dropout on hidden state of RNN to linear layer\n","    rnn_clf = RNNSequenceClassifier(num_classes=2, embedding_dim=300+1024+50, hidden_size=300,\n","                                    num_layers=1, bidir=True,\n","                                    dropout1=0.2, dropout2=0, dropout3=0)\n","    # Move the model to the GPU if available\n","    if using_GPU:\n","        rnn_clf = rnn_clf.cuda()\n","    # Set up criterion for calculating loss\n","    nll_criterion = nn.NLLLoss()\n","    # Set up an optimizer for updating the parameters of the rnn_clf\n","    rnn_clf_optimizer = optim.Adam(rnn_clf.parameters(), lr=0.001)\n","    # Number of epochs (passes through the dataset) to train the model for.\n","    num_epochs = 15\n","\n","    '''\n","    3. 2\n","    train model\n","    '''\n","    training_loss = []\n","    val_loss = []\n","    training_f1 = []\n","    val_f1 = []\n","    val_p = []\n","    val_r = []\n","    val_acc = []\n","    # A counter for the number of gradient updates\n","    num_iter = 0\n","    train_dataloader = train_dataloader_trofi \n","    val_dataloader = val_dataloader_trofi\n","    model_index = 0\n","    for epoch in range(num_epochs):\n","        print(\"Starting epoch {}\".format(epoch + 1))\n","        for (example_text, example_lengths, labels) in train_dataloader:\n","            example_text = Variable(example_text)\n","            example_lengths = Variable(example_lengths)\n","            labels = Variable(labels)\n","            if using_GPU:\n","                example_text = example_text.cuda()\n","                example_lengths = example_lengths.cuda()\n","                labels = labels.cuda()\n","            # predicted shape: (batch_size, 2)\n","            predicted = rnn_clf(example_text, example_lengths)\n","            batch_loss = nll_criterion(predicted, labels)\n","            rnn_clf_optimizer.zero_grad()\n","            batch_loss.backward()\n","            rnn_clf_optimizer.step()\n","            num_iter += 1\n","            # Calculate validation and training set loss and accuracy every 200 gradient updates\n","            if num_iter % 200 == 0:\n","                avg_eval_loss, eval_accuracy, precision, recall, f1, fus_f1 = evaluate(val_dataloader, rnn_clf, nll_criterion, using_GPU)\n","                val_loss.append(avg_eval_loss)\n","                val_f1.append(f1)\n","                val_p.append(precision)\n","                val_r.append(recall)\n","                val_acc.append(eval_accuracy)\n","                print(\n","                    \"Iteration {}. Validation Loss {}. Validation Accuracy {}. Validation Precision {}. Validation Recall {}. Validation F1 {}. Validation class-wise F1 {}.\".format(\n","                        num_iter, avg_eval_loss, eval_accuracy, precision, recall, f1, fus_f1))\n","#                 filename = '../models/LSTMSuffixElmoAtt_MOH_fold_' + str(i) + '_epoch_' + str(model_index) + '.pt'\n","#                 torch.save(rnn_clf, filename)\n","                model_index += 1\n","#                 avg_eval_loss, eval_accuracy, precision, recall, f1, fus_f1 = evaluate(train_dataloader, rnn_clf, nll_criterion, using_GPU)\n","#                 training_loss.append(avg_eval_loss)\n","#                 training_f1.append(f1)\n","#                 print(\n","#                     \"Iteration {}. Training Loss {}. Training Accuracy {}. Training Precision {}. Training Recall {}. Training F1 {}. Training class-wise F1 {}.\".format(\n","#                         num_iter, avg_eval_loss, eval_accuracy, precision, recall, f1, fus_f1))\n","    \"\"\"\n","    store the best f1\n","    \"\"\"\n","    print('val_f1: ', val_f1)\n","    idx = 0\n","    if math.isnan(max(val_f1)):\n","        optimal_f1s.append(max(val_f1[6:]))\n","        idx = val_f1.index(optimal_f1s[-1])\n","        optimal_ps.append(val_p[idx])\n","        optimal_rs.append(val_r[idx])\n","        optimal_accs.append(val_acc[idx])\n","    else:\n","        optimal_f1s.append(max(val_f1))\n","        idx = val_f1.index(optimal_f1s[-1])\n","        optimal_ps.append(val_p[idx])\n","        optimal_rs.append(val_r[idx])\n","        optimal_accs.append(val_acc[idx])\n","#     filename = '../models/LSTMSuffixElmoAtt_TroFi_fold_' + str(i) + '_epoch_' + str(idx) + '.pt'\n","#     temp_model = torch.load(filename)\n","#     print('best model: ', filename)\n","#     predictions_all.extend(test(val_dataloader_TroFi, temp_model, using_GPU))"],"metadata":{"collapsed":true,"id":"gny9s0XRHyfQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('F1 on TroFi by 10-fold = ', optimal_f1s)\n","print('Precision on TroFi = ', np.mean(np.array(optimal_ps)))\n","print('Recall on TroFi = ', np.mean(np.array(optimal_rs)))\n","print('F1 on TroFi = ', np.mean(np.array(optimal_f1s)))\n","print('Accuracy on TroFi = ', np.mean(np.array(torch.tensor(optimal_accs))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1nSqQzRQJ3e","executionInfo":{"status":"ok","timestamp":1646889909969,"user_tz":360,"elapsed":203,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"43d62557-f9a1-48db-8742-4f186ce707f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["F1 on TroFi by 10-fold =  [69.41176470588236]\n","Precision on TroFi =  72.39263803680981\n","Recall on TroFi =  66.66666666666667\n","F1 on TroFi =  69.41176470588236\n","Accuracy on TroFi =  72.117966\n"]}]},{"cell_type":"code","source":["np.mean(np.array(torch.tensor(optimal_accs)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oBrX9bzYSDL7","executionInfo":{"status":"ok","timestamp":1646889892540,"user_tz":360,"elapsed":184,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"4ac80f58-65e0-4784-e69d-66bc5c43b37a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["72.117966"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["gao_scores = [68.7, 74.6, 72.0, 73.7]\n","our_scores = [np.mean(np.array(optimal_ps)),\n","  np.mean(np.array(optimal_rs)),\n","  np.mean(np.array(optimal_f1s)),\n","  np.mean(np.array(torch.tensor(optimal_accs)))]\n","our_scores = [round(score,1) for score in our_scores]\n","all_scores = [gao_scores, our_scores]\n","all_scores_df = pd.DataFrame(all_scores, columns= ['P', 'R', 'F1', 'Acc'], index=['Gao et al', 'US'])\n","print(\"trofi cls model: classification task\\n\")\n","all_scores_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":147},"id":"xbxPEtdYQWwD","executionInfo":{"status":"ok","timestamp":1646890132370,"user_tz":360,"elapsed":184,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"ce96888a-65c7-4c84-e70c-7976b1361d9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["trofi cls model: classification task\n","\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-0d5d1b10-c281-4ada-b121-4fa7971a05d2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>P</th>\n","      <th>R</th>\n","      <th>F1</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Gao et al</th>\n","      <td>68.7</td>\n","      <td>74.6</td>\n","      <td>72.0</td>\n","      <td>73.700000</td>\n","    </tr>\n","    <tr>\n","      <th>US</th>\n","      <td>72.4</td>\n","      <td>66.7</td>\n","      <td>69.4</td>\n","      <td>72.099998</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d5d1b10-c281-4ada-b121-4fa7971a05d2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0d5d1b10-c281-4ada-b121-4fa7971a05d2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0d5d1b10-c281-4ada-b121-4fa7971a05d2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["              P     R    F1        Acc\n","Gao et al  68.7  74.6  72.0  73.700000\n","US         72.4  66.7  69.4  72.099998"]},"metadata":{},"execution_count":46}]}]}