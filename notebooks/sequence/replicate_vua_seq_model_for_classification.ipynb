{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"replicate_vua_seq_model_for_classification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO7MwdwAXuKNgXL2Kr5C2ff"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Code for replicating gao et al research on VUA Sequence Model"],"metadata":{"id":"cwGntX9XF_w5"}},{"cell_type":"code","source":["# mount drive\n","from google.colab import drive\n","ROOT = '/content/drive'\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-5eimCtJGFMV","executionInfo":{"status":"ok","timestamp":1646748213700,"user_tz":360,"elapsed":18795,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"d454b3a0-496d-4bc5-c9c4-c98279e0910c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# add repo directory to path\n","import os\n","import sys\n","from os.path import join \n","repo_dir = '/content/drive/MyDrive/Repos/metaphor-detection'\n","if repo_dir not in sys.path:\n","    sys.path.append(repo_dir)\n","print(sys.path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"05s1lk-FGRkv","executionInfo":{"status":"ok","timestamp":1646748235898,"user_tz":360,"elapsed":141,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"adc5199d-9c40-4750-b19f-c8cec39f414d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["['', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/MyDrive/Repos/metaphor-detection']\n"]}]},{"cell_type":"code","source":["# directories\n","# to download glove and elmo vectors see: notebooks/Download_large_data.ipynb\n","data_dir = repo_dir + '/resources/metaphor-in-context/data/'\n","glove_dir = repo_dir + '/resources/glove/'\n","elmo_dir = repo_dir + '/resources/elmo/'"],"metadata":{"id":"DP7y3T40GVyt","executionInfo":{"status":"ok","timestamp":1646748238799,"user_tz":360,"elapsed":152,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# cd to working directory here if neccesary\n","%pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"9_hQF3t13kYt","executionInfo":{"status":"ok","timestamp":1646748671289,"user_tz":360,"elapsed":128,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"e5e8c809-2053-4bbd-eaf0-09164c07ccb0"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Repos/metaphor-detection'"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["Gao code"],"metadata":{"id":"9U55BkPGGZWt"}},{"cell_type":"code","source":["# pip install requirements (takes a while)\n","!cd drive/MyDrive/Repos/metaphor-detection/; pip install -r gao-g-requirements.txt\n","!pip install --upgrade google-cloud-storage"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DXGSJDyhGZGT","executionInfo":{"status":"ok","timestamp":1646748596925,"user_tz":360,"elapsed":120923,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"1ea5a63c-9c05-4598-8bce-ec1eda5c9da2","collapsed":true},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 0: cd: drive/MyDrive/Repos/metaphor-detection/: No such file or directory\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r gao-g-requirements.txt (line 3)) (4.63.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r gao-g-requirements.txt (line 6)) (1.21.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from -r gao-g-requirements.txt (line 9)) (3.1.0)\n","Collecting allennlp\n","  Downloading allennlp-2.9.0-py3-none-any.whl (716 kB)\n","\u001b[K     |████████████████████████████████| 716 kB 8.7 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r gao-g-requirements.txt (line 16)) (3.2.2)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->-r gao-g-requirements.txt (line 9)) (1.5.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp->-r gao-g-requirements.txt (line 13)) (1.0.2)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from allennlp->-r gao-g-requirements.txt (line 13)) (8.12.0)\n","Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from allennlp->-r gao-g-requirements.txt (line 13)) (0.99)\n","Requirement already satisfied: torchvision<0.12.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r gao-g-requirements.txt (line 13)) (0.11.1+cu111)\n","Collecting huggingface-hub>=0.0.16\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.0 MB/s \n","\u001b[?25hCollecting jsonnet>=0.10.0\n","  Downloading jsonnet-0.18.0.tar.gz (592 kB)\n","\u001b[K     |████████████████████████████████| 592 kB 59.4 MB/s \n","\u001b[?25hCollecting base58\n","  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n","Requirement already satisfied: nltk<3.6.6 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r gao-g-requirements.txt (line 13)) (3.2.5)\n","Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r gao-g-requirements.txt (line 13)) (1.1.0)\n","Collecting cached-path<2.0.0,>=1.0.2\n","  Downloading cached_path-1.1.0-py3-none-any.whl (26 kB)\n","Collecting wandb<0.13.0,>=0.10.0\n","  Downloading wandb-0.12.11-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 52.9 MB/s \n","\u001b[?25hCollecting tensorboardX>=1.2\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 72.2 MB/s \n","\u001b[?25hRequirement already satisfied: torch<1.11.0,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r gao-g-requirements.txt (line 13)) (1.10.0+cu111)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from allennlp->-r gao-g-requirements.txt (line 13)) (0.3.4)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 48.1 MB/s \n","\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp->-r gao-g-requirements.txt (line 13)) (3.6.4)\n","Requirement already satisfied: spacy<3.3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r gao-g-requirements.txt (line 13)) (2.2.4)\n","Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp->-r gao-g-requirements.txt (line 13)) (2.23.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp->-r gao-g-requirements.txt (line 13)) (1.4.1)\n","Collecting fairscale==0.4.5\n","  Downloading fairscale-0.4.5.tar.gz (240 kB)\n","\u001b[K     |████████████████████████████████| 240 kB 72.5 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting filelock<3.5,>=3.3\n","  Downloading filelock-3.4.2-py3-none-any.whl (9.9 kB)\n","Collecting transformers<4.16,>=4.1\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 28.2 MB/s \n","\u001b[?25hCollecting checklist==0.0.11\n","  Downloading checklist-0.0.11.tar.gz (12.1 MB)\n","\u001b[K     |████████████████████████████████| 12.1 MB 48.4 MB/s \n","\u001b[?25hCollecting munch>=2.5\n","  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n","Requirement already satisfied: jupyter>=1.0 in /usr/local/lib/python3.7/dist-packages (from checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (1.0.0)\n","Requirement already satisfied: ipywidgets>=7.5 in /usr/local/lib/python3.7/dist-packages (from checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (7.6.5)\n","Collecting patternfork-nosql\n","  Downloading patternfork_nosql-3.6.tar.gz (22.3 MB)\n","\u001b[K     |████████████████████████████████| 22.3 MB 1.4 MB/s \n","\u001b[?25hCollecting iso-639\n","  Downloading iso-639-0.4.5.tar.gz (167 kB)\n","\u001b[K     |████████████████████████████████| 167 kB 70.5 MB/s \n","\u001b[?25hCollecting boto3<2.0,>=1.0\n","  Downloading boto3-1.21.14-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 66.4 MB/s \n","\u001b[?25hRequirement already satisfied: google-cloud-storage<3.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from cached-path<2.0.0,>=1.0.2->allennlp->-r gao-g-requirements.txt (line 13)) (1.18.1)\n","Collecting botocore<1.25.0,>=1.24.14\n","  Downloading botocore-1.24.14-py3-none-any.whl (8.6 MB)\n","\u001b[K     |████████████████████████████████| 8.6 MB 51.5 MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 11.1 MB/s \n","\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 70.0 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.14->boto3<2.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp->-r gao-g-requirements.txt (line 13)) (2.8.2)\n","Requirement already satisfied: google-auth>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp->-r gao-g-requirements.txt (line 13)) (1.35.0)\n","Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp->-r gao-g-requirements.txt (line 13)) (1.0.3)\n","Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp->-r gao-g-requirements.txt (line 13)) (0.4.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp->-r gao-g-requirements.txt (line 13)) (0.2.8)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp->-r gao-g-requirements.txt (line 13)) (57.4.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp->-r gao-g-requirements.txt (line 13)) (4.2.4)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp->-r gao-g-requirements.txt (line 13)) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp->-r gao-g-requirements.txt (line 13)) (4.8)\n","Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp->-r gao-g-requirements.txt (line 13)) (1.26.3)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp->-r gao-g-requirements.txt (line 13)) (3.17.3)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp->-r gao-g-requirements.txt (line 13)) (2018.9)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp->-r gao-g-requirements.txt (line 13)) (1.55.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp->-r gao-g-requirements.txt (line 13)) (21.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp->-r gao-g-requirements.txt (line 13)) (3.13)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp->-r gao-g-requirements.txt (line 13)) (4.11.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp->-r gao-g-requirements.txt (line 13)) (3.10.0.2)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (3.5.2)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (1.0.2)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (5.1.1)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (0.2.0)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (5.5.0)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (5.1.3)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (4.10.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (5.3.5)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (5.1.1)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (2.6.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (1.0.18)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (0.8.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (4.8.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (0.7.5)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (5.3.1)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (5.2.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (5.6.1)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (5.2.2)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (4.3.3)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (4.9.2)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (0.18.1)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (21.4.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (5.4.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (3.7.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp->-r gao-g-requirements.txt (line 13)) (3.0.7)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (0.2.5)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp->-r gao-g-requirements.txt (line 13)) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp->-r gao-g-requirements.txt (line 13)) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp->-r gao-g-requirements.txt (line 13)) (3.0.4)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 47.2 MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp->-r gao-g-requirements.txt (line 13)) (2.10)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp->-r gao-g-requirements.txt (line 13)) (0.4.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp->-r gao-g-requirements.txt (line 13)) (0.9.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp->-r gao-g-requirements.txt (line 13)) (3.0.6)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp->-r gao-g-requirements.txt (line 13)) (1.1.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp->-r gao-g-requirements.txt (line 13)) (2.0.6)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp->-r gao-g-requirements.txt (line 13)) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp->-r gao-g-requirements.txt (line 13)) (1.0.6)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp->-r gao-g-requirements.txt (line 13)) (7.4.0)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp->-r gao-g-requirements.txt (line 13)) (1.0.0)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision<0.12.0,>=0.8.1->allennlp->-r gao-g-requirements.txt (line 13)) (7.1.2)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 60.8 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.16,>=4.1->allennlp->-r gao-g-requirements.txt (line 13)) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 50.7 MB/s \n","\u001b[?25hCollecting pyyaml\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 59.4 MB/s \n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp->-r gao-g-requirements.txt (line 13)) (2.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp->-r gao-g-requirements.txt (line 13)) (5.4.8)\n","Collecting setproctitle\n","  Downloading setproctitle-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (36 kB)\n","Collecting yaspin>=1.0.0\n","  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp->-r gao-g-requirements.txt (line 13)) (7.1.2)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 76.6 MB/s \n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.5.7-py2.py3-none-any.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 61.4 MB/s \n","\u001b[?25hCollecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (0.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (2.11.3)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (1.8.0)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (22.3.0)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter>=1.0->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (0.7.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r gao-g-requirements.txt (line 16)) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r gao-g-requirements.txt (line 16)) (1.3.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter>=1.0->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (2.0.1)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (1.5.0)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (0.4)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (0.8.4)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (0.7.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (4.1.0)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (0.6.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (0.5.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (0.16.0)\n","Collecting backports.csv\n","  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (4.6.3)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (4.2.6)\n","Collecting feedparser\n","  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n","\u001b[K     |████████████████████████████████| 81 kB 13.5 MB/s \n","\u001b[?25hCollecting pdfminer.six\n","  Downloading pdfminer.six-20211012-py3-none-any.whl (5.6 MB)\n","\u001b[K     |████████████████████████████████| 5.6 MB 19.4 MB/s \n","\u001b[?25hCollecting python-docx\n","  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n","\u001b[K     |████████████████████████████████| 5.6 MB 47.9 MB/s \n","\u001b[?25hCollecting cherrypy\n","  Downloading CherryPy-18.6.1-py2.py3-none-any.whl (419 kB)\n","\u001b[K     |████████████████████████████████| 419 kB 51.6 MB/s \n","\u001b[?25hCollecting jaraco.collections\n","  Downloading jaraco.collections-3.5.1-py3-none-any.whl (10 kB)\n","Collecting cheroot>=8.2.1\n","  Downloading cheroot-8.6.0-py2.py3-none-any.whl (104 kB)\n","\u001b[K     |████████████████████████████████| 104 kB 72.2 MB/s \n","\u001b[?25hCollecting portend>=2.1.1\n","  Downloading portend-3.1.0-py3-none-any.whl (5.3 kB)\n","Collecting zc.lockfile\n","  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n","Collecting jaraco.functools\n","  Downloading jaraco.functools-3.5.0-py3-none-any.whl (7.0 kB)\n","Collecting tempora>=1.8\n","  Downloading tempora-5.0.1-py3-none-any.whl (15 kB)\n","Collecting sgmllib3k\n","  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n","Collecting jaraco.text\n","  Downloading jaraco.text-3.7.0-py3-none-any.whl (8.6 kB)\n","Collecting jaraco.classes\n","  Downloading jaraco.classes-3.2.1-py3-none-any.whl (5.6 kB)\n","Collecting jaraco.context>=4.1\n","  Downloading jaraco.context-4.1.1-py3-none-any.whl (4.4 kB)\n","Collecting cryptography\n","  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n","\u001b[K     |████████████████████████████████| 3.6 MB 46.3 MB/s \n","\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six->patternfork-nosql->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six->patternfork-nosql->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (2.21)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp->-r gao-g-requirements.txt (line 13)) (1.11.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp->-r gao-g-requirements.txt (line 13)) (1.4.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp->-r gao-g-requirements.txt (line 13)) (0.7.1)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter>=1.0->checklist==0.0.11->allennlp->-r gao-g-requirements.txt (line 13)) (2.0.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.16,>=4.1->allennlp->-r gao-g-requirements.txt (line 13)) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->allennlp->-r gao-g-requirements.txt (line 13)) (3.1.0)\n","Building wheels for collected packages: checklist, fairscale, jsonnet, iso-639, pathtools, patternfork-nosql, python-docx, sgmllib3k\n","  Building wheel for checklist (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for checklist: filename=checklist-0.0.11-py3-none-any.whl size=12165635 sha256=d8f35b24ebe7f18c349657ce4f5036aa140289697465c2d949cc0a2822472485\n","  Stored in directory: /root/.cache/pip/wheels/6a/8a/07/6446879be434879c27671c83443727d74cecf6b630c8a24d03\n","  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairscale: filename=fairscale-0.4.5-py3-none-any.whl size=297992 sha256=074f73be530d03859cb8535d47996badabf73a73c69d6952a9d174fadfbd86bf\n","  Stored in directory: /root/.cache/pip/wheels/83/d0/90/bcfc419ab267ea41fda54216f0c99e3faf9bab9b38ec760c46\n","  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jsonnet: filename=jsonnet-0.18.0-cp37-cp37m-linux_x86_64.whl size=3994562 sha256=c384eef1667ad084405ae8423eda64d24ceb089f154dd7c5b6f23c0229b1d1c7\n","  Stored in directory: /root/.cache/pip/wheels/a9/63/f9/a653f9c21575e6ff271ee6a49939aa002005174cea6c35919d\n","  Building wheel for iso-639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iso-639: filename=iso_639-0.4.5-py3-none-any.whl size=169061 sha256=9976bc42f4aa3a335ab0a2902682f4048c0866d093368456674ae297dcc485cf\n","  Stored in directory: /root/.cache/pip/wheels/47/60/19/6d020fc92138ed1b113a18271e83ea4b5525fe770cb45b9a2e\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=874b18446487f732013cf0f6e7dd70e7bcdab0e2c4be471571ca2286d48b6bc8\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","  Building wheel for patternfork-nosql (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for patternfork-nosql: filename=patternfork_nosql-3.6-py3-none-any.whl size=22332804 sha256=26c4096c18f4e987378354e26c215fa7e907048f38080ffd92e80dd80c81c926\n","  Stored in directory: /root/.cache/pip/wheels/97/72/8f/5305fe28168f93b658da9ed433b9a1d3ec90594faa0c9aaf4b\n","  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184507 sha256=b0504ee434a7a0d0644af2f59e61d2ad286673df63858e368f2d946d52ecbc20\n","  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n","  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=a3ef17e021eabbe1dbfc5c53fdbf2d5ad560ece8da4fb4206a28e00437fb807a\n","  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n","Successfully built checklist fairscale jsonnet iso-639 pathtools patternfork-nosql python-docx sgmllib3k\n","Installing collected packages: urllib3, jaraco.functools, jaraco.context, tempora, jmespath, jaraco.text, jaraco.classes, zc.lockfile, smmap, sgmllib3k, pyyaml, portend, jaraco.collections, filelock, cryptography, cheroot, botocore, tokenizers, sacremoses, s3transfer, python-docx, pdfminer.six, huggingface-hub, gitdb, feedparser, cherrypy, backports.csv, yaspin, transformers, shortuuid, setproctitle, sentry-sdk, patternfork-nosql, pathtools, munch, iso-639, GitPython, docker-pycreds, boto3, wandb, tensorboardX, sentencepiece, jsonnet, fairscale, checklist, cached-path, base58, allennlp\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: filelock\n","    Found existing installation: filelock 3.6.0\n","    Uninstalling filelock-3.6.0:\n","      Successfully uninstalled filelock-3.6.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed GitPython-3.1.27 allennlp-2.9.0 backports.csv-1.0.7 base58-2.1.1 boto3-1.21.14 botocore-1.24.14 cached-path-1.1.0 checklist-0.0.11 cheroot-8.6.0 cherrypy-18.6.1 cryptography-36.0.1 docker-pycreds-0.4.0 fairscale-0.4.5 feedparser-6.0.8 filelock-3.4.2 gitdb-4.0.9 huggingface-hub-0.4.0 iso-639-0.4.5 jaraco.classes-3.2.1 jaraco.collections-3.5.1 jaraco.context-4.1.1 jaraco.functools-3.5.0 jaraco.text-3.7.0 jmespath-0.10.0 jsonnet-0.18.0 munch-2.5.0 pathtools-0.1.2 patternfork-nosql-3.6 pdfminer.six-20211012 portend-3.1.0 python-docx-0.8.11 pyyaml-6.0 s3transfer-0.5.2 sacremoses-0.0.47 sentencepiece-0.1.96 sentry-sdk-1.5.7 setproctitle-1.2.2 sgmllib3k-1.0.0 shortuuid-1.0.8 smmap-5.0.0 tempora-5.0.1 tensorboardX-2.5 tokenizers-0.10.3 transformers-4.15.0 urllib3-1.25.11 wandb-0.12.11 yaspin-2.1.0 zc.lockfile-2.0\n","Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (1.18.1)\n","Collecting google-cloud-storage\n","  Downloading google_cloud_storage-2.1.0-py2.py3-none-any.whl (106 kB)\n","\u001b[K     |████████████████████████████████| 106 kB 7.6 MB/s \n","\u001b[?25hCollecting google-api-core<3.0dev,>=1.29.0\n","  Downloading google_api_core-2.6.1-py3-none-any.whl (114 kB)\n","\u001b[K     |████████████████████████████████| 114 kB 45.6 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (3.17.3)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (2.23.0)\n","Collecting google-resumable-media>=1.3.0\n","  Downloading google_resumable_media-2.3.1-py2.py3-none-any.whl (76 kB)\n","\u001b[K     |████████████████████████████████| 76 kB 7.1 MB/s \n","\u001b[?25hCollecting google-cloud-core<3.0dev,>=1.6.0\n","  Downloading google_cloud_core-2.2.3-py2.py3-none-any.whl (29 kB)\n","Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (1.35.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage) (1.55.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (57.4.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.2.4)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (1.15.0)\n","Collecting google-crc32c<2.0dev,>=1.0\n","  Downloading google_crc32c-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38 kB)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2021.10.8)\n","Installing collected packages: google-crc32c, google-api-core, google-resumable-media, google-cloud-core, google-cloud-storage\n","  Attempting uninstall: google-api-core\n","    Found existing installation: google-api-core 1.26.3\n","    Uninstalling google-api-core-1.26.3:\n","      Successfully uninstalled google-api-core-1.26.3\n","  Attempting uninstall: google-resumable-media\n","    Found existing installation: google-resumable-media 0.4.1\n","    Uninstalling google-resumable-media-0.4.1:\n","      Successfully uninstalled google-resumable-media-0.4.1\n","  Attempting uninstall: google-cloud-core\n","    Found existing installation: google-cloud-core 1.0.3\n","    Uninstalling google-cloud-core-1.0.3:\n","      Successfully uninstalled google-cloud-core-1.0.3\n","  Attempting uninstall: google-cloud-storage\n","    Found existing installation: google-cloud-storage 1.18.1\n","    Uninstalling google-cloud-storage-1.18.1:\n","      Successfully uninstalled google-cloud-storage-1.18.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-cloud-translate 1.5.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.6.1 which is incompatible.\n","google-cloud-translate 1.5.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.2.3 which is incompatible.\n","google-cloud-language 1.2.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.6.1 which is incompatible.\n","google-cloud-firestore 1.7.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.6.1 which is incompatible.\n","google-cloud-firestore 1.7.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.2.3 which is incompatible.\n","google-cloud-datastore 1.8.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.6.1 which is incompatible.\n","google-cloud-datastore 1.8.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.2.3 which is incompatible.\n","google-cloud-bigquery 1.21.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.2.3 which is incompatible.\n","google-cloud-bigquery 1.21.0 requires google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1, but you have google-resumable-media 2.3.1 which is incompatible.\n","google-cloud-bigquery-storage 1.1.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.6.1 which is incompatible.\n","firebase-admin 4.4.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\", but you have google-api-core 2.6.1 which is incompatible.\u001b[0m\n","Successfully installed google-api-core-2.6.1 google-cloud-core-2.2.3 google-cloud-storage-2.1.0 google-crc32c-1.3.0 google-resumable-media-2.3.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{}}]},{"cell_type":"code","source":["#@title\n","!pip install Ipython --upgrade"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":729},"id":"OyWlpyi3LoSW","executionInfo":{"status":"ok","timestamp":1646748680509,"user_tz":360,"elapsed":4982,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"9a27fd64-a74e-447d-90af-5e7817f886a6","collapsed":true},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: Ipython in /usr/local/lib/python3.7/dist-packages (5.5.0)\n","Collecting Ipython\n","  Downloading ipython-7.32.0-py3-none-any.whl (793 kB)\n","\u001b[K     |████████████████████████████████| 793 kB 6.6 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from Ipython) (57.4.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from Ipython) (4.8.0)\n","Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n","  Downloading prompt_toolkit-3.0.28-py3-none-any.whl (380 kB)\n","\u001b[K     |████████████████████████████████| 380 kB 65.5 MB/s \n","\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from Ipython) (0.2.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from Ipython) (0.18.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from Ipython) (4.4.2)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from Ipython) (5.1.1)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from Ipython) (0.1.3)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from Ipython) (2.6.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from Ipython) (0.7.5)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->Ipython) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->Ipython) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->Ipython) (0.2.5)\n","Installing collected packages: prompt-toolkit, Ipython\n","  Attempting uninstall: prompt-toolkit\n","    Found existing installation: prompt-toolkit 1.0.18\n","    Uninstalling prompt-toolkit-1.0.18:\n","      Successfully uninstalled prompt-toolkit-1.0.18\n","  Attempting uninstall: Ipython\n","    Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.28 which is incompatible.\n","google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.32.0 which is incompatible.\u001b[0m\n","Successfully installed Ipython-7.32.0 prompt-toolkit-3.0.28\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython","prompt_toolkit"]}}},"metadata":{}}]},{"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2"],"metadata":{"id":"qnY1RWAjLrvw","executionInfo":{"status":"ok","timestamp":1646748694570,"user_tz":360,"elapsed":135,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["from core.gao_files.sequence.util import get_num_lines, get_pos2idx_idx2pos, index_sequence, get_vocab, embed_indexed_sequence, \\\n","    get_word2idx_idx2word, get_embedding_matrix, write_predictions, get_performance_VUAverb_val, \\\n","    get_performance_VUAverb_test, get_performance_VUA_test\n","from core.gao_files.sequence.util import TextDatasetWithGloveElmoSuffix as TextDataset\n","from core.gao_files.sequence.util import evaluate\n","from core.gao_files.sequence.model import RNNSequenceModel\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","\n","import csv\n","import h5py\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","import random\n","import ast"],"metadata":{"id":"_afdMRsLGvbE","executionInfo":{"status":"ok","timestamp":1646748704267,"user_tz":360,"elapsed":7455,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["print(\"PyTorch version:\")\n","print(torch.__version__)\n","print(\"GPU Detected:\")\n","print(torch.cuda.is_available())\n","using_GPU = torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ieNqFHMmJD2e","executionInfo":{"status":"ok","timestamp":1646748766143,"user_tz":360,"elapsed":263,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"bad41ea9-f73f-4560-cb78-efbc49b2f115"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch version:\n","1.10.0+cu111\n","GPU Detected:\n","True\n"]}]},{"cell_type":"code","source":["\"\"\"\n","1. Data pre-processing\n","\"\"\"\n","'''\n","1.1 VUA\n","get raw dataset as a list:\n","  Each element is a triple:\n","    a sentence: string\n","    a list of labels: \n","    a list of pos: \n","'''\n","pos_set = set()\n","raw_train_vua = []\n","with open(data_dir + 'VUAsequence/VUA_seq_formatted_train.csv', encoding='latin-1') as f:\n","    lines = csv.reader(f)\n","    next(lines)\n","    for line in lines:\n","        pos_seq = ast.literal_eval(line[4])\n","        label_seq = ast.literal_eval(line[3])\n","        assert (len(pos_seq) == len(label_seq))\n","        assert (len(line[2].split()) == len(pos_seq))\n","        raw_train_vua.append([line[2], label_seq, pos_seq])\n","        pos_set.update(pos_seq)\n","\n","raw_val_vua = []\n","with open(data_dir + 'VUAsequence/VUA_seq_formatted_val.csv', encoding='latin-1') as f:\n","    lines = csv.reader(f)\n","    next(lines)\n","    for line in lines:\n","        pos_seq = ast.literal_eval(line[4])\n","        label_seq = ast.literal_eval(line[3])\n","        assert (len(pos_seq) == len(label_seq))\n","        assert (len(line[2].split()) == len(pos_seq))\n","        raw_val_vua.append([line[2], label_seq, pos_seq])\n","        pos_set.update(pos_seq)\n","\n","# embed the pos tags\n","pos2idx, idx2pos = get_pos2idx_idx2pos(pos_set)\n","\n","for i in range(len(raw_train_vua)):\n","    raw_train_vua[i][2] = index_sequence(pos2idx, raw_train_vua[i][2])\n","for i in range(len(raw_val_vua)):\n","    raw_val_vua[i][2] = index_sequence(pos2idx, raw_val_vua[i][2])\n","print('size of training set, validation set: ', len(raw_train_vua), len(raw_val_vua))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ioy_FgUtJEtd","executionInfo":{"status":"ok","timestamp":1646748770785,"user_tz":360,"elapsed":1890,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"7503cf20-bf84-410c-bf20-79e4a66e5842"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["size of training set, validation set:  6323 1550\n"]}]},{"cell_type":"code","source":["raw_train_vua[:2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nxvg79gAKATq","executionInfo":{"status":"ok","timestamp":1646748779913,"user_tz":360,"elapsed":261,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"40eb8baf-9ce0-405a-c337-790f5d73f5dd"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[\"Ca n't fail to be entertaining .\",\n","  [0, 0, 0, 0, 0, 0, 0],\n","  [8, 9, 8, 14, 8, 13, 0]],\n"," ['How much was he going to tell her ?',\n","  [0, 0, 0, 0, 0, 0, 0, 0, 0],\n","  [9, 13, 8, 1, 8, 14, 8, 1, 0]]]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["\"\"\"\n","2. Data preparation\n","\"\"\"\n","'''\n","2. 1\n","get vocabulary and glove embeddings in raw dataset \n","'''\n","# vocab is a set of words\n","vocab = get_vocab(raw_train_vua)\n","# two dictionaries. <PAD>: 0, <UNK>: 1\n","word2idx, idx2word = get_word2idx_idx2word(vocab)\n","# glove_embeddings a nn.Embeddings\n","glove_embeddings = get_embedding_matrix(glove_dir + 'glove.840B.300d.txt',word2idx, idx2word, normalization=False)\n","# elmo_embeddings\n","elmos_train_vua = h5py.File(elmo_dir + 'VUA_train.hdf5', 'r')\n","elmos_val_vua = h5py.File(elmo_dir + 'VUA_val.hdf5', 'r')\n","# no suffix embeddings for sequence labeling\n","suffix_embeddings = None"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9cMKW8IIN0cK","executionInfo":{"status":"ok","timestamp":1646748911654,"user_tz":360,"elapsed":125643,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"7a4b24ba-9fb5-45e1-edaf-b0c2292b4065"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["vocab size:  13843\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2196017/2196017 [00:54<00:00, 40492.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of pre-trained word vectors loaded:  13404\n","Embeddings mean:  0.0005707233212888241\n","Embeddings stdev:  0.3729434907436371\n"]}]},{"cell_type":"code","source":["print(len(vocab))\n","glove_embeddings.weight.shape\n","# 300d embeddings for the 13843 words in the vocab"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Our2VVARSuO","executionInfo":{"status":"ok","timestamp":1646748915628,"user_tz":360,"elapsed":433,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"ec094a07-9234-4a86-c2c1-df4da8595c47"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["13843\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([13845, 300])"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["'''\n","2. 2\n","embed the datasets\n","'''\n","# raw_train_vua: sentence, label_seq, pos_seq\n","# embedded_train_vua: embedded_sentence, pos, labels\n","embedded_train_vua = [[embed_indexed_sequence(example[0], example[2], word2idx,\n","                                      glove_embeddings, elmos_train_vua, suffix_embeddings),\n","                       example[2], example[1]]\n","                      for example in raw_train_vua]\n","embedded_val_vua = [[embed_indexed_sequence(example[0], example[2], word2idx,\n","                                    glove_embeddings, elmos_val_vua, suffix_embeddings),\n","                     example[2], example[1]]\n","                    for example in raw_val_vua]"],"metadata":{"id":"Wd1OHrtRQte_","executionInfo":{"status":"ok","timestamp":1646748932959,"user_tz":360,"elapsed":14494,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# embedded_train_vua is a list of lists -- one list per sentence\n","# each sentence list contains \n","#     an array of embeddings (seq_length x embedding_dim)\n","#     list of pos tag ids\n","#     list of labels\n","print(len(embedded_train_vua))\n","print(len(embedded_train_vua[0]))\n","print(embedded_train_vua[0][0].shape)\n","print(embedded_train_vua[0][1])\n","print(embedded_train_vua[0][2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hf5VPoVXRylW","executionInfo":{"status":"ok","timestamp":1646748936983,"user_tz":360,"elapsed":245,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"3e73dee2-b587-4430-b53e-af2857ee9900"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["6323\n","3\n","(7, 1324)\n","[8, 9, 8, 14, 8, 13, 0]\n","[0, 0, 0, 0, 0, 0, 0]\n"]}]},{"cell_type":"code","source":["'''\n","2. 3\n","set up Dataloader for batching\n","'''\n","# Separate the input (embedded_sequence) and labels in the indexed train sets.\n","# embedded_train_vua: embedded_sentence, pos, labels\n","train_dataset_vua = TextDataset([example[0] for example in embedded_train_vua],\n","                                [example[1] for example in embedded_train_vua],\n","                                [example[2] for example in embedded_train_vua])\n","val_dataset_vua = TextDataset([example[0] for example in embedded_val_vua],\n","                              [example[1] for example in embedded_val_vua],\n","                              [example[2] for example in embedded_val_vua])\n","\n","# Data-related hyperparameters\n","batch_size = 64\n","# Set up a DataLoader for the training, validation, and test dataset\n","train_dataloader_vua = DataLoader(dataset=train_dataset_vua, batch_size=batch_size, shuffle=True,\n","                              collate_fn=TextDataset.collate_fn)\n","val_dataloader_vua = DataLoader(dataset=val_dataset_vua, batch_size=batch_size,\n","                            collate_fn=TextDataset.collate_fn)"],"metadata":{"id":"RC-GZBfvTKcU","executionInfo":{"status":"ok","timestamp":1646748943152,"user_tz":360,"elapsed":156,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","3. Model training\n","\"\"\"\n","'''\n","3. 1 \n","set up model, loss criterion, optimizer\n","'''\n","# Instantiate the model\n","# embedding_dim = glove + elmo + suffix indicator\n","# dropout1: dropout on input to RNN\n","# dropout2: dropout in RNN; would be used if num_layers!=1\n","# dropout3: dropout on hidden state of RNN to linear layer\n","RNNseq_model = RNNSequenceModel(num_classes=2, embedding_dim=300 + 1024, hidden_size=300, num_layers=1, bidir=True,\n","                                dropout1=0.5, dropout2=0, dropout3=0.1)\n","# Move the model to the GPU if available\n","if using_GPU:\n","    RNNseq_model = RNNseq_model.cuda()\n","# Set up criterion for calculating loss\n","loss_criterion = nn.NLLLoss()\n","# Set up an optimizer for updating the parameters of the rnn_clf\n","rnn_optimizer = optim.Adam(RNNseq_model.parameters(), lr=0.005)\n","# Number of epochs (passes through the dataset) to train the model for.\n","num_epochs = 10"],"metadata":{"id":"byfaN3-vUpPA","executionInfo":{"status":"ok","timestamp":1646748985485,"user_tz":360,"elapsed":11682,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["'''\n","3. 2\n","train model\n","'''\n","train_loss = []\n","val_loss = []\n","performance_matrix = None\n","val_f1s = []\n","train_f1s = []\n","# A counter for the number of gradient updates\n","num_iter = 0\n","comparable = []\n","for epoch in range(num_epochs):\n","    print(\"Starting epoch {}\".format(epoch + 1))\n","    for (__, example_text, example_lengths, labels) in train_dataloader_vua:\n","        example_text = Variable(example_text)\n","        example_lengths = Variable(example_lengths)\n","        labels = Variable(labels)\n","        if using_GPU:\n","            example_text = example_text.cuda()\n","            example_lengths = example_lengths.cuda()\n","            labels = labels.cuda()\n","        # predicted shape: (batch_size, seq_len, 2)\n","        predicted = RNNseq_model(example_text, example_lengths)\n","        batch_loss = loss_criterion(predicted.view(-1, 2), labels.view(-1))\n","        rnn_optimizer.zero_grad()\n","        batch_loss.backward()\n","        rnn_optimizer.step()\n","        num_iter += 1\n","        # Calculate validation and training set loss and accuracy every 200 gradient updates\n","        if num_iter % 200 == 0:\n","            avg_eval_loss, performance_matrix = evaluate(idx2pos, val_dataloader_vua, RNNseq_model,\n","                                                         loss_criterion, using_GPU)\n","            val_loss.append(avg_eval_loss)\n","            val_f1s.append(performance_matrix[:, 2])\n","            print(\"Iteration {}. Validation Loss {}.\".format(num_iter, avg_eval_loss))\n","#             avg_eval_loss, performance_matrix = evaluate(idx2pos, train_dataloader_vua, RNNseq_model,\n","#                                                          loss_criterion, using_GPU)\n","#             train_loss.append(avg_eval_loss)\n","#             train_f1s.append(performance_matrix[:, 2])\n","#             print(\"Iteration {}. Training Loss {}.\".format(num_iter, avg_eval_loss))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UZSKapN5XH1w","executionInfo":{"status":"ok","timestamp":1646749078119,"user_tz":360,"elapsed":44203,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"d5cee562-1e25-4263-afe2-5ae687b2ade8"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting epoch 1\n","Starting epoch 2\n","Starting epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:218: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  eval_text = Variable(eval_text, volatile=True)\n","/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:219: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  eval_lengths = Variable(eval_lengths, volatile=True)\n","/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:220: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  eval_labels = Variable(eval_labels, volatile=True)\n"]},{"output_type":"stream","name":"stdout","text":["------------------------------\n","total_eval_loss.shape torch.Size([])\n","PRFA performance for  PUNCT 75.0 60.0 66.66666666666667 99.92217898832685\n","PRFA performance for  PRON nan 0.0 nan 99.68609865470852\n","PRFA performance for  INTJ nan 0.0 nan 98.74213836477988\n","PRFA performance for  SYM nan nan nan 100.0\n","PRFA performance for  NOUN 80.9090909090909 38.44492440604752 52.12298682284041 90.46508237352384\n","PRFA performance for  PROPN 100.0 9.090909090909092 16.666666666666668 98.93276414087514\n","PRFA performance for  DET 84.30656934306569 92.4 88.16793893129771 98.2490821801751\n","PRFA performance for  X nan nan nan 100.0\n","PRFA performance for  VERB 66.33744855967078 60.149253731343286 63.09197651663404 86.8148769574944\n","PRFA performance for  ADV 61.458333333333336 38.311688311688314 47.2 94.07806191117093\n","PRFA performance for  CCONJ nan nan nan 100.0\n","PRFA performance for  NUM nan 0.0 nan 99.77272727272727\n","PRFA performance for  ADP 81.67883211678833 83.56982823002241 82.61351052048727 89.66198419666374\n","PRFA performance for  ADJ 64.94845360824742 36.627906976744185 46.84014869888476 91.09866168689697\n","PRFA performance for  PART 61.44578313253012 52.577319587628864 56.66666666666666 93.13984168865436\n","Iteration 200. Validation Loss 0.18829944729804993.\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:351: RuntimeWarning: invalid value encountered in double_scalars\n","  precision = 100 * grid[1, 1] / np.sum(grid[1])\n","/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:352: RuntimeWarning: invalid value encountered in double_scalars\n","  recall = 100 * grid[1, 1] / np.sum(grid[:, 1])\n"]},{"output_type":"stream","name":"stdout","text":["Starting epoch 4\n","Starting epoch 5\n","------------------------------\n","total_eval_loss.shape torch.Size([])\n","PRFA performance for  PUNCT 75.0 60.0 66.66666666666667 99.92217898832685\n","PRFA performance for  PRON 0.0 0.0 nan 99.64125560538116\n","PRFA performance for  INTJ nan 0.0 nan 98.74213836477988\n","PRFA performance for  SYM nan nan nan 100.0\n","PRFA performance for  NOUN 68.81188118811882 60.043196544276455 64.12918108419838 90.93162268552267\n","PRFA performance for  PROPN 66.66666666666667 18.181818181818183 28.57142857142857 98.93276414087514\n","PRFA performance for  DET 85.97785977859779 93.2 89.44337811900192 98.44676645015532\n","PRFA performance for  X nan nan nan 100.0\n","PRFA performance for  VERB 64.07307171853857 70.67164179104478 67.21078779276084 87.08053691275168\n","PRFA performance for  ADV 63.63636363636363 50.0 56.0 94.57155675190668\n","PRFA performance for  CCONJ 0.0 nan nan 99.92695398100804\n","PRFA performance for  NUM nan 0.0 nan 99.77272727272727\n","PRFA performance for  ADP 80.0701754385965 85.21284540702017 82.56150506512301 89.42054433713784\n","PRFA performance for  ADJ 58.38509316770186 54.651162790697676 56.45645645645646 90.97416744475568\n","PRFA performance for  PART 57.983193277310924 71.1340206185567 63.888888888888886 93.13984168865436\n","Iteration 400. Validation Loss 0.11298518627882004.\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:353: RuntimeWarning: invalid value encountered in double_scalars\n","  f1 = 2 * precision * recall / (precision + recall)\n"]},{"output_type":"stream","name":"stdout","text":["Starting epoch 6\n","Starting epoch 7\n","------------------------------\n","total_eval_loss.shape torch.Size([])\n","PRFA performance for  PUNCT 80.0 80.0 80.0 99.94811932555123\n","PRFA performance for  PRON 0.0 0.0 nan 99.64125560538116\n","PRFA performance for  INTJ nan 0.0 nan 98.74213836477988\n","PRFA performance for  SYM nan nan nan 100.0\n","PRFA performance for  NOUN 75.18573551263002 54.64362850971922 63.2895559724828 91.44190115177139\n","PRFA performance for  PROPN 71.42857142857143 22.727272727272727 34.48275862068965 98.98612593383137\n","PRFA performance for  DET 88.14229249011858 89.2 88.66799204771371 98.39028523016097\n","PRFA performance for  X nan nan nan 100.0\n","PRFA performance for  VERB 64.92434662998625 70.44776119402985 67.57337151037937 87.33221476510067\n","PRFA performance for  ADV 63.28125 52.5974025974026 57.4468085106383 94.6164199192463\n","PRFA performance for  CCONJ nan nan nan 100.0\n","PRFA performance for  NUM nan 0.0 nan 99.77272727272727\n","PRFA performance for  ADP 81.49466192170819 85.51157580283794 83.45481049562683 90.03511852502194\n","PRFA performance for  ADJ 57.72870662460568 53.19767441860465 55.37065052950075 90.81854964207905\n","PRFA performance for  PART 61.320754716981135 67.01030927835052 64.03940886699509 93.57959542656113\n","Iteration 600. Validation Loss 0.09230257570743561.\n","Starting epoch 8\n","Starting epoch 9\n","------------------------------\n","total_eval_loss.shape torch.Size([])\n","PRFA performance for  PUNCT 80.0 80.0 80.0 99.94811932555123\n","PRFA performance for  PRON nan 0.0 nan 99.68609865470852\n","PRFA performance for  INTJ 100.0 50.0 66.66666666666667 99.37106918238993\n","PRFA performance for  SYM nan nan nan 100.0\n","PRFA performance for  NOUN 72.08706786171575 60.79913606911447 65.96367896895137 91.52937746027118\n","PRFA performance for  PROPN 54.54545454545455 27.272727272727273 36.36363636363637 98.87940234791888\n","PRFA performance for  DET 85.18518518518519 92.0 88.46153846153847 98.30556340016945\n","PRFA performance for  X nan nan nan 100.0\n","PRFA performance for  VERB 62.27801592161666 75.8955223880597 68.41574167507568 86.87080536912751\n","PRFA performance for  ADV 60.294117647058826 53.246753246753244 56.55172413793104 94.34724091520862\n","PRFA performance for  CCONJ 0.0 nan nan 99.92695398100804\n","PRFA performance for  NUM nan 0.0 nan 99.77272727272727\n","PRFA performance for  ADP 81.54172560113155 86.1090365944735 83.76316745368689 90.18876207199298\n","PRFA performance for  ADJ 59.24764890282132 54.94186046511628 57.01357466063347 91.12978524743231\n","PRFA performance for  PART 62.71186440677966 76.28865979381443 68.83720930232558 94.10729991204926\n","Iteration 800. Validation Loss 0.086768738925457.\n","Starting epoch 10\n"]}]},{"cell_type":"code","source":["\"\"\"\n","for additional training\n","\"\"\"\n","rnn_optimizer = optim.Adam(RNNseq_model.parameters(), lr=0.0001)\n","for epoch in range(10):\n","    print(\"Starting epoch {}\".format(epoch + 1))\n","    for (__, example_text, example_lengths, labels) in train_dataloader_vua:\n","        example_text = Variable(example_text)\n","        example_lengths = Variable(example_lengths)\n","        labels = Variable(labels)\n","        if using_GPU:\n","            example_text = example_text.cuda()\n","            example_lengths = example_lengths.cuda()\n","            labels = labels.cuda()\n","        # predicted shape: (batch_size, seq_len, 2)\n","        predicted = RNNseq_model(example_text, example_lengths)\n","        batch_loss = loss_criterion(predicted.view(-1, 2), labels.view(-1))\n","        rnn_optimizer.zero_grad()\n","        batch_loss.backward()\n","        rnn_optimizer.step()\n","        num_iter += 1\n","        # Calculate validation and training set loss and accuracy every 200 gradient updates\n","        if num_iter % 200 == 0:\n","            avg_eval_loss, performance_matrix = evaluate(idx2pos, val_dataloader_vua, RNNseq_model,\n","                                                         loss_criterion, using_GPU)\n","            val_loss.append(avg_eval_loss)\n","            val_f1s.append(performance_matrix[:, 2])\n","            print(\"Iteration {}. Validation Loss {}.\".format(num_iter, avg_eval_loss))\n","\n","#             avg_eval_loss, performance_matrix = evaluate(idx2pos, train_dataloader_vua, RNNseq_model,\n","#                                                          loss_criterion, using_GPU)\n","#             train_loss.append(avg_eval_loss)\n","#             train_f1s.append(performance_matrix[:, 2])\n","#             print(\"Iteration {}. Training Loss {}.\".format(num_iter, avg_eval_loss))\n","#             comparable.append(get_performance())\n","\n","print(\"Training done!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eWoLULJhXqUl","executionInfo":{"status":"ok","timestamp":1646749142198,"user_tz":360,"elapsed":45702,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"10f4b711-a539-404a-8e04-92f4dbaf5de0"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:218: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  eval_text = Variable(eval_text, volatile=True)\n","/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:219: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  eval_lengths = Variable(eval_lengths, volatile=True)\n","/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:220: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  eval_labels = Variable(eval_labels, volatile=True)\n"]},{"output_type":"stream","name":"stdout","text":["------------------------------\n","total_eval_loss.shape torch.Size([])\n","PRFA performance for  PUNCT 80.0 80.0 80.0 99.94811932555123\n","PRFA performance for  PRON 0.0 0.0 nan 99.64125560538116\n","PRFA performance for  INTJ 100.0 50.0 66.66666666666667 99.37106918238993\n","PRFA performance for  SYM nan nan nan 100.0\n","PRFA performance for  NOUN 71.89119170984456 59.93520518358531 65.37102473498233 91.42732176702143\n","PRFA performance for  PROPN 54.54545454545455 27.272727272727273 36.36363636363637 98.87940234791888\n","PRFA performance for  DET 88.52459016393442 86.4 87.4493927125506 98.2490821801751\n","PRFA performance for  X nan nan nan 100.0\n","PRFA performance for  VERB 65.98984771573605 67.91044776119404 66.93637366678928 87.43008948545861\n","PRFA performance for  ADV 60.15625 50.0 54.60992907801418 94.25751458052939\n","PRFA performance for  CCONJ 0.0 nan nan 99.92695398100804\n","PRFA performance for  NUM nan 0.0 nan 99.77272727272727\n","PRFA performance for  ADP 84.35171385991057 84.54070201643017 84.44610220067139 90.84723441615452\n","PRFA performance for  ADJ 59.80392156862745 53.19767441860465 56.30769230769231 91.16090880796763\n","PRFA performance for  PART 61.53846153846154 57.7319587628866 59.57446808510638 93.31574318381706\n","Iteration 1000. Validation Loss 0.08277726918458939.\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:353: RuntimeWarning: invalid value encountered in double_scalars\n","  f1 = 2 * precision * recall / (precision + recall)\n","/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:351: RuntimeWarning: invalid value encountered in double_scalars\n","  precision = 100 * grid[1, 1] / np.sum(grid[1])\n","/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:352: RuntimeWarning: invalid value encountered in double_scalars\n","  recall = 100 * grid[1, 1] / np.sum(grid[:, 1])\n"]},{"output_type":"stream","name":"stdout","text":["Starting epoch 2\n","Starting epoch 3\n","------------------------------\n","total_eval_loss.shape torch.Size([])\n","PRFA performance for  PUNCT 80.0 80.0 80.0 99.94811932555123\n","PRFA performance for  PRON 0.0 0.0 nan 99.64125560538116\n","PRFA performance for  INTJ 100.0 50.0 66.66666666666667 99.37106918238993\n","PRFA performance for  SYM nan nan nan 100.0\n","PRFA performance for  NOUN 69.92753623188406 62.52699784017279 66.02052451539339 91.31068668902172\n","PRFA performance for  PROPN 58.333333333333336 31.818181818181817 41.17647058823529 98.93276414087514\n","PRFA performance for  DET 87.73946360153256 91.6 89.62818003913895 98.50324767014968\n","PRFA performance for  X nan nan nan 100.0\n","PRFA performance for  VERB 64.31893687707641 72.23880597014926 68.04920913884008 87.29026845637584\n","PRFA performance for  ADV 61.19402985074627 53.246753246753244 56.944444444444436 94.43696724988784\n","PRFA performance for  CCONJ 0.0 nan nan 99.92695398100804\n","PRFA performance for  NUM nan 0.0 nan 99.77272727272727\n","PRFA performance for  ADP 83.44274252370532 85.4368932038835 84.42804428044279 90.73748902546093\n","PRFA performance for  ADJ 55.84045584045584 56.97674418604651 56.402877697841724 90.56956115779646\n","PRFA performance for  PART 61.386138613861384 63.91752577319588 62.62626262626262 93.49164467897977\n","Iteration 1200. Validation Loss 0.08280321210622787.\n","Starting epoch 4\n","Starting epoch 5\n","------------------------------\n","total_eval_loss.shape torch.Size([])\n","PRFA performance for  PUNCT 80.0 80.0 80.0 99.94811932555123\n","PRFA performance for  PRON 0.0 0.0 nan 99.64125560538116\n","PRFA performance for  INTJ 100.0 50.0 66.66666666666667 99.37106918238993\n","PRFA performance for  SYM nan nan nan 100.0\n","PRFA performance for  NOUN 70.91584158415841 61.879049676025915 66.08996539792388 91.42732176702143\n","PRFA performance for  PROPN 58.333333333333336 31.818181818181817 41.17647058823529 98.93276414087514\n","PRFA performance for  DET 88.07692307692308 91.6 89.80392156862746 98.53148828014685\n","PRFA performance for  X nan nan nan 100.0\n","PRFA performance for  VERB 65.05376344086021 72.23880597014926 68.45827439886844 87.52796420581656\n","PRFA performance for  ADV 61.19402985074627 53.246753246753244 56.944444444444436 94.43696724988784\n","PRFA performance for  CCONJ 0.0 nan nan 99.92695398100804\n","PRFA performance for  NUM nan 0.0 nan 99.77272727272727\n","PRFA performance for  ADP 83.97951719092904 85.73562359970127 84.84848484848486 91.00087796312555\n","PRFA performance for  ADJ 56.25 57.55813953488372 56.896551724137936 90.66293183940243\n","PRFA performance for  PART 61.76470588235294 64.94845360824742 63.31658291457286 93.57959542656113\n","Iteration 1400. Validation Loss 0.08240673691034317.\n","Starting epoch 6\n","Starting epoch 7\n","------------------------------\n","total_eval_loss.shape torch.Size([])\n","PRFA performance for  PUNCT 80.0 80.0 80.0 99.94811932555123\n","PRFA performance for  PRON 0.0 0.0 nan 99.64125560538116\n","PRFA performance for  INTJ 100.0 50.0 66.66666666666667 99.37106918238993\n","PRFA performance for  SYM nan nan nan 100.0\n","PRFA performance for  NOUN 70.24096385542168 62.95896328293737 66.40091116173122 91.39816299752151\n","PRFA performance for  PROPN 58.333333333333336 31.818181818181817 41.17647058823529 98.93276414087514\n","PRFA performance for  DET 88.37209302325581 91.2 89.76377952755905 98.53148828014685\n","PRFA performance for  X nan nan nan 100.0\n","PRFA performance for  VERB 64.70198675496688 72.91044776119404 68.56140350877193 87.47203579418344\n","PRFA performance for  ADV 62.40601503759399 53.896103896103895 57.8397212543554 94.57155675190668\n","PRFA performance for  CCONJ 0.0 nan nan 99.92695398100804\n","PRFA performance for  NUM nan 0.0 nan 99.77272727272727\n","PRFA performance for  ADP 83.7345003646973 85.73562359970127 84.72324723247232 90.91308165057067\n","PRFA performance for  ADJ 56.25 57.55813953488372 56.896551724137936 90.66293183940243\n","PRFA performance for  PART 60.18518518518518 67.01030927835052 63.41463414634146 93.40369393139842\n","Iteration 1600. Validation Loss 0.08254442363977432.\n","Starting epoch 8\n","Starting epoch 9\n","------------------------------\n","total_eval_loss.shape torch.Size([])\n","PRFA performance for  PUNCT 80.0 80.0 80.0 99.94811932555123\n","PRFA performance for  PRON 0.0 0.0 nan 99.64125560538116\n","PRFA performance for  INTJ 100.0 50.0 66.66666666666667 99.37106918238993\n","PRFA performance for  SYM nan nan nan 100.0\n","PRFA performance for  NOUN 70.53892215568862 63.60691144708424 66.89381033503692 91.50021869077125\n","PRFA performance for  PROPN 58.333333333333336 31.818181818181817 41.17647058823529 98.93276414087514\n","PRFA performance for  DET 88.07692307692308 91.6 89.80392156862746 98.53148828014685\n","PRFA performance for  X nan nan nan 100.0\n","PRFA performance for  VERB 64.60526315789474 73.28358208955224 68.67132867132868 87.47203579418344\n","PRFA performance for  ADV 62.31884057971015 55.84415584415584 58.90410958904109 94.6164199192463\n","PRFA performance for  CCONJ 0.0 nan nan 99.92695398100804\n","PRFA performance for  NUM nan 0.0 nan 99.77272727272727\n","PRFA performance for  ADP 82.97258297258297 85.88498879761016 84.40366972477064 90.67164179104478\n","PRFA performance for  ADJ 55.182072829131656 57.26744186046512 56.205420827389446 90.44506691565515\n","PRFA performance for  PART 62.280701754385966 73.19587628865979 67.29857819905213 93.93139841688654\n","Iteration 1800. Validation Loss 0.08272161334753036.\n","Starting epoch 10\n","Training done!\n"]}]},{"cell_type":"code","source":["\"\"\"\n","test on genres by POS tags\n","\"\"\"\n","print(\"**********************************************************\")\n","print(\"Evalutation on test set: \")\n","\n","raw_test_vua = []\n","with open(data_dir + 'VUAsequence/VUA_seq_formatted_test.csv', encoding='latin-1') as f:\n","    lines = csv.reader(f)\n","    next(lines)\n","    for line in lines:\n","        # txt_id\tsen_ix\tsentence\tlabel_seq\tpos_seq\tlabeled_sentence\tgenre\n","        pos_seq = ast.literal_eval(line[4])\n","        label_seq = ast.literal_eval(line[3])\n","        assert(len(pos_seq) == len(label_seq))\n","        assert(len(line[2].split()) == len(pos_seq))\n","        raw_test_vua.append([line[2], label_seq, pos_seq])\n","print('number of examples(sentences) for test_set ', len(raw_test_vua))\n","\n","for i in range(len(raw_test_vua)):\n","    raw_test_vua[i][2] = index_sequence(pos2idx, raw_test_vua[i][2])\n","\n","elmos_test_vua = h5py.File(elmo_dir + 'VUA_test.hdf5', 'r')\n","# raw_train_vua: sentence, label_seq, pos_seq\n","# embedded_train_vua: embedded_sentence, pos, labels\n","embedded_test_vua = [[embed_indexed_sequence(example[0], example[2], word2idx,\n","                                      glove_embeddings, elmos_test_vua, suffix_embeddings),\n","                       example[2], example[1]]\n","                      for example in raw_test_vua]\n","\n","# Separate the input (embedded_sequence) and labels in the indexed train sets.\n","# embedded_train_vua: embedded_sentence, pos, labels\n","test_dataset_vua = TextDataset([example[0] for example in embedded_test_vua],\n","                              [example[1] for example in embedded_test_vua],\n","                              [example[2] for example in embedded_test_vua])\n","\n","# Set up a DataLoader for the test dataset\n","test_dataloader_vua = DataLoader(dataset=test_dataset_vua, batch_size=batch_size,\n","                              collate_fn=TextDataset.collate_fn)\n","\n","print(\"Tagging model performance on VUA test set by POS tags: regardless of genres\")\n","avg_eval_loss, pos_performance_matrix = evaluate(idx2pos, test_dataloader_vua, RNNseq_model, loss_criterion, using_GPU)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W2TGxriudWOI","executionInfo":{"status":"ok","timestamp":1646751706575,"user_tz":360,"elapsed":5543,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"e7564ee3-226b-4d04-9015-90fd75663c55"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["**********************************************************\n","Evalutation on test set: \n","number of examples(sentences) for test_set  2694\n","Tagging model performance on VUA test set by POS tags: regardless of genres\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:218: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  eval_text = Variable(eval_text, volatile=True)\n","/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:219: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  eval_lengths = Variable(eval_lengths, volatile=True)\n","/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:220: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  eval_labels = Variable(eval_labels, volatile=True)\n"]},{"output_type":"stream","name":"stdout","text":["------------------------------\n","total_eval_loss.shape torch.Size([])\n","PRFA performance for  PUNCT 50.0 33.333333333333336 40.0 99.94099134539732\n","PRFA performance for  PRON nan 0.0 nan 99.84829329962074\n","PRFA performance for  INTJ 100.0 50.0 66.66666666666667 99.74874371859296\n","PRFA performance for  SYM nan nan nan 100.0\n","PRFA performance for  NOUN 68.02906448683015 58.01704105344694 62.625418060200666 89.59012575687005\n","PRFA performance for  PROPN 50.0 12.903225806451612 20.51282051282051 98.37270341207349\n","PRFA performance for  DET 89.61625282167043 94.74940334128878 92.11136890951276 98.34871296745993\n","PRFA performance for  X nan nan nan 100.0\n","PRFA performance for  VERB 68.26625386996903 70.11128775834658 69.17647058823529 88.05713128038897\n","PRFA performance for  ADV 67.6056338028169 59.01639344262295 63.01969365426695 95.01915708812261\n","PRFA performance for  CCONJ nan nan nan 100.0\n","PRFA performance for  NUM nan nan nan 100.0\n","PRFA performance for  ADP 88.08259587020649 89.40119760479043 88.73699851411591 92.84905660377359\n","PRFA performance for  ADJ 61.46435452793834 58.96487985212569 60.18867924528301 89.35687263556116\n","PRFA performance for  PART 56.774193548387096 59.060402684563755 57.89473684210527 91.25085440874915\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:351: RuntimeWarning: invalid value encountered in double_scalars\n","  precision = 100 * grid[1, 1] / np.sum(grid[1])\n","/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:352: RuntimeWarning: invalid value encountered in double_scalars\n","  recall = 100 * grid[1, 1] / np.sum(grid[:, 1])\n"]}]},{"cell_type":"code","source":["print(\"Breakdown of performance on the VUA sequence labeling test set by POS tags: \")\n","pd.DataFrame(pos_performance_matrix[[8,4,12,13,14],:], columns = [\"Pr\", \"Re\",\"F1\",\"Acc\"],\n","             index=[\"VERB\",\"NOUN\",\"ADP\",\"ADJ\",\"PART\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"LfUdaROnBw4x","executionInfo":{"status":"ok","timestamp":1646751883596,"user_tz":360,"elapsed":172,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"02924b37-d659-40d5-b1fc-b28b8ae018d1"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Breakdown of performance on the VUA sequence labeling test set by POS tags: \n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-c9430066-5b66-4cad-ad9b-2dab67ee3c0b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pr</th>\n","      <th>Re</th>\n","      <th>F1</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>VERB</th>\n","      <td>68.266254</td>\n","      <td>70.111288</td>\n","      <td>69.176471</td>\n","      <td>88.057131</td>\n","    </tr>\n","    <tr>\n","      <th>NOUN</th>\n","      <td>68.029064</td>\n","      <td>58.017041</td>\n","      <td>62.625418</td>\n","      <td>89.590126</td>\n","    </tr>\n","    <tr>\n","      <th>ADP</th>\n","      <td>88.082596</td>\n","      <td>89.401198</td>\n","      <td>88.736999</td>\n","      <td>92.849057</td>\n","    </tr>\n","    <tr>\n","      <th>ADJ</th>\n","      <td>61.464355</td>\n","      <td>58.964880</td>\n","      <td>60.188679</td>\n","      <td>89.356873</td>\n","    </tr>\n","    <tr>\n","      <th>PART</th>\n","      <td>56.774194</td>\n","      <td>59.060403</td>\n","      <td>57.894737</td>\n","      <td>91.250854</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9430066-5b66-4cad-ad9b-2dab67ee3c0b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c9430066-5b66-4cad-ad9b-2dab67ee3c0b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c9430066-5b66-4cad-ad9b-2dab67ee3c0b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["             Pr         Re         F1        Acc\n","VERB  68.266254  70.111288  69.176471  88.057131\n","NOUN  68.029064  58.017041  62.625418  89.590126\n","ADP   88.082596  89.401198  88.736999  92.849057\n","ADJ   61.464355  58.964880  60.188679  89.356873\n","PART  56.774194  59.060403  57.894737  91.250854"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["seq_test_pred = write_predictions(raw_test_vua, test_dataloader_vua, RNNseq_model, using_GPU, data_dir + 'VUAsequence/VUA_seq_formatted_test.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vvs0NRVRPEhQ","executionInfo":{"status":"ok","timestamp":1646749718079,"user_tz":360,"elapsed":1411,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"b5496114-5220-4f5d-eab1-16338f5ab885"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:304: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  eval_text = Variable(eval_text, volatile=True)\n","/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:305: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  eval_lengths = Variable(eval_lengths, volatile=True)\n","/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/sequence/util.py:306: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  eval_labels = Variable(eval_labels, volatile=True)\n"]}]},{"cell_type":"code","source":["seq_test_pred[0:2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pJ6Sb_2zV3_U","executionInfo":{"status":"ok","timestamp":1646749722099,"user_tz":360,"elapsed":161,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"31bc7ffd-1e85-46e1-d9bd-78184da52241"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['txt_id',\n","  'sen_ix',\n","  'sentence',\n","  'label_seq',\n","  'pos_seq',\n","  'labeled_sentence',\n","  'genre',\n","  'prediction'],\n"," ['a3m-fragment02',\n","  '45',\n","  'Design : Crossed lines over the toytown tram : City transport could soon be back on the right track , says Jonathan Glancey',\n","  '[0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0]',\n","  \"['NOUN', 'PUNCT', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT', 'NOUN', 'NOUN', 'VERB', 'ADV', 'VERB', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT', 'VERB', 'PROPN', 'PROPN']\",\n","  'Design : M_Crossed M_lines M_over the toytown tram : City transport could soon be M_back M_on the right M_track , says Jonathan Glancey',\n","  'news',\n","  [tensor(0, device='cuda:0'),\n","   tensor(0, device='cuda:0'),\n","   tensor(1, device='cuda:0'),\n","   tensor(1, device='cuda:0'),\n","   tensor(0, device='cuda:0'),\n","   tensor(0, device='cuda:0'),\n","   tensor(0, device='cuda:0'),\n","   tensor(0, device='cuda:0'),\n","   tensor(0, device='cuda:0'),\n","   tensor(0, device='cuda:0'),\n","   tensor(0, device='cuda:0'),\n","   tensor(0, device='cuda:0'),\n","   tensor(0, device='cuda:0'),\n","   tensor(0, device='cuda:0'),\n","   tensor(1, device='cuda:0'),\n","   tensor(1, device='cuda:0'),\n","   tensor(0, device='cuda:0'),\n","   tensor(0, device='cuda:0'),\n","   tensor(1, device='cuda:0'),\n","   tensor(0, device='cuda:0'),\n","   tensor(0, device='cuda:0'),\n","   tensor(0, device='cuda:0'),\n","   tensor(0, device='cuda:0')]]]"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["get_performance_VUAverb_test(data_dir,seq_test_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9sai71hPYfjC","executionInfo":{"status":"ok","timestamp":1646749729798,"user_tz":360,"elapsed":1365,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"48a99e05-3e6e-4278-f1c5-c734475584d4"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Tagging model performance on test-verb: genre\n","news Precision, Recall, F1, Accuracy:  73.51351351351352 72.98747763864043 73.24955116696589 75.7328990228013\n","fiction Precision, Recall, F1, Accuracy:  56.56565656565657 61.53846153846154 58.94736842105264 83.10469314079423\n","academic Precision, Recall, F1, Accuracy:  73.42143906020559 78.36990595611286 75.81501137225172 74.66243050039714\n","conversation Precision, Recall, F1, Accuracy:  56.22641509433962 51.202749140893474 53.59712230215828 87.10644677661169\n","Tagging model performance on test-verb: regardless of genre\n","Precision, Recall, F1, Accuracy:  68.13125695216908 69.56274843838727 68.8395616746277 81.116975991827\n"]},{"output_type":"execute_result","data":{"text/plain":["array([64.93175606, 66.02464857, 65.40226332, 80.15161736])"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["#macro-averaged F1 score across four genres\n","maF1 = (73.2495 + 58.9473 + 75.8150 + 53.5971) / 4\n","maF1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xev03Cge8X5M","executionInfo":{"status":"ok","timestamp":1646750004006,"user_tz":360,"elapsed":121,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"3d987f9d-0246-49e7-ad43-90423860c080"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["65.402225"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["get_performance_VUA_test(data_dir,seq_test_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wClBEkdodUTx","executionInfo":{"status":"ok","timestamp":1646749869624,"user_tz":360,"elapsed":918,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"d01d0cc8-e38a-4660-ca71-cfea04a0c3d8"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Tagging model performance on test-sequence: genre\n","news Precision, Recall, F1, Accuracy:  77.24056603773585 69.97863247863248 73.4304932735426 92.3076923076923\n","fiction Precision, Recall, F1, Accuracy:  66.57088122605364 68.54043392504931 67.54130223517978 93.9084442823272\n","academic Precision, Recall, F1, Accuracy:  79.60582690659811 78.99659863945578 79.30004268032437 92.87550495776716\n","conversation Precision, Recall, F1, Accuracy:  65.53446553446554 65.27363184079601 65.40378863409771 94.77015825169555\n","Tagging model performance on test-sequence: regardless of genre\n","Precision, Recall, F1, Accuracy:  74.38683127572017 72.38507127983341 73.37230069816528 93.46287992027902\n"]},{"output_type":"execute_result","data":{"text/plain":["array([72.23793493, 70.69732422, 71.41890671, 93.46544995])"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["import pandas as pd\n","gao_scores_verb = [68.2, 71.3, 69.7, 81.4, 66.4]\n","our_scores_verb = [68.0, 68.3, 68.2, 80.9, 65.4]\n","our_scores_verb = [round(score,1) for score in our_scores_verb]\n","all_scores_verb = [gao_scores_verb, our_scores_verb]\n","all_scores_verb_df = pd.DataFrame(all_scores_verb, columns= ['P', 'R', 'F1', 'Acc', 'MaF1'], index=['Gao et al', 'US'])\n","print(\"VUA seq model: classification task\\n\")\n","all_scores_verb_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":147},"id":"Ynfg8ciAiipC","executionInfo":{"status":"ok","timestamp":1646750057099,"user_tz":360,"elapsed":139,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"bb9be872-6c24-4f82-8650-b52f1e2a3f9d"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["VUA seq model: classification task\n","\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-5600c6fa-d9d8-407e-8ade-c7be7beaebb2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>P</th>\n","      <th>R</th>\n","      <th>F1</th>\n","      <th>Acc</th>\n","      <th>MaF1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Gao et al</th>\n","      <td>68.2</td>\n","      <td>71.3</td>\n","      <td>69.7</td>\n","      <td>81.4</td>\n","      <td>66.4</td>\n","    </tr>\n","    <tr>\n","      <th>US</th>\n","      <td>68.0</td>\n","      <td>68.3</td>\n","      <td>68.2</td>\n","      <td>80.9</td>\n","      <td>65.4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5600c6fa-d9d8-407e-8ade-c7be7beaebb2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5600c6fa-d9d8-407e-8ade-c7be7beaebb2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5600c6fa-d9d8-407e-8ade-c7be7beaebb2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["              P     R    F1   Acc  MaF1\n","Gao et al  68.2  71.3  69.7  81.4  66.4\n","US         68.0  68.3  68.2  80.9  65.4"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["!g"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y162RSxLmZPM","executionInfo":{"status":"ok","timestamp":1646751142343,"user_tz":360,"elapsed":690,"user":{"displayName":"Cole Frank","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02198055664829140597"}},"outputId":"f80141ae-2ff7-45c7-a845-9e88e4c84a9d"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","\t\u001b[31mmodified:   notebooks/sequence/replicate_vua_seq_model_for_classification.ipynb\u001b[m\n","\n","no changes added to commit\n"]}]}]}