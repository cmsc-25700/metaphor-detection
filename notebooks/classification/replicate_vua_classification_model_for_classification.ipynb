{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"replicate_vua_classification_model_for_classification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN30f7CkawxfC6zsd/+yvAn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["##Code for replicating gao et al research on VUA Classifcation Model"],"metadata":{"id":"CJ0nenviLc-B"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RqqkYmRiKiGt","executionInfo":{"status":"ok","timestamp":1646889853485,"user_tz":360,"elapsed":17502,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"4576a8cc-a8b1-4fd4-8881-cfc88335141b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# mount drive\n","from google.colab import drive\n","ROOT = '/content/drive'\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# add repo directory to path\n","import os\n","import sys\n","from os.path import join \n","repo_dir = '/content/drive/MyDrive/Repos/metaphor-detection'\n","if repo_dir not in sys.path:\n","    sys.path.append(repo_dir)\n","print(sys.path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndu2cHtHMpUO","executionInfo":{"status":"ok","timestamp":1646889853486,"user_tz":360,"elapsed":10,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"2dc6af9b-5f9f-4bbc-9089-d17e62cacd1f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["['', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/MyDrive/Repos/metaphor-detection']\n"]}]},{"cell_type":"code","source":["import random\n","random.seed(0)"],"metadata":{"id":"ylCvvHVuwslG","executionInfo":{"status":"ok","timestamp":1646889853486,"user_tz":360,"elapsed":6,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# pip install requirements (takes a while)\n","!cd drive/MyDrive/Repos/metaphor-detection/; pip install -r gao-g-requirements.txt\n","!pip install --upgrade google-cloud-storage"],"metadata":{"id":"4u9n8pNmMsDd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from core.gao_files.classification.util import get_num_lines, get_vocab, embed_sequence, get_word2idx_idx2word, get_embedding_matrix\n","from core.gao_files.classification.util  import TextDatasetWithGloveElmoSuffix as TextDataset\n","from core.gao_files.classification.util  import evaluate, write_predictions\n","from core.gao_files.classification.model import RNNSequenceClassifier\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","\n","import csv\n","import h5py\n","# import matplotlib\n","# matplotlib.use('Agg')  # to avoid the error: _tkinter.TclError: no display name and no $DISPLAY environment variable\n","# matplotlib.use('tkagg') # to display the graph on remote server\n","import matplotlib.pyplot as plt\n","import pandas as pd"],"metadata":{"id":"43yxdso-N2Xa","executionInfo":{"status":"ok","timestamp":1646889953909,"user_tz":360,"elapsed":9716,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["print(\"PyTorch version:\")\n","print(torch.__version__)\n","print(\"GPU Detected:\")\n","print(torch.cuda.is_available())\n","using_GPU = torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucPMqD95PBB4","executionInfo":{"status":"ok","timestamp":1646889953909,"user_tz":360,"elapsed":9,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"650a62b3-5dbb-41e3-dab6-31d4de59a332"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch version:\n","1.10.0+cu111\n","GPU Detected:\n","True\n"]}]},{"cell_type":"code","source":["# directories\n","# to download glove and elmo vectors see: notebooks/Download_large_data.ipynb\n","data_dir = repo_dir + '/resources/metaphor-in-context/data/'\n","glove_dir = repo_dir + '/resources/glove/'\n","elmo_dir = repo_dir + '/resources/elmo/'"],"metadata":{"id":"C24CjkKTQjx6","executionInfo":{"status":"ok","timestamp":1646889953910,"user_tz":360,"elapsed":7,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### Gao code"],"metadata":{"id":"WM1uHe5zQk49"}},{"cell_type":"code","source":["\"\"\"\n","1. Data pre-processing\n","\"\"\"\n","'''\n","1.1 VUA\n","get raw dataset as a list:\n","  Each element is a triple:\n","    a sentence: string\n","    a index: int: idx of the focus verb\n","    a label: int 1 or 0\n","'''\n","raw_train_vua = []\n","with open(data_dir + 'VUA/VUA_formatted_train.csv', encoding='latin-1') as f:\n","    lines = csv.reader(f)\n","    next(lines)\n","    for line in lines:\n","        raw_train_vua.append([line[3], int(line[4]), int(line[5])])\n","\n","raw_val_vua = []\n","with open(data_dir+ 'VUA/VUA_formatted_val.csv', encoding='latin-1') as f:\n","    lines = csv.reader(f)\n","    next(lines)\n","    for line in lines:\n","        raw_val_vua.append([line[3], int(line[4]), int(line[5])])\n","\n","raw_test_vua = []\n","with open(data_dir+ 'VUA/VUA_formatted_test.csv', encoding='latin-1') as f:\n","    lines = csv.reader(f)\n","    next(lines)\n","    for line in lines:\n","        raw_test_vua.append([line[3], int(line[4]), int(line[5])])\n","print('VUA dataset division: ', '\\ntrain:', len(raw_train_vua), '\\nval:',len(raw_val_vua), '\\ntest:',len(raw_test_vua))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6CTsaxXqPK2A","executionInfo":{"status":"ok","timestamp":1646889955792,"user_tz":360,"elapsed":1889,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"884e8739-070e-46cb-df6d-a5f80f2c2a01"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["VUA dataset division:  \n","train: 15516 \n","val: 1724 \n","test: 5873\n"]}]},{"cell_type":"code","source":["\"\"\"\n","2. Data preparation\n","\"\"\"\n","'''\n","2. 1\n","get vocabulary and glove embeddings in raw dataset \n","'''\n","# vocab is a set of words\n","vocab = get_vocab(raw_train_vua + raw_val_vua + raw_test_vua)\n","# two dictionaries. <PAD>: 0, <UNK>: 1\n","word2idx, idx2word = get_word2idx_idx2word(vocab)\n","# glove_embeddings a nn.Embeddings\n","glove_embeddings = get_embedding_matrix(glove_dir + 'glove.840B.300d.txt', word2idx, idx2word, normalization=False)\n","# elmo_embeddings\n","elmos_train_vua = h5py.File(elmo_dir + 'VUA_train.hdf5', 'r')\n","elmos_val_vua = h5py.File(elmo_dir + 'VUA_val.hdf5', 'r')\n","# suffix_embeddings: number of suffix tag is 2, and the suffix embedding dimension is 50\n","suffix_embeddings = nn.Embedding(2, 50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ao866hZRD3c","executionInfo":{"status":"ok","timestamp":1646890084144,"user_tz":360,"elapsed":128360,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"2151cf31-9905-449d-8c71-96c4fff504e6"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["vocab size:  18695\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2196017/2196017 [00:51<00:00, 43029.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of pre-trained word vectors loaded:  17941\n","Embeddings mean:  -0.0001772342948243022\n","Embeddings stdev:  0.37537267804145813\n"]}]},{"cell_type":"code","source":["'''\n","2. 2\n","embed the datasets\n","'''\n","embedded_train_vua = [[embed_sequence(example[0], example[1], word2idx,\n","                                      glove_embeddings, elmos_train_vua, suffix_embeddings), example[2]]\n","                      for example in raw_train_vua]\n","embedded_val_vua = [[embed_sequence(example[0], example[1], word2idx,\n","                                    glove_embeddings, elmos_val_vua, suffix_embeddings), example[2]]\n","                    for example in raw_val_vua]"],"metadata":{"id":"xO5F1t8OSIIl","executionInfo":{"status":"ok","timestamp":1646890100867,"user_tz":360,"elapsed":16736,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["'''\n","2. 3\n","set up Dataloader for batching\n","'''\n","# Separate the input (embedded_sequence) and labels in the indexed train sets.\n","train_dataset_vua = TextDataset([example[0] for example in embedded_train_vua],\n","                                [example[1] for example in embedded_train_vua])\n","val_dataset_vua = TextDataset([example[0] for example in embedded_val_vua],\n","                              [example[1] for example in embedded_val_vua])\n","\n","# Data-related hyperparameters\n","batch_size = 64\n","# Set up a DataLoader for the training, validation, and test dataset\n","train_dataloader_vua = DataLoader(dataset=train_dataset_vua, batch_size=batch_size, shuffle=True,\n","                                  collate_fn=TextDataset.collate_fn)\n","val_dataloader_vua = DataLoader(dataset=val_dataset_vua, batch_size=batch_size,\n","                                collate_fn=TextDataset.collate_fn)"],"metadata":{"id":"r54zwdEGTHb4","executionInfo":{"status":"ok","timestamp":1646890100868,"user_tz":360,"elapsed":4,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","3. Model training\n","\"\"\"\n","'''\n","3. 1 \n","set up model, loss criterion, optimizer\n","'''\n","# Instantiate the model\n","# embedding_dim = glove + elmo + suffix indicator\n","# dropout1: dropout on input to RNN\n","# dropout2: dropout in RNN; would be used if num_layers=1\n","# dropout3: dropout on hidden state of RNN to linear layer\n","rnn_clf = RNNSequenceClassifier(num_classes=2, embedding_dim=300 + 1024 + 50, hidden_size=300, num_layers=1, bidir=True,\n","                                dropout1=0.3, dropout2=0.2, dropout3=0.2)\n","# Move the model to the GPU if available\n","if using_GPU:\n","    rnn_clf = rnn_clf.cuda()\n","# Set up criterion for calculating loss\n","nll_criterion = nn.NLLLoss()\n","# Set up an optimizer for updating the parameters of the rnn_clf\n","rnn_clf_optimizer = optim.SGD(rnn_clf.parameters(), lr=0.01,momentum=0.9)\n","# Number of epochs (passes through the dataset) to train the model for.\n","num_epochs = 20"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RHshluSiTK7K","executionInfo":{"status":"ok","timestamp":1646890109386,"user_tz":360,"elapsed":8521,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"34dec3b7-4839-4e6a-9793-397bd73090f5"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]}]},{"cell_type":"code","source":["'''\n","3. 2\n","train model\n","'''\n","training_loss = []\n","val_loss = []\n","\n","training_f1 = []\n","val_f1 = []\n","\n","training_accuracy = []\n","val_accuracy = []\n","\n","training_precision = []\n","val_precision = []\n","\n","training_recall = []\n","val_recall = []\n","\n","training_fus_f1 = []\n","val_fus_f1 = []\n","\n","# A counter for the number of gradient updates\n","num_iter = 0\n","for epoch in range(num_epochs):\n","    print(\"Starting epoch {}\".format(epoch + 1))\n","    for (example_text, example_lengths, labels) in train_dataloader_vua:\n","        example_text = Variable(example_text)\n","        example_lengths = Variable(example_lengths)\n","        labels = Variable(labels)\n","        if using_GPU:\n","            example_text = example_text.cuda()\n","            example_lengths = example_lengths.cuda()\n","            labels = labels.cuda()\n","        # predicted shape: (batch_size, 2)\n","        predicted = rnn_clf(example_text, example_lengths)\n","        batch_loss = nll_criterion(predicted, labels)\n","        rnn_clf_optimizer.zero_grad()\n","        batch_loss.backward()\n","        rnn_clf_optimizer.step()\n","        num_iter += 1\n","        # Calculate validation and training set loss and accuracy every 200 gradient updates\n","        if num_iter % 200 == 0:\n","            avg_eval_loss, eval_accuracy, precision, recall, f1, fus_f1 = evaluate(val_dataloader_vua, rnn_clf,\n","                                                                                   nll_criterion, using_GPU, print_verbose=False)\n","            val_loss.append(avg_eval_loss)\n","            val_f1.append(f1)\n","            val_accuracy.append(eval_accuracy)\n","            val_precision.append(precision)\n","            val_recall.append(recall)\n","            val_fus_f1.append(fus_f1)\n","\n","            # print metrics less often\n","            print(\n","                  \"Iteration {}. Validation Loss {}. Validation Accuracy {}. Validation Precision {}. Validation Recall {}. Validation F1 {}. Validation class-wise F1 {}.\".format(\n","                      num_iter, avg_eval_loss, eval_accuracy, precision, recall, f1, fus_f1))\n","            # filename = '../models/LSTMSuffixElmoAtt_???_all_iter_' + str(num_iter) + '.pt'\n","            # torch.save(rnn_clf, filename)\n","            # avg_eval_loss, eval_accuracy, precision, recall, f1, fus_f1 = evaluate(train_dataloader_vua, rnn_clf,\n","            #                                                                        nll_criterion, using_GPU)\n","            # training_loss.append(avg_eval_loss)\n","            # training_f1.append(f1)\n","            # training_accuracy.append(eval_accuracy)\n","            # training_precision.append(precision)\n","            # training_recall.append(recall)\n","            # training_fus_f1.append(fus_f1)\n","            \n","#             print(\n","#                 \"Iteration {}. Training Loss {}. Training Accuracy {}. Training Precision {}. Training Recall {}. Training F1 {}. Training class-wise F1 {}.\".format(\n","#                     num_iter, avg_eval_loss, eval_accuracy, precision, recall, f1, fus_f1))\n","print(\"Training done!\")"],"metadata":{"id":"A0Br26_MUJyi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","print('Precision on vua = ', np.mean(np.array(val_precision)))\n","print('Recall on vua = ', np.mean(np.array(val_recall)))\n","print('F1 on vua = ', np.mean(np.array(val_f1)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yR-Z-ffmQQkL","executionInfo":{"status":"ok","timestamp":1646890316907,"user_tz":360,"elapsed":18,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"9eff3b2d-0cb8-4056-8d6d-693d4afcd4e4"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision on vua =  nan\n","Recall on vua =  50.269396551724135\n","F1 on vua =  nan\n"]}]},{"cell_type":"code","source":["\"\"\"\n","4. test the model\n","the following code is for test data of VUA\n","\"\"\"\n","'''\n","VUA\n","'''\n","elmos_test_vua = h5py.File(elmo_dir + 'VUA_test.hdf5', 'r')\n","embedded_test_vua = [[embed_sequence(example[0], example[1], word2idx,\n","                                     glove_embeddings, elmos_test_vua, suffix_embeddings), example[2]]\n","                     for example in raw_test_vua]\n","test_dataset_vua = TextDataset([example[0] for example in embedded_test_vua],\n","                               [example[1] for example in embedded_test_vua])\n","test_dataloader_vua = DataLoader(dataset=test_dataset_vua, batch_size=batch_size,\n","                                 collate_fn=TextDataset.collate_fn)\n","avg_eval_loss, eval_accuracy, precision, recall, f1, fus_f1 = evaluate(test_dataloader_vua, rnn_clf,\n","                                                                       nll_criterion, using_GPU)\n","print(\"Test Accuracy {}. Test Precision {}. Test Recall {}. Test F1 {}. Test class-wise F1 {}.\".format(\n","    eval_accuracy, precision, recall, f1, fus_f1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RqXRiiKMX_sS","executionInfo":{"status":"ok","timestamp":1646890328467,"user_tz":360,"elapsed":9970,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"1b480d26-4cd9-4c78-93f9-c4ed69db6e87"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/classification/util.py:179: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  eval_text = Variable(eval_text, volatile=True)\n","/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/classification/util.py:180: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  eval_lengths = Variable(eval_lengths, volatile=True)\n","/content/drive/MyDrive/Repos/metaphor-detection/core/gao_files/classification/util.py:181: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  eval_labels = Variable(eval_labels, volatile=True)\n"]},{"output_type":"stream","name":"stdout","text":["[[3705.  663.]\n"," [ 407. 1098.]]\n","Test Accuracy 81.78103637695312. Test Precision 72.95681063122923. Test Recall 62.35093696763203. Test F1 67.23821187997551. Test class-wise F1 77.31014367583681.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","gao_scores = [53.4, 65.6, 58.9, 69.1, 53.4]\n","our_scores = [precision,\n","  recall,\n","  f1,\n","  eval_accuracy.item(),\n","  fus_f1]\n","our_scores = [round(score,1) for score in our_scores]\n","all_scores = [gao_scores, our_scores]\n","all_scores_df = pd.DataFrame(all_scores, columns= ['P', 'R', 'F1', 'Acc', 'MaF1'], index=['Gao et al', 'US'])\n","print(\"vua classification model: classification task\\n\")\n","all_scores_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":147},"id":"VGtn6BWPZX3x","executionInfo":{"status":"ok","timestamp":1646890328467,"user_tz":360,"elapsed":20,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"f60c7844-bbec-49dd-aead-9bfa331433b4"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["vua classification model: classification task\n","\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-80784356-8d17-4ebe-b52a-110d5a7bfce3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>P</th>\n","      <th>R</th>\n","      <th>F1</th>\n","      <th>Acc</th>\n","      <th>MaF1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Gao et al</th>\n","      <td>53.4</td>\n","      <td>65.6</td>\n","      <td>58.9</td>\n","      <td>69.1</td>\n","      <td>53.4</td>\n","    </tr>\n","    <tr>\n","      <th>US</th>\n","      <td>73.0</td>\n","      <td>62.4</td>\n","      <td>67.2</td>\n","      <td>81.8</td>\n","      <td>77.3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80784356-8d17-4ebe-b52a-110d5a7bfce3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-80784356-8d17-4ebe-b52a-110d5a7bfce3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-80784356-8d17-4ebe-b52a-110d5a7bfce3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["              P     R    F1   Acc  MaF1\n","Gao et al  53.4  65.6  58.9  69.1  53.4\n","US         73.0  62.4  67.2  81.8  77.3"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["def write_predictions(raw_dataset, evaluation_dataloader, model, using_GPU, rawdata_filename):\n","    \"\"\"\n","    Evaluate the model on the given evaluation_dataloader\n","\n","    :param raw_dataset\n","    :param evaluation_dataloader:\n","    :param model:\n","    :param using_GPU: a boolean\n","    :return: a list of\n","    \"\"\"\n","    # Set model to eval mode, which turns off dropout.\n","    model.eval()\n","\n","    predictions = []\n","    for (example_text, example_lengths, labels) in evaluation_dataloader:\n","        eval_text = Variable(example_text, volatile=True)\n","        eval_lengths = Variable(example_lengths, volatile=True)\n","        eval_labels = Variable(labels, volatile=True)\n","        if using_GPU:\n","            eval_text = eval_text.cuda()\n","            eval_lengths = eval_lengths.cuda()\n","            eval_labels = eval_labels.cuda()\n","\n","        # predicted shape: (batch_size, seq_len, 2)\n","        predicted = model(eval_text, eval_lengths)\n","        # get 0 or 1 predictions\n","        # predicted_labels: (batch_size, seq_len)\n","        # print(\"predicted\", predicted.data )\n","        _, predicted_labels = torch.max(predicted.data, 1)\n","        predictions.extend(predicted_labels)\n","\n","    # Set the model back to train mode, which activates dropout again.\n","    model.train()\n","    assert (len(predictions) == len(raw_dataset))\n","\n","    # read original data\n","    data = []\n","    with open(rawdata_filename, encoding='latin-1') as f:\n","        lines = csv.reader(f)\n","        for line in lines:\n","            data.append(line)\n","\n","    # append predictions to the original data\n","    data[0].append('prediction')\n","    for i in range(len(predictions)):\n","        data[i + 1].append(predictions[i])\n","    return data"],"metadata":{"id":"4oHkVlOWHeyo","executionInfo":{"status":"ok","timestamp":1646890328468,"user_tz":360,"elapsed":16,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["cls_test_pred = write_predictions(raw_test_vua, test_dataloader_vua, rnn_clf , using_GPU, data_dir + 'VUA/VUA_formatted_test.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dsCV3jL19jSZ","executionInfo":{"status":"ok","timestamp":1646890330284,"user_tz":360,"elapsed":1832,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"258fd12c-66e9-4a42-bc5a-cf52b25d11e2"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"]}]},{"cell_type":"code","source":["def get_performance_VUAverb_test(data_path, seq_test_pred):\n","    \"\"\"\n","    Similar treatment as get_performance_VUAverb_val\n","    Read the VUA-verb test data, and the VUA-sequence test data.\n","    Extract the predictions for VUA-verb test data from the VUA-sequence test data.\n","    Prints the performance of LSTM sequence model on VUA-verb test set based on genre\n","    Prints the performance of LSTM sequence model on VUA-verb test set regardless of genre\n","\n","    :return: the averaged performance across genre and performance on verb test\n","    regardless of genre\n","    \"\"\"\n","    # get the VUA-ver test set\n","    ID_verbidx_label = []  # ID tuple, verb_idx, label 1 or 0\n","    with open(data_path + 'VUA/VUA_formatted_test.csv', encoding='latin-1') as f:\n","        lines = csv.reader(f)\n","        next(lines)\n","        for line in lines:\n","          ID_verbidx_label.append([(line[0], line[1]), int(line[4]), int(line[5])])\n","\n","    # get genre\n","    ID2genre = {}\n","    with open(data_path + 'VUAsequence/VUA_seq_formatted_test.csv', encoding='latin-1') as f:\n","      lines = csv.reader(f)\n","      next(lines)\n","      for line in lines:\n","        ID2genre[(line[0], line[1])] = line[6]\n","\n","    # get the prediction from LSTM sequence model\n","    ID2sen_labelseq = {}  # ID tuple --> [genre, label_sequence]\n","    for line in seq_test_pred[1:]:\n","      ID2sen_labelseq[(line[0], line[1])] = line[6]\n","    # with open('/predictions/vua_seq_test_predictions_LSTMsequence_vua.csv', encoding='latin-1') as f:\n","    #     # txt_id\tsen_ix\tsentence\tlabel_seq\tpos_seq\tlabeled_sentence\tgenre   predictions\n","    #     lines = csv.reader(f)\n","    #     next(lines)\n","    #     for line in lines:\n","    #         ID2sen_labelseq[(line[0], line[1])] = [line[6], ast.literal_eval(line[7])]\n","    # compute confusion_matrix\n","    predictions = []\n","    genres = ['news', 'fiction', 'academic', 'conversation']\n","    confusion_matrix = np.zeros((4, 2, 2))\n","    for ID, verbidx, label in ID_verbidx_label:\n","        pred = ID2sen_labelseq[ID]\n","        # pred = ID2sen_labelseq[ID][1][verbidx]\n","        predictions.append(pred)\n","        genre = ID2genre[ID]\n","        genre_idx = genres.index(genre)\n","        confusion_matrix[genre_idx][pred][label] += 1\n","    assert (np.sum(confusion_matrix) == len(ID_verbidx_label))\n","\n","    print('Tagging model performance on test-verb: genre')\n","    avg_performance = []\n","    for i in range(len(genres)):\n","        precision = 100 * confusion_matrix[i, 1, 1] / np.sum(confusion_matrix[i, 1])\n","        recall = 100 * confusion_matrix[i, 1, 1] / np.sum(confusion_matrix[i, :, 1])\n","        f1 = 2 * precision * recall / (precision + recall)\n","        accuracy = 100 * (confusion_matrix[i, 1, 1] + confusion_matrix[i, 0, 0]) / np.sum(confusion_matrix[i])\n","        print(genres[i], 'Precision, Recall, F1, Accuracy: ', precision, recall, f1, accuracy)\n","        avg_performance.append([precision, recall, f1, accuracy])\n","    avg_performance = np.array(avg_performance)\n","    macro_avg_performance = avg_performance.mean(0)\n","\n","    print('Tagging model performance on test-verb: regardless of genre')\n","    confusion_matrix = confusion_matrix.sum(axis=0)\n","    precision = 100 * confusion_matrix[1, 1] / np.sum(confusion_matrix[1])\n","    recall = 100 * confusion_matrix[1, 1] / np.sum(confusion_matrix[:, 1])\n","    f1 = 2 * precision * recall / (precision + recall)\n","    accuracy = 100 * (confusion_matrix[1, 1] + confusion_matrix[0, 0]) / np.sum(confusion_matrix)\n","    overall_performance = np.array([precision, recall, f1, accuracy])\n","    print('Precision, Recall, F1, Accuracy: ', precision, recall, f1, accuracy)\n","\n","    return macro_avg_performance, overall_performance"],"metadata":{"id":"6sov7ed3I_3H","executionInfo":{"status":"ok","timestamp":1646890330284,"user_tz":360,"elapsed":3,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["macro_avg_performance, overall_verb_performance = get_performance_VUAverb_test(data_dir, cls_test_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Lse5Emt-5fs","executionInfo":{"status":"ok","timestamp":1646890331113,"user_tz":360,"elapsed":831,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"5227dd03-b43b-4cb3-c4f3-f9feab584f34"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Tagging model performance on test-verb: genre\n","news Precision, Recall, F1, Accuracy:  61.53846153846154 57.24508050089445 59.31417979610751 64.25081433224756\n","fiction Precision, Recall, F1, Accuracy:  41.904761904761905 48.35164835164835 44.89795918367347 76.60649819494584\n","academic Precision, Recall, F1, Accuracy:  58.208955223880594 55.01567398119122 56.56728444802579 57.188244638602065\n","conversation Precision, Recall, F1, Accuracy:  34.751773049645394 33.67697594501718 34.20593368237347 81.15942028985508\n","Tagging model performance on test-verb: regardless of genre\n","Precision, Recall, F1, Accuracy:  52.383720930232556 51.1641113003975 51.766733697213446 71.41154435552528\n"]}]},{"cell_type":"code","source":["macro_F1 = macro_avg_performance[2]\n","classification_performance = np.append(overall_verb_performance, macro_F1)"],"metadata":{"id":"CxHiSfSO--dI","executionInfo":{"status":"ok","timestamp":1646890331113,"user_tz":360,"elapsed":9,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["gao_scores = [53.4, 65.6, 58.9, 69.1, 53.4]\n","our_scores = classification_performance\n","our_scores = [round(score,1) for score in our_scores]\n","all_scores = [gao_scores, our_scores]\n","all_scores_df = pd.DataFrame(all_scores, columns= ['P', 'R', 'F1', 'Acc', 'MaF1'], index=['Gao et al', 'US'])\n","print(\"vua classification model: classification task\\n\")\n","all_scores_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":147},"id":"NfERdgYN_Gi0","executionInfo":{"status":"ok","timestamp":1646890331114,"user_tz":360,"elapsed":9,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"bd40ca85-2e66-44e1-9dcd-30b13c5a40b2"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["vua classification model: classification task\n","\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-5baf9f02-305a-4deb-a811-b4c3cfad34d6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>P</th>\n","      <th>R</th>\n","      <th>F1</th>\n","      <th>Acc</th>\n","      <th>MaF1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Gao et al</th>\n","      <td>53.4</td>\n","      <td>65.6</td>\n","      <td>58.9</td>\n","      <td>69.1</td>\n","      <td>53.4</td>\n","    </tr>\n","    <tr>\n","      <th>US</th>\n","      <td>52.4</td>\n","      <td>51.2</td>\n","      <td>51.8</td>\n","      <td>71.4</td>\n","      <td>48.7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5baf9f02-305a-4deb-a811-b4c3cfad34d6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5baf9f02-305a-4deb-a811-b4c3cfad34d6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5baf9f02-305a-4deb-a811-b4c3cfad34d6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["              P     R    F1   Acc  MaF1\n","Gao et al  53.4  65.6  58.9  69.1  53.4\n","US         52.4  51.2  51.8  71.4  48.7"]},"metadata":{},"execution_count":22}]}]}