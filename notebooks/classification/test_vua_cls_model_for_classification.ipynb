{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_vua_cls_model_for_classification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNCGKV7ArTJt4W9I0TMwuU2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["##Code for investigating robustness of gao et al VUA Classifcation Model"],"metadata":{"id":"CJ0nenviLc-B"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RqqkYmRiKiGt","executionInfo":{"status":"ok","timestamp":1646933259447,"user_tz":360,"elapsed":13479,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"d271dc24-00c8-40f1-847b-5dca6869c773"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# mount drive\n","from google.colab import drive\n","ROOT = '/content/drive'\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# add repo directory to path\n","import os\n","import sys\n","from os.path import join \n","repo_dir = '/content/drive/MyDrive/Repos/metaphor-detection'\n","if repo_dir not in sys.path:\n","    sys.path.append(repo_dir)\n","print(sys.path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndu2cHtHMpUO","executionInfo":{"status":"ok","timestamp":1646933259448,"user_tz":360,"elapsed":10,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"5c13192d-206c-4e53-fde5-82b7fb22dda3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["['', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/MyDrive/Repos/metaphor-detection']\n"]}]},{"cell_type":"code","source":["# pip install requirements (takes a while)\n","!cd drive/MyDrive/Repos/metaphor-detection/; pip install -r gao-g-requirements.txt\n","!pip install --upgrade google-cloud-storage"],"metadata":{"id":"4u9n8pNmMsDd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from core.gao_files.classification.util import get_num_lines, get_vocab, embed_sequence, get_word2idx_idx2word, get_embedding_matrix\n","from core.gao_files.classification.util  import TextDatasetWithGloveElmoSuffix as TextDataset\n","from core.gao_files.classification.util  import evaluate\n","from core.gao_files.classification.model import RNNSequenceClassifier\n","from core.gao_files.classification.vua_util  import write_predictions_vua_cls, get_performance_VUAverb_test\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","\n","import csv\n","import h5py\n","# import matplotlib\n","# matplotlib.use('Agg')  # to avoid the error: _tkinter.TclError: no display name and no $DISPLAY environment variable\n","# matplotlib.use('tkagg') # to display the graph on remote server\n","import matplotlib.pyplot as plt\n","import pandas as pd"],"metadata":{"id":"43yxdso-N2Xa","executionInfo":{"status":"ok","timestamp":1646933365174,"user_tz":360,"elapsed":8680,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["print(\"PyTorch version:\")\n","print(torch.__version__)\n","print(\"GPU Detected:\")\n","print(torch.cuda.is_available())\n","using_GPU = torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucPMqD95PBB4","executionInfo":{"status":"ok","timestamp":1646933365175,"user_tz":360,"elapsed":9,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"7b21ab17-2ade-438a-a907-2c8341ac7be9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch version:\n","1.10.0+cu111\n","GPU Detected:\n","True\n"]}]},{"cell_type":"code","source":["# directories\n","# to download glove and elmo vectors see: notebooks/Download_large_data.ipynb\n","data_dir = repo_dir + '/resources/metaphor-in-context/data/'\n","glove_dir = repo_dir + '/resources/glove/'\n","elmo_dir = repo_dir + '/resources/elmo/'"],"metadata":{"id":"C24CjkKTQjx6","executionInfo":{"status":"ok","timestamp":1646933365175,"user_tz":360,"elapsed":7,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### Gao code"],"metadata":{"id":"WM1uHe5zQk49"}},{"cell_type":"code","source":["\"\"\"\n","1. Data pre-processing\n","\"\"\"\n","'''\n","1.1 VUA\n","get raw dataset as a list:\n","  Each element is a triple:\n","    a sentence: string\n","    a index: int: idx of the focus verb\n","    a label: int 1 or 0\n","'''\n","# header for vua files:\n","# text_idx, sentence_idx, verb, sentence, verb_idx, label\n","SENT_IDX = 3\n","VERB_IDX = 4\n","LABEL_IDX = 5\n","\n","raw_train_vua = []\n","with open(data_dir + 'VUA/VUA_formatted_train.csv', encoding='latin-1') as f:\n","    lines = csv.reader(f)\n","    next(lines)\n","    for line in lines:\n","        raw_train_vua.append([line[SENT_IDX], int(line[VERB_IDX]), int(line[LABEL_IDX])])\n","\n","raw_val_vua = []\n","with open(data_dir+ 'VUA/VUA_formatted_val.csv', encoding='latin-1') as f:\n","    lines = csv.reader(f)\n","    next(lines)\n","    for line in lines:\n","        raw_val_vua.append([line[SENT_IDX], int(line[VERB_IDX]), int(line[LABEL_IDX])])\n","\n","raw_test_vua = []\n","with open(data_dir+ 'VUA/VUA_formatted_test.csv', encoding='latin-1') as f:\n","    lines = csv.reader(f)\n","    next(lines)\n","    for line in lines:\n","        raw_test_vua.append([line[SENT_IDX], int(line[VERB_IDX]), int(line[LABEL_IDX])])\n","print('VUA dataset division: ', '\\ntrain:', len(raw_train_vua), '\\nval:',len(raw_val_vua), '\\ntest:',len(raw_test_vua))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6CTsaxXqPK2A","executionInfo":{"status":"ok","timestamp":1646933366980,"user_tz":360,"elapsed":1811,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"760fabf8-2156-4d5b-e7f4-47327a5ac6cd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["VUA dataset division:  \n","train: 15516 \n","val: 1724 \n","test: 5873\n"]}]},{"cell_type":"code","source":["\"\"\"\n","2. Data preparation\n","\"\"\"\n","'''\n","2. 1\n","get vocabulary and glove embeddings in raw dataset \n","'''\n","# vocab is a set of words\n","vocab = get_vocab(raw_train_vua + raw_val_vua + raw_test_vua)\n","# two dictionaries. <PAD>: 0, <UNK>: 1\n","word2idx, idx2word = get_word2idx_idx2word(vocab)\n","# glove_embeddings a nn.Embeddings\n","glove_embeddings = get_embedding_matrix(glove_dir + 'glove.840B.300d.txt', word2idx, idx2word, normalization=False)\n","# elmo_embeddings\n","elmos_train_vua = h5py.File(elmo_dir + 'VUA_train.hdf5', 'r')\n","elmos_val_vua = h5py.File(elmo_dir + 'VUA_val.hdf5', 'r')\n","# suffix_embeddings: number of suffix tag is 2, and the suffix embedding dimension is 50\n","suffix_embeddings = nn.Embedding(2, 50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ao866hZRD3c","executionInfo":{"status":"ok","timestamp":1646933549437,"user_tz":360,"elapsed":182460,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"3d9c6f1f-82e7-4998-da80-98a1b5e0a6df"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["vocab size:  18695\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2196017/2196017 [00:54<00:00, 40118.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Number of pre-trained word vectors loaded:  17941\n","Embeddings mean:  -0.0001772342948243022\n","Embeddings stdev:  0.37537267804145813\n"]}]},{"cell_type":"code","source":["'''\n","2. 2\n","embed the datasets\n","'''\n","# indices for raw_[train/val]_vua lists\n","raw_sent_idx = 0\n","raw_verb_idx = 1\n","raw_label_idx = 2\n","\n","embedded_train_vua = [[embed_sequence(example[raw_sent_idx], \n","                                      example[raw_verb_idx], \n","                                      word2idx, glove_embeddings, elmos_train_vua, suffix_embeddings), \n","                       example[raw_label_idx]]\n","                      for example in raw_train_vua]\n","\n","embedded_val_vua = [[embed_sequence(example[raw_sent_idx],\n","                                    example[raw_verb_idx],\n","                                    word2idx, glove_embeddings, elmos_val_vua, suffix_embeddings), \n","                     example[raw_label_idx]]\n","                    for example in raw_val_vua]\n","\n","# each row in embedded_[train/val]_vua contains an embedding and a label"],"metadata":{"id":"xO5F1t8OSIIl","executionInfo":{"status":"ok","timestamp":1646933568726,"user_tz":360,"elapsed":19294,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","def run_model_once(i, train_dataset_vua, val_dataset_vua, num_epochs = 20):\n","  print(\"#\"*30)\n","  print(f\"\\nRunning model i = {i}\\n\")\n","  print(\"#\"*30)\n","\n","  # set up data loader\n","  # Data-related hyperparameters\n","  batch_size = 64\n","  # Set up a DataLoader for the training, validation, and test dataset\n","  train_dataloader_vua = DataLoader(dataset=train_dataset_vua, batch_size=batch_size, shuffle=True,\n","                                    collate_fn=TextDataset.collate_fn)\n","\n","  val_dataloader_vua = DataLoader(dataset=val_dataset_vua, batch_size=batch_size,\n","                                  collate_fn=TextDataset.collate_fn)\n","\n","  \"\"\"\n","  3. Model training\n","  \"\"\"\n","  '''\n","  3. 1 \n","  set up model, loss criterion, optimizer\n","  '''\n","  # Instantiate the model\n","  rnn_clf = RNNSequenceClassifier(num_classes=2, embedding_dim=300 + 1024 + 50, hidden_size=300, num_layers=1, bidir=True,\n","                                  dropout1=0.3, dropout2=0.2, dropout3=0.2)\n","  # Move the model to the GPU if available\n","  if using_GPU:\n","      rnn_clf = rnn_clf.cuda()\n","  # Set up criterion for calculating loss\n","  nll_criterion = nn.NLLLoss()\n","  # Set up an optimizer for updating the parameters of the rnn_clf\n","  rnn_clf_optimizer = optim.SGD(rnn_clf.parameters(), lr=0.01,momentum=0.9)\n","  # Number of epochs (passes through the dataset) to train the model for.\n","\n","  training_loss = []\n","  val_loss = []\n","\n","  training_f1 = []\n","  val_f1 = []\n","\n","  val_accuracy = []\n","  val_precision = []\n","  val_recall = []\n","  val_fus_f1 = []\n","\n","  # A counter for the number of gradient updates\n","  num_iter = 0\n","  for epoch in range(num_epochs):\n","      print(\"Starting epoch {}\".format(epoch + 1))\n","      for (example_text, example_lengths, labels) in train_dataloader_vua:\n","          example_text = Variable(example_text)\n","          example_lengths = Variable(example_lengths)\n","          labels = Variable(labels)\n","          if using_GPU:\n","              example_text = example_text.cuda()\n","              example_lengths = example_lengths.cuda()\n","              labels = labels.cuda()\n","          # predicted shape: (batch_size, 2)\n","          predicted = rnn_clf(example_text, example_lengths)\n","          batch_loss = nll_criterion(predicted, labels)\n","          rnn_clf_optimizer.zero_grad()\n","          batch_loss.backward()\n","          rnn_clf_optimizer.step()\n","          num_iter += 1\n","          # Calculate validation and training set loss and accuracy every 200 gradient updates\n","          if num_iter % 200 == 0:\n","              avg_eval_loss, eval_accuracy, precision, recall, f1, fus_f1 = evaluate(val_dataloader_vua, rnn_clf,\n","                                                                                    nll_criterion, using_GPU, print_verbose=False)\n","              val_loss.append(avg_eval_loss)\n","              val_f1.append(f1)\n","              val_accuracy.append(eval_accuracy)\n","              val_precision.append(precision)\n","              val_recall.append(recall)\n","              val_fus_f1.append(fus_f1)\n","\n","              if num_iter % 1000 == 0:\n","                print(\n","                      \"Iteration {}. Validation Loss {}. Validation Accuracy {}. Validation Precision {}. Validation Recall {}. Validation F1 {}. Validation class-wise F1 {}.\".format(\n","                          num_iter, avg_eval_loss, eval_accuracy, precision, recall, f1, fus_f1))\n","\n","  print(\"Training done!\")\n","\n","  \"\"\"\n","  4. test the model\n","  the following code is for test data of VUA\n","  \"\"\"\n","  '''\n","  VUA\n","  '''\n","  elmos_test_vua = h5py.File(elmo_dir + 'VUA_test.hdf5', 'r')\n","  embedded_test_vua = [[embed_sequence(example[raw_sent_idx],\n","                                      example[raw_verb_idx],\n","                                      word2idx, glove_embeddings, elmos_test_vua, suffix_embeddings), \n","                          example[raw_label_idx]]\n","                      for example in raw_test_vua]\n","\n","  test_dataset_vua = TextDataset([example[embedding_idx] for example in embedded_test_vua], # embeddings\n","                                [example[label_idx] for example in embedded_test_vua] # labels\n","                                )\n","\n","  test_dataloader_vua = DataLoader(dataset=test_dataset_vua, batch_size=batch_size,\n","                                  collate_fn=TextDataset.collate_fn)\n","  cls_test_pred = write_predictions_vua_cls(raw_test_vua, test_dataloader_vua, rnn_clf , using_GPU, data_dir + 'VUA/VUA_formatted_test.csv')\n","  macro_avg_performance, overall_verb_performance = get_performance_VUAverb_test(data_dir, cls_test_pred)\n","\n","  macro_F1 = macro_avg_performance[2]\n","  classification_performance = np.append(overall_verb_performance, macro_F1)\n","  return list(classification_performance)"],"metadata":{"id":"Zw0h6epu4Knu","executionInfo":{"status":"ok","timestamp":1646935306469,"user_tz":360,"elapsed":117,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["'''\n","2. 3\n","set up Dataloader for batching\n","'''\n","embedding_idx = 0\n","label_idx = 1\n","# Separate the input (embedded_sequence) and labels in the indexed train sets.\n","train_dataset_vua = TextDataset([example[embedding_idx] for example in embedded_train_vua],\n","                                [example[label_idx] for example in embedded_train_vua])\n","\n","val_dataset_vua = TextDataset([example[embedding_idx] for example in embedded_val_vua],\n","                              [example[label_idx] for example in embedded_val_vua])"],"metadata":{"id":"zM3ekDD53774"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run model a bunch of times\n","number_times_to_run = 10\n","num_epochs = 10 #20\n","average_metrics = [['P', 'R', 'F1', 'Acc', 'MaF1']]\n","for test_i in range(number_times_to_run):\n","  average_metrics.append(run_model_once(test_i, train_dataset_vua, val_dataset_vua, num_epochs=num_epochs))"],"metadata":{"id":"ailElnBI5CqM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["average_metrics_df =  pd.DataFrame(average_metrics[1:], columns = average_metrics[0])\n","average_metrics_df "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"S8N76TxJ8BXg","executionInfo":{"status":"ok","timestamp":1646940434408,"user_tz":360,"elapsed":172,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}},"outputId":"401211a6-d122-44f4-8a5f-a4f82e7ea33a"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-d8b9f74f-53d0-4e29-a9e0-0ead4021aeaa\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>P</th>\n","      <th>R</th>\n","      <th>F1</th>\n","      <th>Acc</th>\n","      <th>MaF1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>75.287356</td>\n","      <td>52.072686</td>\n","      <td>61.564283</td>\n","      <td>80.504001</td>\n","      <td>56.362457</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>67.628993</td>\n","      <td>62.521295</td>\n","      <td>64.974919</td>\n","      <td>79.788864</td>\n","      <td>60.358038</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>71.841155</td>\n","      <td>56.501988</td>\n","      <td>63.254927</td>\n","      <td>80.316704</td>\n","      <td>59.202261</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>74.530612</td>\n","      <td>51.845542</td>\n","      <td>61.152043</td>\n","      <td>80.248595</td>\n","      <td>56.398371</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>76.764706</td>\n","      <td>44.463373</td>\n","      <td>56.310680</td>\n","      <td>79.312106</td>\n","      <td>52.388014</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>72.648903</td>\n","      <td>52.640545</td>\n","      <td>61.047086</td>\n","      <td>79.856973</td>\n","      <td>55.558423</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>73.712529</td>\n","      <td>54.457694</td>\n","      <td>62.638798</td>\n","      <td>80.521028</td>\n","      <td>57.262419</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>68.915344</td>\n","      <td>59.170926</td>\n","      <td>63.672472</td>\n","      <td>79.754810</td>\n","      <td>60.241636</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>74.870466</td>\n","      <td>49.233390</td>\n","      <td>59.403905</td>\n","      <td>79.822918</td>\n","      <td>54.135022</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>73.632653</td>\n","      <td>51.220897</td>\n","      <td>60.415271</td>\n","      <td>79.874000</td>\n","      <td>55.813961</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8b9f74f-53d0-4e29-a9e0-0ead4021aeaa')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d8b9f74f-53d0-4e29-a9e0-0ead4021aeaa button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d8b9f74f-53d0-4e29-a9e0-0ead4021aeaa');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["           P          R         F1        Acc       MaF1\n","0  75.287356  52.072686  61.564283  80.504001  56.362457\n","1  67.628993  62.521295  64.974919  79.788864  60.358038\n","2  71.841155  56.501988  63.254927  80.316704  59.202261\n","3  74.530612  51.845542  61.152043  80.248595  56.398371\n","4  76.764706  44.463373  56.310680  79.312106  52.388014\n","5  72.648903  52.640545  61.047086  79.856973  55.558423\n","6  73.712529  54.457694  62.638798  80.521028  57.262419\n","7  68.915344  59.170926  63.672472  79.754810  60.241636\n","8  74.870466  49.233390  59.403905  79.822918  54.135022\n","9  73.632653  51.220897  60.415271  79.874000  55.813961"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["output_dir = \"/content/drive/MyDrive/metaphor-detection-output/\"\n","file_name = \"vua_cls_classification_performance_epochs-{}.csv\".format(num_epochs)\n","average_metrics_df.to_csv(output_dir+file_name, index=False)"],"metadata":{"id":"6K046DmnIAL2","executionInfo":{"status":"ok","timestamp":1646940439433,"user_tz":360,"elapsed":149,"user":{"displayName":"Christie Ibaraki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIFzH4hTxQQ5yaIkcpfIR3eeP_amQmg2nF-axQHQ=s64","userId":"17023704871620396360"}}},"execution_count":53,"outputs":[]}]}