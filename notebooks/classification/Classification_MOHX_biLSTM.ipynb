{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_MOHX.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL01yWg6PWDG",
        "outputId": "ca2c9fe8-a14b-422a-c8ff-56c2cd71586f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount google drive \n",
        "from google.colab import drive\n",
        "ROOT = '/content/drive'\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from os.path import join \n",
        "repo_dir = '/content/drive/MyDrive/metaphor-detection'"
      ],
      "metadata": {
        "id": "SM0CV7h9Pn8C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## directories for resources\n",
        "data_dir = repo_dir + '/resources/metaphor-in-context/data/'\n",
        "glove_dir = repo_dir + '/resources/glove/'\n",
        "elmo_dir = repo_dir + '/resources/elmo/'\n"
      ],
      "metadata": {
        "id": "JEcWut_bPv-k"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installing the requirements\n",
        "%cd 'drive/MyDrive/metaphor-detection/' \n",
        "#;!pip install allennlp\n",
        "#!pip install -r gao-g-requirements.txt\n",
        "#!pip install --upgrade google-cloud-storage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI3D0ZE-P80O",
        "outputId": "2fbd728c-3d06-462a-be07-da497eb99c74"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/metaphor-detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from core.gao_files.classification.model import RNNSequenceClassifier\n",
        "import time\n",
        "import matplotlib\n",
        "from core.gao_files.classification.util import *\n",
        "from core.data.gao_data import *\n",
        "import h5py\n",
        "import math\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "IKl_22p9QTyc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preperation"
      ],
      "metadata": {
        "id": "sEH2Y0yIVUSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Read MOH-x Data \n",
        "data_dir = os.path.join(\"resources\", \"metaphor-in-context\", \"data\")\n",
        "data_container = ExperimentData(data_dir)\n",
        "data_container.read_moh_x_data(to_pandas = False)\n",
        "moh_x_data = data_container.moh_x_formatted_svo_cleaned\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNgZNtHrS4N9",
        "outputId": "5edcbf3b-0d82-4efe-9949-3682977a77ae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MOH-X formatted svo nrow: 647\n",
            "MOH-X formatted svo cleaned nrow: 647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Pre-Process Data\n",
        "vocab = get_vocab(moh_x_data)\n",
        "word2idx, idx2word = get_word2idx_idx2word(vocab)\n",
        "glove_embeddings = get_embedding_matrix(glove_dir + 'glove840B300d.txt', \n",
        "                                        word2idx, \n",
        "                                        idx2word, \n",
        "                                        normalization=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQLbTn4iVFvI",
        "outputId": "1dbd387c-8584-475e-a489-f1ec1d277818"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size:  453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2196017/2196017 [00:48<00:00, 44819.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of pre-trained word vectors loaded:  453\n",
            "Embeddings mean:  -0.0009290720336139202\n",
            "Embeddings stdev:  0.38682886958122253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_SUFFIX_TAG = 2\n",
        "elmo_embeddings = h5py.File(elmo_dir + 'MOH-X_cleaned.hdf5', 'r')\n",
        "suffix_embeddings = nn.Embedding(NUM_SUFFIX_TAG, 50)"
      ],
      "metadata": {
        "id": "ENtoXss4VqYA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Embedding Datasets\n",
        "embedded_data = [[embed_sequence(data[3].strip(), int(data[4]), word2idx, glove_embeddings, elmo_embeddings, suffix_embeddings), int(data[-1])] for data in moh_x_data]\n",
        "sentences = [data[0] for data in embedded_data]\n",
        "labels = [data[1] for data in embedded_data]"
      ],
      "metadata": {
        "id": "eP9Yq78ZaR5k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Fold Training"
      ],
      "metadata": {
        "id": "bWFqrO4IeJ_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Data Length is {len(moh_x_data)}\")\n",
        "NUMBER_FOLD = 10\n",
        "fold_size = round(len(moh_x_data) / NUMBER_FOLD)\n",
        "print(f\"Each fold size is {fold_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9r2c1theMCs",
        "outputId": "4f75d1de-a08d-4d5b-eac8-9645cac8f270"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Length is 647\n",
            "Each fold size is 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folds = []\n",
        "for i in range(NUMBER_FOLD):\n",
        "    folds.append((sentences[i * fold_size:(i + 1) * fold_size], labels[i * fold_size: (i + 1) * fold_size]))\n"
      ],
      "metadata": {
        "id": "m2p3ypuYelV9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_f1s = []\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "BATCH_SIZE = 10\n",
        "using_GPU = True\n",
        "NUM_EPOCHS = 30\n",
        "for i in range(NUMBER_FOLD):\n",
        "    ### DATA BATCHING\n",
        "    training_sentences = []\n",
        "    training_labels = []\n",
        "    for j in range(NUMBER_FOLD):\n",
        "        if j != i:\n",
        "            training_sentences.extend(folds[j][0])\n",
        "            training_labels.extend(folds[j][1])\n",
        "    training_dataset_mohX = TextDatasetWithGloveElmoSuffix(training_sentences, \n",
        "                                                           training_labels)\n",
        "    val_dataset_mohX = TextDatasetWithGloveElmoSuffix(folds[i][0], \n",
        "                                                      folds[i][1])\n",
        "\n",
        "    # Data-related hyperparameters\n",
        "    # Set up a DataLoader for the training, validation, and test dataset\n",
        "    train_dataloader_mohX = DataLoader(dataset=training_dataset_mohX, \n",
        "                                       batch_size=BATCH_SIZE, \n",
        "                                       shuffle=True,\n",
        "                                      collate_fn=TextDatasetWithGloveElmoSuffix\n",
        "                                                .collate_fn)\n",
        "    val_dataloader_mohX = DataLoader(dataset=val_dataset_mohX, \n",
        "                                     batch_size=BATCH_SIZE, \n",
        "                                     shuffle=True,\n",
        "                                      collate_fn=TextDatasetWithGloveElmoSuffix\n",
        "                                                .collate_fn)\n",
        "    rnn_clf = RNNSequenceClassifier(num_classes=2, \n",
        "                                    embedding_dim=300+1024+50, \n",
        "                                    hidden_size=300, num_layers=1, \n",
        "                                    bidir=True,\n",
        "                                    dropout1=0.2, dropout2=0, dropout3=0.2)\n",
        "    nll_criterion = nn.NLLLoss()\n",
        "    if using_GPU:\n",
        "        rnn_clf = rnn_clf.cuda()\n",
        "        nll_criterion = nll_criterion.cuda()\n",
        "\n",
        "    rnn_clf_optimizer = optim.SGD(rnn_clf.parameters(), lr=0.02, momentum=0.9)\n",
        "    #### TRAIN ####\n",
        "    training_loss = []\n",
        "    val_loss = []\n",
        "    val_p = []\n",
        "    val_r = []\n",
        "    val_acc = []\n",
        "    training_f1 = []\n",
        "    val_f1 = []\n",
        "    num_iter = 0\n",
        "    train_dataloader = train_dataloader_mohX\n",
        "    val_dataloader = val_dataloader_mohX\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        print(\"-----Starting epoch {}------\".format(epoch + 1))\n",
        "        now = time.time()\n",
        "        for (example_text, example_lengths, labels) in train_dataloader:\n",
        "            example_text = Variable(example_text)\n",
        "            example_lengths = Variable(example_lengths)\n",
        "            labels = Variable(labels)\n",
        "            if using_GPU:\n",
        "                example_text = example_text.cuda()\n",
        "                example_lengths = example_lengths.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            # predicted shape: (batch_size, 2)\n",
        "            predicted = rnn_clf(example_text, example_lengths)\n",
        "            batch_loss = nll_criterion(predicted, labels)\n",
        "            rnn_clf_optimizer.zero_grad()\n",
        "            batch_loss.backward()\n",
        "            rnn_clf_optimizer.step()\n",
        "            num_iter += 1\n",
        "            # Calculate validation and training set loss and accuracy every 200 gradient updates\n",
        "            if num_iter % 200 == 0:\n",
        "                passed = now - time.time()\n",
        "                now = time.time()\n",
        "                avg_eval_loss, eval_accuracy, precision, r, f1, val_fus_f1 = evaluate(val_dataloader, rnn_clf, nll_criterion, using_GPU)\n",
        "                val_loss.append(avg_eval_loss)\n",
        "                val_acc.append(eval_accuracy.item())\n",
        "                val_f1.append(f1)\n",
        "                val_r.append(r)\n",
        "                val_p.append(precision)\n",
        "                print(\n",
        "                    \"\"\"####################Iteration {}.#############\n",
        "                       Validation Loss {}. Validation Accuracy {}. \n",
        "                       Validation Precision {}. Validation Recall {}. \n",
        "                       Validation F1 {}. Validation class-wise F1 {}. \n",
        "                       Time passed {}###############################\"\"\".format(\n",
        "                        num_iter, avg_eval_loss, eval_accuracy, val_p, val_r, val_f1, val_fus_f1, passed))\n",
        "                # filename = '../models/LSTMSuffixElmoAtt_???_all_iter_' + str(num_iter) + '.pt'\n",
        "                # torch.save(rnn_clf, filename)\n",
        "                avg_eval_loss, eval_accuracy, precision, recall, f1, fus_f1 = evaluate(train_dataloader, rnn_clf, nll_criterion, using_GPU)\n",
        "                training_loss.append(avg_eval_loss)\n",
        "                training_f1.append(f1)\n",
        "                #accuracies.append(eval_accuracy.item())\n",
        "                #if str(precision) != \"nan\":\n",
        "                #precisions.append(precision)\n",
        "                #recalls.append(recall)\n",
        "                #if str(max(val_f1)) != \"nan\":\n",
        "                training_loss.append(avg_eval_loss)\n",
        "                training_f1.append(f1)\n",
        "                print(\n",
        "                    \"\"\"######################Iteration {}######################. \n",
        "                      Training Loss {}. Training Accuracy {}. Training Precision {}. \n",
        "                      Training Recall {}. Training F1 {}. Training class-wise F1 {}.\"\"\".format(\n",
        "                        num_iter, avg_eval_loss, eval_accuracy, precision, recall, f1, fus_f1))\n",
        "                \n",
        "            \n",
        "    print(\"Training done for fold {}\".format(i))\n",
        "    optimal_f1s.append(max(val_f1))\n",
        "    #if str(max(val_f1)) != \"nan\":\n",
        "    print('val_f1: ', val_f1)\n",
        "    idx = 0\n",
        "    if math.isnan(max(val_f1)):\n",
        "        optimal_f1s.append(max(val_f1[6:]))\n",
        "        idx = val_f1.index(optimal_f1s[-1])\n",
        "        precisions.append(val_p[idx])\n",
        "        recalls.append(val_r[idx])\n",
        "        accuracies.append(val_acc[idx])\n",
        "    else:\n",
        "        optimal_f1s.append(max(val_f1))\n",
        "        idx = val_f1.index(optimal_f1s[-1])\n",
        "        precisions.append(val_p[idx])\n",
        "        recalls.append(val_r[idx])\n",
        "        accuracies.append(val_acc[idx])\n",
        "            \n",
        "\n",
        "print('F1 on MOH-X by 10-fold = ', optimal_f1s)\n",
        "print('F1 on MOH-X = ', np.mean(np.array(optimal_f1s)))\n",
        "print('precisions on MOH-X = ', np.mean(np.array(precisions)))\n",
        "print('recalls on MOH-X = ', np.mean(np.array(recalls)))\n",
        "print('accuracies on MOH-X = ', np.mean(np.array(accuracies)))\n"
      ],
      "metadata": {
        "id": "vu1PnX_mfR4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb431b2-f530-4f25-821c-83988de9ff73"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----Starting epoch 1------\n",
            "-----Starting epoch 2------\n",
            "-----Starting epoch 3------\n",
            "-----Starting epoch 4------\n",
            "[[ 6.  2.]\n",
            " [27. 30.]]\n",
            "####################Iteration 200.#############\n",
            "                       Validation Loss 1.0874603597017436. Validation Accuracy 55.38461685180664. \n",
            "                       Validation Precision [52.63157894736842]. Validation Recall [93.75]. \n",
            "                       Validation F1 [67.41573033707866]. Validation class-wise F1 48.34201151000274. \n",
            "                       Time passed -0.13670587539672852###############################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/metaphor-detection/core/gao_files/classification/util.py:178: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  eval_text = Variable(eval_text, volatile=True)\n",
            "/content/drive/MyDrive/metaphor-detection/core/gao_files/classification/util.py:179: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  eval_lengths = Variable(eval_lengths, volatile=True)\n",
            "/content/drive/MyDrive/metaphor-detection/core/gao_files/classification/util.py:180: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  eval_labels = Variable(eval_labels, volatile=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[150.  12.]\n",
            " [149. 271.]]\n",
            "######################Iteration 200######################. \n",
            "                      Training Loss 0.5287285624039951. Training Accuracy 72.3367691040039. Training Precision 64.52380952380952. \n",
            "                      Training Recall 95.75971731448763. Training F1 77.09815078236132. Training class-wise F1 71.08703634562752.\n",
            "-----Starting epoch 5------\n",
            "-----Starting epoch 6------\n",
            "-----Starting epoch 7------\n",
            "[[15.  6.]\n",
            " [18. 26.]]\n",
            "####################Iteration 400.#############\n",
            "                       Validation Loss 0.8601410113848172. Validation Accuracy 63.07692337036133. \n",
            "                       Validation Precision [52.63157894736842, 59.09090909090909]. Validation Recall [93.75, 81.25]. \n",
            "                       Validation F1 [67.41573033707866, 68.42105263157895]. Validation class-wise F1 61.98830409356725. \n",
            "                       Time passed -0.25832414627075195###############################\n",
            "[[275.   9.]\n",
            " [ 24. 274.]]\n",
            "######################Iteration 400######################. \n",
            "                      Training Loss 0.20990086659865895. Training Accuracy 94.32989501953125. Training Precision 91.94630872483222. \n",
            "                      Training Recall 96.81978798586573. Training F1 94.32013769363168. Training class-wise F1 94.32988016757056.\n",
            "-----Starting epoch 8------\n",
            "-----Starting epoch 9------\n",
            "-----Starting epoch 10------\n",
            "-----Starting epoch 11------\n",
            "[[29. 18.]\n",
            " [ 4. 14.]]\n",
            "####################Iteration 600.#############\n",
            "                       Validation Loss 1.1506348894192622. Validation Accuracy 66.15384674072266. \n",
            "                       Validation Precision [52.63157894736842, 59.09090909090909, 77.77777777777777]. Validation Recall [93.75, 81.25, 43.75]. \n",
            "                       Validation F1 [67.41573033707866, 68.42105263157895, 55.99999999999999]. Validation class-wise F1 64.24999999999999. \n",
            "                       Time passed -0.05649447441101074###############################\n",
            "[[299. 140.]\n",
            " [  0. 143.]]\n",
            "######################Iteration 600######################. \n",
            "                      Training Loss 0.4108213214635772. Training Accuracy 75.94501495361328. Training Precision 100.0. \n",
            "                      Training Recall 50.53003533568904. Training F1 67.13615023474179. Training class-wise F1 74.08298026642238.\n",
            "-----Starting epoch 12------\n",
            "-----Starting epoch 13------\n",
            "-----Starting epoch 14------\n",
            "[[19.  6.]\n",
            " [14. 26.]]\n",
            "####################Iteration 800.#############\n",
            "                       Validation Loss 1.5649090088330782. Validation Accuracy 69.23076629638672. \n",
            "                       Validation Precision [52.63157894736842, 59.09090909090909, 77.77777777777777, 65.0]. Validation Recall [93.75, 81.25, 43.75, 81.25]. \n",
            "                       Validation F1 [67.41573033707866, 68.42105263157895, 55.99999999999999, 72.22222222222223]. Validation class-wise F1 68.86973180076629. \n",
            "                       Time passed -0.19631433486938477###############################\n",
            "[[298.   3.]\n",
            " [  1. 280.]]\n",
            "######################Iteration 800######################. \n",
            "                      Training Loss 0.02640610849892855. Training Accuracy 99.31271362304688. Training Precision 99.644128113879. \n",
            "                      Training Recall 98.93992932862191. Training F1 99.29078014184398. Training class-wise F1 99.31205673758866.\n",
            "-----Starting epoch 15------\n",
            "-----Starting epoch 16------\n",
            "-----Starting epoch 17------\n",
            "[[19.  6.]\n",
            " [14. 26.]]\n",
            "####################Iteration 1000.#############\n",
            "                       Validation Loss 1.5866050536815937. Validation Accuracy 69.23076629638672. \n",
            "                       Validation Precision [52.63157894736842, 59.09090909090909, 77.77777777777777, 65.0, 65.0]. Validation Recall [93.75, 81.25, 43.75, 81.25, 81.25]. \n",
            "                       Validation F1 [67.41573033707866, 68.42105263157895, 55.99999999999999, 72.22222222222223, 72.22222222222223]. Validation class-wise F1 68.86973180076629. \n",
            "                       Time passed -0.31751036643981934###############################\n",
            "[[298.   2.]\n",
            " [  1. 281.]]\n",
            "######################Iteration 1000######################. \n",
            "                      Training Loss 0.022011415440557385. Training Accuracy 99.48453521728516. Training Precision 99.64539007092199. \n",
            "                      Training Recall 99.29328621908127. Training F1 99.46902654867257. Training class-wise F1 99.48409591206584.\n",
            "-----Starting epoch 18------\n",
            "-----Starting epoch 19------\n",
            "-----Starting epoch 20------\n",
            "-----Starting epoch 21------\n",
            "[[20.  9.]\n",
            " [13. 23.]]\n",
            "####################Iteration 1200.#############\n",
            "                       Validation Loss 1.5342808136573205. Validation Accuracy 66.15384674072266. \n",
            "                       Validation Precision [52.63157894736842, 59.09090909090909, 77.77777777777777, 65.0, 65.0, 63.888888888888886]. Validation Recall [93.75, 81.25, 43.75, 81.25, 81.25, 71.875]. \n",
            "                       Validation F1 [67.41573033707866, 68.42105263157895, 55.99999999999999, 72.22222222222223, 72.22222222222223, 67.6470588235294]. Validation class-wise F1 66.08159392789373. \n",
            "                       Time passed -0.10770630836486816###############################\n",
            "[[298.   3.]\n",
            " [  1. 280.]]\n",
            "######################Iteration 1200######################. \n",
            "                      Training Loss 0.01828766382225654. Training Accuracy 99.31271362304688. Training Precision 99.644128113879. \n",
            "                      Training Recall 98.93992932862191. Training F1 99.29078014184398. Training class-wise F1 99.31205673758866.\n",
            "-----Starting epoch 22------\n",
            "-----Starting epoch 23------\n",
            "-----Starting epoch 24------\n",
            "[[20.  7.]\n",
            " [13. 25.]]\n",
            "####################Iteration 1400.#############\n",
            "                       Validation Loss 1.69966505582516. Validation Accuracy 69.23076629638672. \n",
            "                       Validation Precision [52.63157894736842, 59.09090909090909, 77.77777777777777, 65.0, 65.0, 63.888888888888886, 65.78947368421052]. Validation Recall [93.75, 81.25, 43.75, 81.25, 81.25, 71.875, 78.125]. \n",
            "                       Validation F1 [67.41573033707866, 68.42105263157895, 55.99999999999999, 72.22222222222223, 72.22222222222223, 67.6470588235294, 71.42857142857142]. Validation class-wise F1 69.04761904761904. \n",
            "                       Time passed -0.2441701889038086###############################\n",
            "[[299.   1.]\n",
            " [  0. 282.]]\n",
            "######################Iteration 1400######################. \n",
            "                      Training Loss 0.009586424818938547. Training Accuracy 99.82817840576172. Training Precision 100.0. \n",
            "                      Training Recall 99.64664310954063. Training F1 99.82300884955752. Training class-wise F1 99.82803197068861.\n",
            "-----Starting epoch 25------\n",
            "-----Starting epoch 26------\n",
            "-----Starting epoch 27------\n",
            "-----Starting epoch 28------\n",
            "[[16.  6.]\n",
            " [17. 26.]]\n",
            "####################Iteration 1600.#############\n",
            "                       Validation Loss 2.4234662606165958. Validation Accuracy 64.61538696289062. \n",
            "                       Validation Precision [52.63157894736842, 59.09090909090909, 77.77777777777777, 65.0, 65.0, 63.888888888888886, 65.78947368421052, 60.46511627906977]. Validation Recall [93.75, 81.25, 43.75, 81.25, 81.25, 71.875, 78.125, 81.25]. \n",
            "                       Validation F1 [67.41573033707866, 68.42105263157895, 55.99999999999999, 72.22222222222223, 72.22222222222223, 67.6470588235294, 71.42857142857142, 69.33333333333333]. Validation class-wise F1 63.75757575757576. \n",
            "                       Time passed -0.040496826171875###############################\n",
            "[[298.   0.]\n",
            " [  1. 283.]]\n",
            "######################Iteration 1600######################. \n",
            "                      Training Loss 0.009570115627916478. Training Accuracy 99.82817840576172. Training Precision 99.64788732394366. \n",
            "                      Training Recall 100.0. Training F1 99.8236331569665. Training class-wise F1 99.82806448468091.\n",
            "-----Starting epoch 29------\n",
            "-----Starting epoch 30------\n",
            "Training done for fold 0\n",
            "val_f1:  [67.41573033707866, 68.42105263157895, 55.99999999999999, 72.22222222222223, 72.22222222222223, 67.6470588235294, 71.42857142857142, 69.33333333333333]\n",
            "-----Starting epoch 1------\n",
            "-----Starting epoch 2------\n",
            "-----Starting epoch 3------\n",
            "-----Starting epoch 4------\n",
            "[[26. 11.]\n",
            " [ 5. 23.]]\n",
            "####################Iteration 200.#############\n",
            "                       Validation Loss 0.6498615879278916. Validation Accuracy 75.38461303710938. \n",
            "                       Validation Precision [82.14285714285714]. Validation Recall [67.6470588235294]. \n",
            "                       Validation F1 [74.19354838709675]. Validation class-wise F1 75.33206831119543. \n",
            "                       Time passed -0.12956881523132324###############################\n",
            "[[272.  79.]\n",
            " [ 29. 202.]]\n",
            "######################Iteration 200######################. \n",
            "                      Training Loss 0.42679979808346924. Training Accuracy 81.44329833984375. Training Precision 87.44588744588745. \n",
            "                      Training Recall 71.88612099644128. Training F1 78.90625. Training class-wise F1 81.17091641104294.\n",
            "-----Starting epoch 5------\n",
            "-----Starting epoch 6------\n",
            "-----Starting epoch 7------\n",
            "[[25. 10.]\n",
            " [ 6. 24.]]\n",
            "####################Iteration 400.#############\n",
            "                       Validation Loss 0.6523813238510718. Validation Accuracy 75.38461303710938. \n",
            "                       Validation Precision [82.14285714285714, 80.0]. Validation Recall [67.6470588235294, 70.58823529411765]. \n",
            "                       Validation F1 [74.19354838709675, 75.00000000000001]. Validation class-wise F1 75.37878787878788. \n",
            "                       Time passed -0.2983863353729248###############################\n",
            "[[289.  46.]\n",
            " [ 12. 235.]]\n",
            "######################Iteration 400######################. \n",
            "                      Training Loss 0.22649376809315377. Training Accuracy 90.03436279296875. Training Precision 95.1417004048583. \n",
            "                      Training Recall 83.62989323843416. Training F1 89.0151515151515. Training class-wise F1 89.9478273299028.\n",
            "-----Starting epoch 8------\n",
            "-----Starting epoch 9------\n",
            "-----Starting epoch 10------\n",
            "-----Starting epoch 11------\n",
            "[[16.  8.]\n",
            " [15. 26.]]\n",
            "####################Iteration 600.#############\n",
            "                       Validation Loss 1.1795751589995165. Validation Accuracy 64.61538696289062. \n",
            "                       Validation Precision [82.14285714285714, 80.0, 63.41463414634146]. Validation Recall [67.6470588235294, 70.58823529411765, 76.47058823529412]. \n",
            "                       Validation F1 [74.19354838709675, 75.00000000000001, 69.33333333333333]. Validation class-wise F1 63.75757575757575. \n",
            "                       Time passed -0.05950045585632324###############################\n",
            "[[250.   3.]\n",
            " [ 51. 278.]]\n",
            "######################Iteration 600######################. \n",
            "                      Training Loss 0.21791677875924356. Training Accuracy 90.72164916992188. Training Precision 84.4984802431611. \n",
            "                      Training Recall 98.932384341637. Training F1 91.14754098360656. Training class-wise F1 90.700124282417.\n",
            "-----Starting epoch 12------\n",
            "-----Starting epoch 13------\n",
            "-----Starting epoch 14------\n",
            "[[25. 12.]\n",
            " [ 6. 22.]]\n",
            "####################Iteration 800.#############\n",
            "                       Validation Loss 1.3665517843686616. Validation Accuracy 72.30769348144531. \n",
            "                       Validation Precision [82.14285714285714, 80.0, 63.41463414634146, 78.57142857142857]. Validation Recall [67.6470588235294, 70.58823529411765, 76.47058823529412, 64.70588235294117]. \n",
            "                       Validation F1 [74.19354838709675, 75.00000000000001, 69.33333333333333, 70.96774193548387]. Validation class-wise F1 72.24857685009488. \n",
            "                       Time passed -0.18386244773864746###############################\n",
            "[[300.   5.]\n",
            " [  1. 276.]]\n",
            "######################Iteration 800######################. \n",
            "                      Training Loss 0.03323718368158199. Training Accuracy 98.96907043457031. Training Precision 99.63898916967509. \n",
            "                      Training Recall 98.22064056939502. Training F1 98.9247311827957. Training class-wise F1 98.96731608644735.\n",
            "-----Starting epoch 15------\n",
            "-----Starting epoch 16------\n",
            "-----Starting epoch 17------\n",
            "[[20.  9.]\n",
            " [11. 25.]]\n",
            "####################Iteration 1000.#############\n",
            "                       Validation Loss 1.726375964971689. Validation Accuracy 69.23076629638672. \n",
            "                       Validation Precision [82.14285714285714, 80.0, 63.41463414634146, 78.57142857142857, 69.44444444444444]. Validation Recall [67.6470588235294, 70.58823529411765, 76.47058823529412, 64.70588235294117, 73.52941176470588]. \n",
            "                       Validation F1 [74.19354838709675, 75.00000000000001, 69.33333333333333, 70.96774193548387, 71.42857142857143]. Validation class-wise F1 69.04761904761905. \n",
            "                       Time passed -0.3166844844818115###############################\n",
            "[[296.   2.]\n",
            " [  5. 279.]]\n",
            "######################Iteration 1000######################. \n",
            "                      Training Loss 0.030971547784656807. Training Accuracy 98.79724884033203. Training Precision 98.2394366197183. \n",
            "                      Training Recall 99.28825622775801. Training F1 98.76106194690264. Training class-wise F1 98.79622379482026.\n",
            "-----Starting epoch 18------\n",
            "-----Starting epoch 19------\n",
            "-----Starting epoch 20------\n",
            "-----Starting epoch 21------\n",
            "[[25. 13.]\n",
            " [ 6. 21.]]\n",
            "####################Iteration 1200.#############\n",
            "                       Validation Loss 1.7998326470215733. Validation Accuracy 70.76923370361328. \n",
            "                       Validation Precision [82.14285714285714, 80.0, 63.41463414634146, 78.57142857142857, 69.44444444444444, 77.77777777777777]. Validation Recall [67.6470588235294, 70.58823529411765, 76.47058823529412, 64.70588235294117, 73.52941176470588, 61.76470588235294]. \n",
            "                       Validation F1 [74.19354838709675, 75.00000000000001, 69.33333333333333, 70.96774193548387, 71.42857142857143, 68.85245901639345]. Validation class-wise F1 70.65811356616774. \n",
            "                       Time passed -0.11322927474975586###############################\n",
            "[[300.   3.]\n",
            " [  1. 278.]]\n",
            "######################Iteration 1200######################. \n",
            "                      Training Loss 0.03131281138322543. Training Accuracy 99.31271362304688. Training Precision 99.6415770609319. \n",
            "                      Training Recall 98.932384341637. Training F1 99.28571428571428. Training class-wise F1 99.31173131504258.\n",
            "-----Starting epoch 22------\n",
            "-----Starting epoch 23------\n",
            "-----Starting epoch 24------\n",
            "[[24. 12.]\n",
            " [ 7. 22.]]\n",
            "####################Iteration 1400.#############\n",
            "                       Validation Loss 1.731344929108253. Validation Accuracy 70.76923370361328. \n",
            "                       Validation Precision [82.14285714285714, 80.0, 63.41463414634146, 78.57142857142857, 69.44444444444444, 77.77777777777777, 75.86206896551724]. Validation Recall [67.6470588235294, 70.58823529411765, 76.47058823529412, 64.70588235294117, 73.52941176470588, 61.76470588235294, 64.70588235294117]. \n",
            "                       Validation F1 [74.19354838709675, 75.00000000000001, 69.33333333333333, 70.96774193548387, 71.42857142857143, 68.85245901639345, 69.84126984126983]. Validation class-wise F1 70.74153044302298. \n",
            "                       Time passed -0.23728203773498535###############################\n",
            "[[300.   2.]\n",
            " [  1. 279.]]\n",
            "######################Iteration 1400######################. \n",
            "                      Training Loss 0.00917689171898875. Training Accuracy 99.48453521728516. Training Precision 99.64285714285714. \n",
            "                      Training Recall 99.28825622775801. Training F1 99.46524064171122. Training class-wise F1 99.48386410195013.\n",
            "-----Starting epoch 25------\n",
            "-----Starting epoch 26------\n",
            "-----Starting epoch 27------\n",
            "-----Starting epoch 28------\n",
            "[[22. 12.]\n",
            " [ 9. 22.]]\n",
            "####################Iteration 1600.#############\n",
            "                       Validation Loss 1.8631043342443614. Validation Accuracy 67.69230651855469. \n",
            "                       Validation Precision [82.14285714285714, 80.0, 63.41463414634146, 78.57142857142857, 69.44444444444444, 77.77777777777777, 75.86206896551724, 70.96774193548387]. Validation Recall [67.6470588235294, 70.58823529411765, 76.47058823529412, 64.70588235294117, 73.52941176470588, 61.76470588235294, 64.70588235294117, 64.70588235294117]. \n",
            "                       Validation F1 [74.19354838709675, 75.00000000000001, 69.33333333333333, 70.96774193548387, 71.42857142857143, 68.85245901639345, 69.84126984126983, 67.69230769230768]. Validation class-wise F1 67.69230769230768. \n",
            "                       Time passed -0.042350053787231445###############################\n",
            "[[300.   1.]\n",
            " [  1. 280.]]\n",
            "######################Iteration 1600######################. \n",
            "                      Training Loss 0.008231085408111927. Training Accuracy 99.65635681152344. Training Precision 99.644128113879. \n",
            "                      Training Recall 99.644128113879. Training F1 99.644128113879. Training class-wise F1 99.65595110012887.\n",
            "-----Starting epoch 29------\n",
            "-----Starting epoch 30------\n",
            "Training done for fold 1\n",
            "val_f1:  [74.19354838709675, 75.00000000000001, 69.33333333333333, 70.96774193548387, 71.42857142857143, 68.85245901639345, 69.84126984126983, 67.69230769230768]\n",
            "-----Starting epoch 1------\n",
            "-----Starting epoch 2------\n",
            "-----Starting epoch 3------\n",
            "-----Starting epoch 4------\n",
            "[[30. 13.]\n",
            " [ 3. 19.]]\n",
            "####################Iteration 200.#############\n",
            "                       Validation Loss 0.4817296083156879. Validation Accuracy 75.38461303710938. \n",
            "                       Validation Precision [86.36363636363636]. Validation Recall [59.375]. \n",
            "                       Validation F1 [70.37037037037037]. Validation class-wise F1 74.65886939571149. \n",
            "                       Time passed -0.13345098495483398###############################\n",
            "[[260.  63.]\n",
            " [ 39. 220.]]\n",
            "######################Iteration 200######################. \n",
            "                      Training Loss 0.4019184748536533. Training Accuracy 82.47422790527344. Training Precision 84.94208494208495. \n",
            "                      Training Recall 77.73851590106007. Training F1 81.18081180811808. Training class-wise F1 82.39104899087576.\n",
            "-----Starting epoch 5------\n",
            "-----Starting epoch 6------\n",
            "-----Starting epoch 7------\n",
            "[[24.  6.]\n",
            " [ 9. 26.]]\n",
            "####################Iteration 400.#############\n",
            "                       Validation Loss 0.4170405933490166. Validation Accuracy 76.92308044433594. \n",
            "                       Validation Precision [86.36363636363636, 74.28571428571429]. Validation Recall [59.375, 81.25]. \n",
            "                       Validation F1 [70.37037037037037, 77.61194029850748]. Validation class-wise F1 76.90120824449184. \n",
            "                       Time passed -0.2577974796295166###############################\n",
            "[[245.  20.]\n",
            " [ 54. 263.]]\n",
            "######################Iteration 400######################. \n",
            "                      Training Loss 0.30926083192178067. Training Accuracy 87.28522491455078. Training Precision 82.96529968454259. \n",
            "                      Training Recall 92.93286219081273. Training F1 87.66666666666667. Training class-wise F1 87.27304964539007.\n",
            "-----Starting epoch 8------\n",
            "-----Starting epoch 9------\n",
            "-----Starting epoch 10------\n",
            "-----Starting epoch 11------\n",
            "[[26.  8.]\n",
            " [ 7. 24.]]\n",
            "####################Iteration 600.#############\n",
            "                       Validation Loss 0.5569777282384726. Validation Accuracy 76.92308044433594. \n",
            "                       Validation Precision [86.36363636363636, 74.28571428571429, 77.41935483870968]. Validation Recall [59.375, 81.25, 75.0]. \n",
            "                       Validation F1 [70.37037037037037, 77.61194029850748, 76.19047619047619]. Validation class-wise F1 76.90120824449181. \n",
            "                       Time passed -0.056760311126708984###############################\n",
            "[[295.  13.]\n",
            " [  4. 270.]]\n",
            "######################Iteration 600######################. \n",
            "                      Training Loss 0.10663636337287237. Training Accuracy 97.07904052734375. Training Precision 98.54014598540147. \n",
            "                      Training Recall 95.40636042402826. Training F1 96.94793536804308. Training class-wise F1 97.07363819472994.\n",
            "-----Starting epoch 12------\n",
            "-----Starting epoch 13------\n",
            "-----Starting epoch 14------\n",
            "[[30. 12.]\n",
            " [ 3. 20.]]\n",
            "####################Iteration 800.#############\n",
            "                       Validation Loss 0.7692167988190284. Validation Accuracy 76.92308044433594. \n",
            "                       Validation Precision [86.36363636363636, 74.28571428571429, 77.41935483870968, 86.95652173913044]. Validation Recall [59.375, 81.25, 75.0, 62.5]. \n",
            "                       Validation F1 [70.37037037037037, 77.61194029850748, 76.19047619047619, 72.72727272727272]. Validation class-wise F1 76.36363636363637. \n",
            "                       Time passed -0.1790163516998291###############################\n",
            "[[298.  31.]\n",
            " [  1. 252.]]\n",
            "######################Iteration 800######################. \n",
            "                      Training Loss 0.10734787126125958. Training Accuracy 94.50171661376953. Training Precision 99.60474308300395. \n",
            "                      Training Recall 89.04593639575971. Training F1 94.02985074626865. Training class-wise F1 94.46715467249737.\n",
            "-----Starting epoch 15------\n",
            "-----Starting epoch 16------\n",
            "-----Starting epoch 17------\n",
            "[[24.  7.]\n",
            " [ 9. 25.]]\n",
            "####################Iteration 1000.#############\n",
            "                       Validation Loss 0.7135221866460947. Validation Accuracy 75.38461303710938. \n",
            "                       Validation Precision [86.36363636363636, 74.28571428571429, 77.41935483870968, 86.95652173913044, 73.52941176470588]. Validation Recall [59.375, 81.25, 75.0, 62.5, 78.125]. \n",
            "                       Validation F1 [70.37037037037037, 77.61194029850748, 76.19047619047619, 72.72727272727272, 75.75757575757575]. Validation class-wise F1 75.37878787878788. \n",
            "                       Time passed -0.32255029678344727###############################\n",
            "[[293.   4.]\n",
            " [  6. 279.]]\n",
            "######################Iteration 1000######################. \n",
            "                      Training Loss 0.05340235926064061. Training Accuracy 98.28179168701172. Training Precision 97.89473684210526. \n",
            "                      Training Recall 98.58657243816255. Training F1 98.23943661971832. Training class-wise F1 98.2807921353625.\n",
            "-----Starting epoch 18------\n",
            "-----Starting epoch 19------\n",
            "-----Starting epoch 20------\n",
            "-----Starting epoch 21------\n",
            "[[26. 12.]\n",
            " [ 7. 20.]]\n",
            "####################Iteration 1200.#############\n",
            "                       Validation Loss 0.8516492989773934. Validation Accuracy 70.76923370361328. \n",
            "                       Validation Precision [86.36363636363636, 74.28571428571429, 77.41935483870968, 86.95652173913044, 73.52941176470588, 74.07407407407408]. Validation Recall [59.375, 81.25, 75.0, 62.5, 78.125, 62.5]. \n",
            "                       Validation F1 [70.37037037037037, 77.61194029850748, 76.19047619047619, 72.72727272727272, 75.75757575757575, 67.79661016949153]. Validation class-wise F1 70.51802339460492. \n",
            "                       Time passed -0.11258578300476074###############################\n",
            "[[299.   3.]\n",
            " [  0. 280.]]\n",
            "######################Iteration 1200######################. \n",
            "                      Training Loss 0.0176169302626961. Training Accuracy 99.48453521728516. Training Precision 100.0. \n",
            "                      Training Recall 98.93992932862191. Training F1 99.4671403197158. Training class-wise F1 99.4839861332356.\n",
            "-----Starting epoch 22------\n",
            "-----Starting epoch 23------\n",
            "-----Starting epoch 24------\n",
            "[[29. 16.]\n",
            " [ 4. 16.]]\n",
            "####################Iteration 1400.#############\n",
            "                       Validation Loss 1.2878319162588854. Validation Accuracy 69.23076629638672. \n",
            "                       Validation Precision [86.36363636363636, 74.28571428571429, 77.41935483870968, 86.95652173913044, 73.52941176470588, 74.07407407407408, 80.0]. Validation Recall [59.375, 81.25, 75.0, 62.5, 78.125, 62.5, 50.0]. \n",
            "                       Validation F1 [70.37037037037037, 77.61194029850748, 76.19047619047619, 72.72727272727272, 75.75757575757575, 67.79661016949153, 61.53846153846154]. Validation class-wise F1 67.94871794871794. \n",
            "                       Time passed -0.243821382522583###############################\n",
            "[[299.   5.]\n",
            " [  0. 278.]]\n",
            "######################Iteration 1400######################. \n",
            "                      Training Loss 0.01923989479522432. Training Accuracy 99.1408920288086. Training Precision 100.0. \n",
            "                      Training Recall 98.23321554770318. Training F1 99.10873440285205. Training class-wise F1 99.13977350325024.\n",
            "-----Starting epoch 25------\n",
            "-----Starting epoch 26------\n",
            "-----Starting epoch 27------\n",
            "-----Starting epoch 28------\n",
            "[[28. 11.]\n",
            " [ 5. 21.]]\n",
            "####################Iteration 1600.#############\n",
            "                       Validation Loss 0.966343879699707. Validation Accuracy 75.38461303710938. \n",
            "                       Validation Precision [86.36363636363636, 74.28571428571429, 77.41935483870968, 86.95652173913044, 73.52941176470588, 74.07407407407408, 80.0, 80.76923076923077]. Validation Recall [59.375, 81.25, 75.0, 62.5, 78.125, 62.5, 50.0, 65.625]. \n",
            "                       Validation F1 [70.37037037037037, 77.61194029850748, 76.19047619047619, 72.72727272727272, 75.75757575757575, 67.79661016949153, 61.53846153846154, 72.41379310344827]. Validation class-wise F1 75.09578544061301. \n",
            "                       Time passed -0.04169034957885742###############################\n",
            "[[299.   2.]\n",
            " [  0. 281.]]\n",
            "######################Iteration 1600######################. \n",
            "                      Training Loss 0.009069159343085893. Training Accuracy 99.65635681152344. Training Precision 100.0. \n",
            "                      Training Recall 99.29328621908127. Training F1 99.64539007092199. Training class-wise F1 99.65602836879432.\n",
            "-----Starting epoch 29------\n",
            "-----Starting epoch 30------\n",
            "Training done for fold 2\n",
            "val_f1:  [70.37037037037037, 77.61194029850748, 76.19047619047619, 72.72727272727272, 75.75757575757575, 67.79661016949153, 61.53846153846154, 72.41379310344827]\n",
            "-----Starting epoch 1------\n",
            "-----Starting epoch 2------\n",
            "-----Starting epoch 3------\n",
            "-----Starting epoch 4------\n",
            "[[22.  7.]\n",
            " [10. 26.]]\n",
            "####################Iteration 200.#############\n",
            "                       Validation Loss 0.48035276394623977. Validation Accuracy 73.84615325927734. \n",
            "                       Validation Precision [72.22222222222223]. Validation Recall [78.78787878787878]. \n",
            "                       Validation F1 [75.36231884057972]. Validation class-wise F1 73.74673319078167. \n",
            "                       Time passed -0.13353657722473145###############################\n",
            "[[223.  29.]\n",
            " [ 77. 253.]]\n",
            "######################Iteration 200######################. \n",
            "                      Training Loss 0.40052165756725366. Training Accuracy 81.78694152832031. Training Precision 76.66666666666667. \n",
            "                      Training Recall 89.71631205673759. Training F1 82.6797385620915. Training class-wise F1 81.73842000568342.\n",
            "-----Starting epoch 5------\n",
            "-----Starting epoch 6------\n",
            "-----Starting epoch 7------\n",
            "[[30. 12.]\n",
            " [ 2. 21.]]\n",
            "####################Iteration 400.#############\n",
            "                       Validation Loss 0.5018707926456745. Validation Accuracy 78.46154022216797. \n",
            "                       Validation Precision [72.22222222222223, 91.30434782608695]. Validation Recall [78.78787878787878, 63.63636363636363]. \n",
            "                       Validation F1 [75.36231884057972, 75.0]. Validation class-wise F1 78.04054054054055. \n",
            "                       Time passed -0.25742435455322266###############################\n",
            "[[292.  35.]\n",
            " [  8. 247.]]\n",
            "######################Iteration 400######################. \n",
            "                      Training Loss 0.1798563104289299. Training Accuracy 92.61168670654297. Training Precision 96.86274509803921. \n",
            "                      Training Recall 87.58865248226951. Training F1 91.99255121042832. Training class-wise F1 92.56724849197653.\n",
            "-----Starting epoch 8------\n",
            "-----Starting epoch 9------\n",
            "-----Starting epoch 10------\n",
            "-----Starting epoch 11------\n",
            "[[30. 15.]\n",
            " [ 2. 18.]]\n",
            "####################Iteration 600.#############\n",
            "                       Validation Loss 0.7366777933560885. Validation Accuracy 73.84615325927734. \n",
            "                       Validation Precision [72.22222222222223, 91.30434782608695, 90.0]. Validation Recall [78.78787878787878, 63.63636363636363, 54.54545454545455]. \n",
            "                       Validation F1 [75.36231884057972, 75.0, 67.92452830188678]. Validation class-wise F1 72.92330311198235. \n",
            "                       Time passed -0.05627584457397461###############################\n",
            "[[299.  25.]\n",
            " [  1. 257.]]\n",
            "######################Iteration 600######################. \n",
            "                      Training Loss 0.10404921606458288. Training Accuracy 95.53264617919922. Training Precision 99.6124031007752. \n",
            "                      Training Recall 91.13475177304964. Training F1 95.18518518518518. Training class-wise F1 95.50925925925925.\n",
            "-----Starting epoch 12------\n",
            "-----Starting epoch 13------\n",
            "-----Starting epoch 14------\n",
            "[[28. 11.]\n",
            " [ 4. 22.]]\n",
            "####################Iteration 800.#############\n",
            "                       Validation Loss 0.8222707498532075. Validation Accuracy 76.92308044433594. \n",
            "                       Validation Precision [72.22222222222223, 91.30434782608695, 90.0, 84.61538461538461]. Validation Recall [78.78787878787878, 63.63636363636363, 54.54545454545455, 66.66666666666667]. \n",
            "                       Validation F1 [75.36231884057972, 75.0, 67.92452830188678, 74.57627118644069]. Validation class-wise F1 76.7247553115302. \n",
            "                       Time passed -0.17929911613464355###############################\n",
            "[[300.   5.]\n",
            " [  0. 277.]]\n",
            "######################Iteration 800######################. \n",
            "                      Training Loss 0.023621598038385556. Training Accuracy 99.1408920288086. Training Precision 100.0. \n",
            "                      Training Recall 98.22695035460993. Training F1 99.10554561717352. Training class-wise F1 99.1395496680909.\n",
            "-----Starting epoch 15------\n",
            "-----Starting epoch 16------\n",
            "-----Starting epoch 17------\n",
            "[[23.  8.]\n",
            " [ 9. 25.]]\n",
            "####################Iteration 1000.#############\n",
            "                       Validation Loss 0.771591995197993. Validation Accuracy 73.84615325927734. \n",
            "                       Validation Precision [72.22222222222223, 91.30434782608695, 90.0, 84.61538461538461, 73.52941176470588]. Validation Recall [78.78787878787878, 63.63636363636363, 54.54545454545455, 66.66666666666667, 75.75757575757575]. \n",
            "                       Validation F1 [75.36231884057972, 75.0, 67.92452830188678, 74.57627118644069, 74.6268656716418]. Validation class-wise F1 73.8213693437574. \n",
            "                       Time passed -0.31969428062438965###############################\n",
            "[[298.   0.]\n",
            " [  2. 282.]]\n",
            "######################Iteration 1000######################. \n",
            "                      Training Loss 0.019863337336473736. Training Accuracy 99.65635681152344. Training Precision 99.29577464788733. \n",
            "                      Training Recall 100.0. Training F1 99.64664310954063. Training class-wise F1 99.65609747450276.\n",
            "-----Starting epoch 18------\n",
            "-----Starting epoch 19------\n",
            "-----Starting epoch 20------\n",
            "-----Starting epoch 21------\n",
            "[[26.  8.]\n",
            " [ 6. 25.]]\n",
            "####################Iteration 1200.#############\n",
            "                       Validation Loss 0.6231730247919376. Validation Accuracy 78.46154022216797. \n",
            "                       Validation Precision [72.22222222222223, 91.30434782608695, 90.0, 84.61538461538461, 73.52941176470588, 80.64516129032258]. Validation Recall [78.78787878787878, 63.63636363636363, 54.54545454545455, 66.66666666666667, 75.75757575757575, 75.75757575757575]. \n",
            "                       Validation F1 [75.36231884057972, 75.0, 67.92452830188678, 74.57627118644069, 74.6268656716418, 78.125]. Validation class-wise F1 78.45643939393939. \n",
            "                       Time passed -0.11007380485534668###############################\n",
            "[[298.   1.]\n",
            " [  2. 281.]]\n",
            "######################Iteration 1200######################. \n",
            "                      Training Loss 0.0225339561640413. Training Accuracy 99.48453521728516. Training Precision 99.29328621908127. \n",
            "                      Training Recall 99.64539007092199. Training F1 99.46902654867257. Training class-wise F1 99.48409591206584.\n",
            "-----Starting epoch 22------\n",
            "-----Starting epoch 23------\n",
            "-----Starting epoch 24------\n",
            "[[22.  6.]\n",
            " [10. 27.]]\n",
            "####################Iteration 1400.#############\n",
            "                       Validation Loss 0.899278883750622. Validation Accuracy 75.38461303710938. \n",
            "                       Validation Precision [72.22222222222223, 91.30434782608695, 90.0, 84.61538461538461, 73.52941176470588, 80.64516129032258, 72.97297297297297]. Validation Recall [78.78787878787878, 63.63636363636363, 54.54545454545455, 66.66666666666667, 75.75757575757575, 75.75757575757575, 81.81818181818181]. \n",
            "                       Validation F1 [75.36231884057972, 75.0, 67.92452830188678, 74.57627118644069, 74.6268656716418, 78.125, 77.14285714285714]. Validation class-wise F1 75.23809523809524. \n",
            "                       Time passed -0.2471776008605957###############################\n",
            "[[295.   0.]\n",
            " [  5. 282.]]\n",
            "######################Iteration 1400######################. \n",
            "                      Training Loss 0.030298428951512184. Training Accuracy 99.1408920288086. Training Precision 98.25783972125436. \n",
            "                      Training Recall 100.0. Training F1 99.12126537785588. Training class-wise F1 99.14046462170106.\n",
            "-----Starting epoch 25------\n",
            "-----Starting epoch 26------\n",
            "-----Starting epoch 27------\n",
            "-----Starting epoch 28------\n",
            "[[25. 10.]\n",
            " [ 7. 23.]]\n",
            "####################Iteration 1600.#############\n",
            "                       Validation Loss 1.157999222095196. Validation Accuracy 73.84615325927734. \n",
            "                       Validation Precision [72.22222222222223, 91.30434782608695, 90.0, 84.61538461538461, 73.52941176470588, 80.64516129032258, 72.97297297297297, 76.66666666666667]. Validation Recall [78.78787878787878, 63.63636363636363, 54.54545454545455, 66.66666666666667, 75.75757575757575, 75.75757575757575, 81.81818181818181, 69.6969696969697]. \n",
            "                       Validation F1 [75.36231884057972, 75.0, 67.92452830188678, 74.57627118644069, 74.6268656716418, 78.125, 77.14285714285714, 73.01587301587303]. Validation class-wise F1 73.8213693437574. \n",
            "                       Time passed -0.03870391845703125###############################\n",
            "[[299.   1.]\n",
            " [  1. 281.]]\n",
            "######################Iteration 1600######################. \n",
            "                      Training Loss 0.007836089233511378. Training Accuracy 99.65635681152344. Training Precision 99.64539007092199. \n",
            "                      Training Recall 99.64539007092199. Training F1 99.645390070922. Training class-wise F1 99.65602836879434.\n",
            "-----Starting epoch 29------\n",
            "-----Starting epoch 30------\n",
            "Training done for fold 3\n",
            "val_f1:  [75.36231884057972, 75.0, 67.92452830188678, 74.57627118644069, 74.6268656716418, 78.125, 77.14285714285714, 73.01587301587303]\n",
            "-----Starting epoch 1------\n",
            "-----Starting epoch 2------\n",
            "-----Starting epoch 3------\n",
            "-----Starting epoch 4------\n",
            "[[31.  5.]\n",
            " [ 5. 24.]]\n",
            "####################Iteration 200.#############\n",
            "                       Validation Loss 0.44969242352705735. Validation Accuracy 84.61538696289062. \n",
            "                       Validation Precision [82.75862068965517]. Validation Recall [82.75862068965517]. \n",
            "                       Validation F1 [82.75862068965517]. Validation class-wise F1 84.43486590038314. \n",
            "                       Time passed -0.13414382934570312###############################\n",
            "[[246.  44.]\n",
            " [ 50. 242.]]\n",
            "######################Iteration 200######################. \n",
            "                      Training Loss 0.3857736377576782. Training Accuracy 83.84880065917969. Training Precision 82.87671232876713. \n",
            "                      Training Recall 84.61538461538461. Training F1 83.73702422145328. Training class-wise F1 83.84803429502699.\n",
            "-----Starting epoch 5------\n",
            "-----Starting epoch 6------\n",
            "-----Starting epoch 7------\n",
            "[[34. 10.]\n",
            " [ 2. 19.]]\n",
            "####################Iteration 400.#############\n",
            "                       Validation Loss 0.482092630977814. Validation Accuracy 81.53845977783203. \n",
            "                       Validation Precision [82.75862068965517, 90.47619047619048]. Validation Recall [82.75862068965517, 65.51724137931035]. \n",
            "                       Validation F1 [82.75862068965517, 76.0]. Validation class-wise F1 80.5. \n",
            "                       Time passed -0.2655336856842041###############################\n",
            "[[294.  85.]\n",
            " [  2. 201.]]\n",
            "######################Iteration 400######################. \n",
            "                      Training Loss 0.32343826307739126. Training Accuracy 85.05154418945312. Training Precision 99.01477832512315. \n",
            "                      Training Recall 70.27972027972028. Training F1 82.20858895705521. Training class-wise F1 84.65985003408316.\n",
            "-----Starting epoch 8------\n",
            "-----Starting epoch 9------\n",
            "-----Starting epoch 10------\n",
            "-----Starting epoch 11------\n",
            "[[22.  3.]\n",
            " [14. 26.]]\n",
            "####################Iteration 600.#############\n",
            "                       Validation Loss 0.6206538356267489. Validation Accuracy 73.84615325927734. \n",
            "                       Validation Precision [82.75862068965517, 90.47619047619048, 65.0]. Validation Recall [82.75862068965517, 65.51724137931035, 89.65517241379311]. \n",
            "                       Validation F1 [82.75862068965517, 76.0, 75.36231884057972]. Validation class-wise F1 73.74673319078167. \n",
            "                       Time passed -0.056871891021728516###############################\n",
            "[[206.   5.]\n",
            " [ 90. 281.]]\n",
            "######################Iteration 600######################. \n",
            "                      Training Loss 0.3242397741558625. Training Accuracy 83.6769790649414. Training Precision 75.74123989218329. \n",
            "                      Training Recall 98.25174825174825. Training F1 85.54033485540334. Training class-wise F1 83.40133113578845.\n",
            "-----Starting epoch 12------\n",
            "-----Starting epoch 13------\n",
            "-----Starting epoch 14------\n",
            "[[33.  6.]\n",
            " [ 3. 23.]]\n",
            "####################Iteration 800.#############\n",
            "                       Validation Loss 0.621695764362812. Validation Accuracy 86.15384674072266. \n",
            "                       Validation Precision [82.75862068965517, 90.47619047619048, 65.0, 88.46153846153847]. Validation Recall [82.75862068965517, 65.51724137931035, 89.65517241379311, 79.3103448275862]. \n",
            "                       Validation F1 [82.75862068965517, 76.0, 75.36231884057972, 83.63636363636364]. Validation class-wise F1 85.81818181818183. \n",
            "                       Time passed -0.19028711318969727###############################\n",
            "[[295.   6.]\n",
            " [  1. 280.]]\n",
            "######################Iteration 800######################. \n",
            "                      Training Loss 0.03837177481224658. Training Accuracy 98.79724884033203. Training Precision 99.644128113879. \n",
            "                      Training Recall 97.9020979020979. Training F1 98.76543209876543. Training class-wise F1 98.7964513927663.\n",
            "-----Starting epoch 15------\n",
            "-----Starting epoch 16------\n",
            "-----Starting epoch 17------\n",
            "[[27.  3.]\n",
            " [ 9. 26.]]\n",
            "####################Iteration 1000.#############\n",
            "                       Validation Loss 0.77603395569783. Validation Accuracy 81.53845977783203. \n",
            "                       Validation Precision [82.75862068965517, 90.47619047619048, 65.0, 88.46153846153847, 74.28571428571429]. Validation Recall [82.75862068965517, 65.51724137931035, 89.65517241379311, 79.3103448275862, 89.65517241379311]. \n",
            "                       Validation F1 [82.75862068965517, 76.0, 75.36231884057972, 83.63636363636364, 81.25]. Validation class-wise F1 81.5340909090909. \n",
            "                       Time passed -0.3262145519256592###############################\n",
            "[[293.   3.]\n",
            " [  3. 283.]]\n",
            "######################Iteration 1000######################. \n",
            "                      Training Loss 0.024293625626582622. Training Accuracy 98.96907043457031. Training Precision 98.95104895104895. \n",
            "                      Training Recall 98.95104895104895. Training F1 98.95104895104895. Training class-wise F1 98.96876771876771.\n",
            "-----Starting epoch 18------\n",
            "-----Starting epoch 19------\n",
            "-----Starting epoch 20------\n",
            "-----Starting epoch 21------\n",
            "[[28.  4.]\n",
            " [ 8. 25.]]\n",
            "####################Iteration 1200.#############\n",
            "                       Validation Loss 0.7862903667757144. Validation Accuracy 81.53845977783203. \n",
            "                       Validation Precision [82.75862068965517, 90.47619047619048, 65.0, 88.46153846153847, 74.28571428571429, 75.75757575757575]. Validation Recall [82.75862068965517, 65.51724137931035, 89.65517241379311, 79.3103448275862, 89.65517241379311, 86.20689655172414]. \n",
            "                       Validation F1 [82.75862068965517, 76.0, 75.36231884057972, 83.63636363636364, 81.25, 80.64516129032258]. Validation class-wise F1 81.49905123339659. \n",
            "                       Time passed -0.11159110069274902###############################\n",
            "[[294.   1.]\n",
            " [  2. 285.]]\n",
            "######################Iteration 1200######################. \n",
            "                      Training Loss 0.019308586548285756. Training Accuracy 99.48453521728516. Training Precision 99.30313588850174. \n",
            "                      Training Recall 99.65034965034965. Training F1 99.47643979057592. Training class-wise F1 99.48441278868897.\n",
            "-----Starting epoch 22------\n",
            "-----Starting epoch 23------\n",
            "-----Starting epoch 24------\n",
            "[[32.  5.]\n",
            " [ 4. 24.]]\n",
            "####################Iteration 1400.#############\n",
            "                       Validation Loss 0.7667685378915988. Validation Accuracy 86.15384674072266. \n",
            "                       Validation Precision [82.75862068965517, 90.47619047619048, 65.0, 88.46153846153847, 74.28571428571429, 75.75757575757575, 85.71428571428571]. Validation Recall [82.75862068965517, 65.51724137931035, 89.65517241379311, 79.3103448275862, 89.65517241379311, 86.20689655172414, 82.75862068965517]. \n",
            "                       Validation F1 [82.75862068965517, 76.0, 75.36231884057972, 83.63636363636364, 81.25, 80.64516129032258, 84.21052631578947]. Validation class-wise F1 85.9408795962509. \n",
            "                       Time passed -0.25420546531677246###############################\n",
            "[[295.   3.]\n",
            " [  1. 283.]]\n",
            "######################Iteration 1400######################. \n",
            "                      Training Loss 0.012798602974569966. Training Accuracy 99.31271362304688. Training Precision 99.64788732394366. \n",
            "                      Training Recall 98.95104895104895. Training F1 99.29824561403508. Training class-wise F1 99.31242247031722.\n",
            "-----Starting epoch 25------\n",
            "-----Starting epoch 26------\n",
            "-----Starting epoch 27------\n",
            "-----Starting epoch 28------\n",
            "[[27.  5.]\n",
            " [ 9. 24.]]\n",
            "####################Iteration 1600.#############\n",
            "                       Validation Loss 0.7826914778695657. Validation Accuracy 78.46154022216797. \n",
            "                       Validation Precision [82.75862068965517, 90.47619047619048, 65.0, 88.46153846153847, 74.28571428571429, 75.75757575757575, 85.71428571428571, 72.72727272727273]. Validation Recall [82.75862068965517, 65.51724137931035, 89.65517241379311, 79.3103448275862, 89.65517241379311, 86.20689655172414, 82.75862068965517, 82.75862068965517]. \n",
            "                       Validation F1 [82.75862068965517, 76.0, 75.36231884057972, 83.63636363636364, 81.25, 80.64516129032258, 84.21052631578947, 77.41935483870968]. Validation class-wise F1 78.415559772296. \n",
            "                       Time passed -0.041135549545288086###############################\n",
            "[[293.   3.]\n",
            " [  3. 283.]]\n",
            "######################Iteration 1600######################. \n",
            "                      Training Loss 0.0273313428213479. Training Accuracy 98.96907043457031. Training Precision 98.95104895104895. \n",
            "                      Training Recall 98.95104895104895. Training F1 98.95104895104895. Training class-wise F1 98.96876771876771.\n",
            "-----Starting epoch 29------\n",
            "-----Starting epoch 30------\n",
            "Training done for fold 4\n",
            "val_f1:  [82.75862068965517, 76.0, 75.36231884057972, 83.63636363636364, 81.25, 80.64516129032258, 84.21052631578947, 77.41935483870968]\n",
            "-----Starting epoch 1------\n",
            "-----Starting epoch 2------\n",
            "-----Starting epoch 3------\n",
            "-----Starting epoch 4------\n",
            "[[24. 10.]\n",
            " [10. 21.]]\n",
            "####################Iteration 200.#############\n",
            "                       Validation Loss 0.5951258035806509. Validation Accuracy 69.23076629638672. \n",
            "                       Validation Precision [67.74193548387096]. Validation Recall [67.74193548387096]. \n",
            "                       Validation F1 [67.74193548387096]. Validation class-wise F1 69.1650853889943. \n",
            "                       Time passed -0.13611245155334473###############################\n",
            "[[253.  33.]\n",
            " [ 45. 251.]]\n",
            "######################Iteration 200######################. \n",
            "                      Training Loss 0.3419612467903452. Training Accuracy 86.59793853759766. Training Precision 84.79729729729729. \n",
            "                      Training Recall 88.38028169014085. Training F1 86.55172413793103. Training class-wise F1 86.5977798771847.\n",
            "-----Starting epoch 5------\n",
            "-----Starting epoch 6------\n",
            "-----Starting epoch 7------\n",
            "[[28. 11.]\n",
            " [ 6. 20.]]\n",
            "####################Iteration 400.#############\n",
            "                       Validation Loss 0.732579366518901. Validation Accuracy 73.84615325927734. \n",
            "                       Validation Precision [67.74193548387096, 76.92307692307692]. Validation Recall [67.74193548387096, 64.51612903225806]. \n",
            "                       Validation F1 [67.74193548387096, 70.17543859649123]. Validation class-wise F1 73.44388368180726. \n",
            "                       Time passed -0.2788205146789551###############################\n",
            "[[295.  55.]\n",
            " [  3. 229.]]\n",
            "######################Iteration 400######################. \n",
            "                      Training Loss 0.2379305620015282. Training Accuracy 90.03436279296875. Training Precision 98.70689655172414. \n",
            "                      Training Recall 80.63380281690141. Training F1 88.75968992248062. Training class-wise F1 89.904536319265.\n",
            "-----Starting epoch 8------\n",
            "-----Starting epoch 9------\n",
            "-----Starting epoch 10------\n",
            "-----Starting epoch 11------\n",
            "[[28. 13.]\n",
            " [ 6. 18.]]\n",
            "####################Iteration 600.#############\n",
            "                       Validation Loss 0.9094397265177506. Validation Accuracy 70.76923370361328. \n",
            "                       Validation Precision [67.74193548387096, 76.92307692307692, 75.0]. Validation Recall [67.74193548387096, 64.51612903225806, 58.064516129032256]. \n",
            "                       Validation F1 [67.74193548387096, 70.17543859649123, 65.45454545454545]. Validation class-wise F1 70.06060606060606. \n",
            "                       Time passed -0.057630062103271484###############################\n",
            "[[295.  10.]\n",
            " [  3. 274.]]\n",
            "######################Iteration 600######################. \n",
            "                      Training Loss 0.07089024452857443. Training Accuracy 97.76632690429688. Training Precision 98.91696750902527. \n",
            "                      Training Recall 96.47887323943662. Training F1 97.68270944741533. Training class-wise F1 97.76341110845061.\n",
            "-----Starting epoch 12------\n",
            "-----Starting epoch 13------\n",
            "-----Starting epoch 14------\n",
            "[[25.  9.]\n",
            " [ 9. 22.]]\n",
            "####################Iteration 800.#############\n",
            "                       Validation Loss 1.1135518482098212. Validation Accuracy 72.30769348144531. \n",
            "                       Validation Precision [67.74193548387096, 76.92307692307692, 75.0, 70.96774193548387]. Validation Recall [67.74193548387096, 64.51612903225806, 58.064516129032256, 70.96774193548387]. \n",
            "                       Validation F1 [67.74193548387096, 70.17543859649123, 65.45454545454545, 70.96774193548387]. Validation class-wise F1 72.24857685009488. \n",
            "                       Time passed -0.18364167213439941###############################\n",
            "[[294.   3.]\n",
            " [  4. 281.]]\n",
            "######################Iteration 800######################. \n",
            "                      Training Loss 0.040549167604913734. Training Accuracy 98.79724884033203. Training Precision 98.59649122807018. \n",
            "                      Training Recall 98.94366197183099. Training F1 98.76977152899825. Training class-wise F1 98.79665047038148.\n",
            "-----Starting epoch 15------\n",
            "-----Starting epoch 16------\n",
            "-----Starting epoch 17------\n",
            "[[22.  8.]\n",
            " [12. 23.]]\n",
            "####################Iteration 1000.#############\n",
            "                       Validation Loss 1.2987454304328332. Validation Accuracy 69.23076629638672. \n",
            "                       Validation Precision [67.74193548387096, 76.92307692307692, 75.0, 70.96774193548387, 65.71428571428571]. Validation Recall [67.74193548387096, 64.51612903225806, 58.064516129032256, 70.96774193548387, 74.19354838709677]. \n",
            "                       Validation F1 [67.74193548387096, 70.17543859649123, 65.45454545454545, 70.96774193548387, 69.69696969696969]. Validation class-wise F1 69.22348484848484. \n",
            "                       Time passed -0.3282904624938965###############################\n",
            "[[294.   1.]\n",
            " [  4. 283.]]\n",
            "######################Iteration 1000######################. \n",
            "                      Training Loss 0.040068665267223545. Training Accuracy 99.1408920288086. Training Precision 98.60627177700349. \n",
            "                      Training Recall 99.64788732394366. Training F1 99.12434325744309. Training class-wise F1 99.14058646851919.\n",
            "-----Starting epoch 18------\n",
            "-----Starting epoch 19------\n",
            "-----Starting epoch 20------\n",
            "-----Starting epoch 21------\n",
            "[[26. 11.]\n",
            " [ 8. 20.]]\n",
            "####################Iteration 1200.#############\n",
            "                       Validation Loss 1.48876108114536. Validation Accuracy 70.76923370361328. \n",
            "                       Validation Precision [67.74193548387096, 76.92307692307692, 75.0, 70.96774193548387, 65.71428571428571, 71.42857142857143]. Validation Recall [67.74193548387096, 64.51612903225806, 58.064516129032256, 70.96774193548387, 74.19354838709677, 64.51612903225806]. \n",
            "                       Validation F1 [67.74193548387096, 70.17543859649123, 65.45454545454545, 70.96774193548387, 69.69696969696969, 67.79661016949153]. Validation class-wise F1 70.51802339460491. \n",
            "                       Time passed -0.11538434028625488###############################\n",
            "[[298.   3.]\n",
            " [  0. 281.]]\n",
            "######################Iteration 1200######################. \n",
            "                      Training Loss 0.014270492084034322. Training Accuracy 99.48453521728516. Training Precision 100.0. \n",
            "                      Training Recall 98.94366197183099. Training F1 99.46902654867257. Training class-wise F1 99.48409591206584.\n",
            "-----Starting epoch 22------\n",
            "-----Starting epoch 23------\n",
            "-----Starting epoch 24------\n",
            "[[28. 10.]\n",
            " [ 6. 21.]]\n",
            "####################Iteration 1400.#############\n",
            "                       Validation Loss 1.3078219844744756. Validation Accuracy 75.38461303710938. \n",
            "                       Validation Precision [67.74193548387096, 76.92307692307692, 75.0, 70.96774193548387, 65.71428571428571, 71.42857142857143, 77.77777777777777]. Validation Recall [67.74193548387096, 64.51612903225806, 58.064516129032256, 70.96774193548387, 74.19354838709677, 64.51612903225806, 67.74193548387096]. \n",
            "                       Validation F1 [67.74193548387096, 70.17543859649123, 65.45454545454545, 70.96774193548387, 69.69696969696969, 67.79661016949153, 72.41379310344827]. Validation class-wise F1 75.09578544061303. \n",
            "                       Time passed -0.2461225986480713###############################\n",
            "[[297.   0.]\n",
            " [  1. 284.]]\n",
            "######################Iteration 1400######################. \n",
            "                      Training Loss 0.010362515762102065. Training Accuracy 99.82817840576172. Training Precision 99.64912280701755. \n",
            "                      Training Recall 100.0. Training F1 99.82425307557119. Training class-wise F1 99.82809292434021.\n",
            "-----Starting epoch 25------\n",
            "-----Starting epoch 26------\n",
            "-----Starting epoch 27------\n",
            "-----Starting epoch 28------\n",
            "[[27. 10.]\n",
            " [ 7. 21.]]\n",
            "####################Iteration 1600.#############\n",
            "                       Validation Loss 1.6597546614133394. Validation Accuracy 73.84615325927734. \n",
            "                       Validation Precision [67.74193548387096, 76.92307692307692, 75.0, 70.96774193548387, 65.71428571428571, 71.42857142857143, 77.77777777777777, 75.0]. Validation Recall [67.74193548387096, 64.51612903225806, 58.064516129032256, 70.96774193548387, 74.19354838709677, 64.51612903225806, 67.74193548387096, 67.74193548387096]. \n",
            "                       Validation F1 [67.74193548387096, 70.17543859649123, 65.45454545454545, 70.96774193548387, 69.69696969696969, 67.79661016949153, 72.41379310344827, 71.18644067796609]. Validation class-wise F1 73.62138935306754. \n",
            "                       Time passed -0.04053688049316406###############################\n",
            "[[297.   0.]\n",
            " [  1. 284.]]\n",
            "######################Iteration 1600######################. \n",
            "                      Training Loss 0.007595351400102158. Training Accuracy 99.82817840576172. Training Precision 99.64912280701755. \n",
            "                      Training Recall 100.0. Training F1 99.82425307557119. Training class-wise F1 99.82809292434021.\n",
            "-----Starting epoch 29------\n",
            "-----Starting epoch 30------\n",
            "Training done for fold 5\n",
            "val_f1:  [67.74193548387096, 70.17543859649123, 65.45454545454545, 70.96774193548387, 69.69696969696969, 67.79661016949153, 72.41379310344827, 71.18644067796609]\n",
            "-----Starting epoch 1------\n",
            "-----Starting epoch 2------\n",
            "-----Starting epoch 3------\n",
            "-----Starting epoch 4------\n",
            "[[25. 15.]\n",
            " [ 4. 21.]]\n",
            "####################Iteration 200.#############\n",
            "                       Validation Loss 0.6795913026883051. Validation Accuracy 70.76923370361328. \n",
            "                       Validation Precision [84.0]. Validation Recall [58.333333333333336]. \n",
            "                       Validation F1 [68.85245901639344]. Validation class-wise F1 70.65811356616774. \n",
            "                       Time passed -0.1273646354675293###############################\n",
            "[[289.  83.]\n",
            " [ 14. 196.]]\n",
            "######################Iteration 200######################. \n",
            "                      Training Loss 0.3826936288541535. Training Accuracy 83.33333587646484. Training Precision 93.33333333333333. \n",
            "                      Training Recall 70.25089605734767. Training F1 80.16359918200409. Training class-wise F1 82.89661440581686.\n",
            "-----Starting epoch 5------\n",
            "-----Starting epoch 6------\n",
            "-----Starting epoch 7------\n",
            "[[16.  8.]\n",
            " [13. 28.]]\n",
            "####################Iteration 400.#############\n",
            "                       Validation Loss 0.7796137172442216. Validation Accuracy 67.69230651855469. \n",
            "                       Validation Precision [84.0, 68.29268292682927]. Validation Recall [58.333333333333336, 77.77777777777777]. \n",
            "                       Validation F1 [68.85245901639344, 72.72727272727272]. Validation class-wise F1 66.55231560891937. \n",
            "                       Time passed -0.2750999927520752###############################\n",
            "[[283.  12.]\n",
            " [ 20. 267.]]\n",
            "######################Iteration 400######################. \n",
            "                      Training Loss 0.17769008464599187. Training Accuracy 94.50171661376953. Training Precision 93.03135888501743. \n",
            "                      Training Recall 95.6989247311828. Training F1 94.34628975265018. Training class-wise F1 94.49755959204415.\n",
            "-----Starting epoch 8------\n",
            "-----Starting epoch 9------\n",
            "-----Starting epoch 10------\n",
            "-----Starting epoch 11------\n",
            "[[23. 15.]\n",
            " [ 6. 21.]]\n",
            "####################Iteration 600.#############\n",
            "                       Validation Loss 1.1724087733488817. Validation Accuracy 67.69230651855469. \n",
            "                       Validation Precision [84.0, 68.29268292682927, 77.77777777777777]. Validation Recall [58.333333333333336, 77.77777777777777, 58.333333333333336]. \n",
            "                       Validation F1 [68.85245901639344, 72.72727272727272, 66.66666666666666]. Validation class-wise F1 67.66169154228855. \n",
            "                       Time passed -0.05549001693725586###############################\n",
            "[[303.   9.]\n",
            " [  0. 270.]]\n",
            "######################Iteration 600######################. \n",
            "                      Training Loss 0.05357845948410582. Training Accuracy 98.45361328125. Training Precision 100.0. \n",
            "                      Training Recall 96.7741935483871. Training F1 98.36065573770492. Training class-wise F1 98.44862055177929.\n",
            "-----Starting epoch 12------\n",
            "-----Starting epoch 13------\n",
            "-----Starting epoch 14------\n",
            "[[16.  8.]\n",
            " [13. 28.]]\n",
            "####################Iteration 800.#############\n",
            "                       Validation Loss 1.3716705097601964. Validation Accuracy 67.69230651855469. \n",
            "                       Validation Precision [84.0, 68.29268292682927, 77.77777777777777, 68.29268292682927]. Validation Recall [58.333333333333336, 77.77777777777777, 58.333333333333336, 77.77777777777777]. \n",
            "                       Validation F1 [68.85245901639344, 72.72727272727272, 66.66666666666666, 72.72727272727272]. Validation class-wise F1 66.55231560891937. \n",
            "                       Time passed -0.18376779556274414###############################\n",
            "[[291.   2.]\n",
            " [ 12. 277.]]\n",
            "######################Iteration 800######################. \n",
            "                      Training Loss 0.06255400663600191. Training Accuracy 97.5945053100586. Training Precision 95.8477508650519. \n",
            "                      Training Recall 99.2831541218638. Training F1 97.53521126760565. Training class-wise F1 97.59310898950753.\n",
            "-----Starting epoch 15------\n",
            "-----Starting epoch 16------\n",
            "-----Starting epoch 17------\n",
            "[[24. 19.]\n",
            " [ 5. 17.]]\n",
            "####################Iteration 1000.#############\n",
            "                       Validation Loss 2.129944223624009. Validation Accuracy 63.07692337036133. \n",
            "                       Validation Precision [84.0, 68.29268292682927, 77.77777777777777, 68.29268292682927, 77.27272727272727]. Validation Recall [58.333333333333336, 77.77777777777777, 58.333333333333336, 77.77777777777777, 47.22222222222222]. \n",
            "                       Validation F1 [68.85245901639344, 72.72727272727272, 66.66666666666666, 72.72727272727272, 58.62068965517242]. Validation class-wise F1 62.64367816091955. \n",
            "                       Time passed -0.330690860748291###############################\n",
            "[[303.  14.]\n",
            " [  0. 265.]]\n",
            "######################Iteration 1000######################. \n",
            "                      Training Loss 0.06008538206240332. Training Accuracy 97.5945053100586. Training Precision 100.0. \n",
            "                      Training Recall 94.9820788530466. Training F1 97.4264705882353. Training class-wise F1 97.58420303605314.\n",
            "-----Starting epoch 18------\n",
            "-----Starting epoch 19------\n",
            "-----Starting epoch 20------\n",
            "-----Starting epoch 21------\n",
            "[[25. 17.]\n",
            " [ 4. 19.]]\n",
            "####################Iteration 1200.#############\n",
            "                       Validation Loss 1.7668964771124034. Validation Accuracy 67.69230651855469. \n",
            "                       Validation Precision [84.0, 68.29268292682927, 77.77777777777777, 68.29268292682927, 77.27272727272727, 82.6086956521739]. Validation Recall [58.333333333333336, 77.77777777777777, 58.333333333333336, 77.77777777777777, 47.22222222222222, 52.77777777777778]. \n",
            "                       Validation F1 [68.85245901639344, 72.72727272727272, 66.66666666666666, 72.72727272727272, 58.62068965517242, 64.40677966101696]. Validation class-wise F1 67.41465743614228. \n",
            "                       Time passed -0.11309385299682617###############################\n",
            "[[303.  20.]\n",
            " [  0. 259.]]\n",
            "######################Iteration 1200######################. \n",
            "                      Training Loss 0.07171208132578451. Training Accuracy 96.5635757446289. Training Precision 100.0. \n",
            "                      Training Recall 92.831541218638. Training F1 96.28252788104089. Training class-wise F1 96.54381985106357.\n",
            "-----Starting epoch 22------\n",
            "-----Starting epoch 23------\n",
            "-----Starting epoch 24------\n",
            "[[16. 10.]\n",
            " [13. 26.]]\n",
            "####################Iteration 1400.#############\n",
            "                       Validation Loss 1.5107393322082667. Validation Accuracy 64.61538696289062. \n",
            "                       Validation Precision [84.0, 68.29268292682927, 77.77777777777777, 68.29268292682927, 77.27272727272727, 82.6086956521739, 66.66666666666667]. Validation Recall [58.333333333333336, 77.77777777777777, 58.333333333333336, 77.77777777777777, 47.22222222222222, 52.77777777777778, 72.22222222222223]. \n",
            "                       Validation F1 [68.85245901639344, 72.72727272727272, 66.66666666666666, 72.72727272727272, 58.62068965517242, 64.40677966101696, 69.33333333333333]. Validation class-wise F1 63.75757575757575. \n",
            "                       Time passed -0.24242520332336426###############################\n",
            "[[302.   0.]\n",
            " [  1. 279.]]\n",
            "######################Iteration 1400######################. \n",
            "                      Training Loss 0.010570099704668214. Training Accuracy 99.82817840576172. Training Precision 99.64285714285714. \n",
            "                      Training Recall 100.0. Training F1 99.8211091234347. Training class-wise F1 99.82790993361817.\n",
            "-----Starting epoch 25------\n",
            "-----Starting epoch 26------\n",
            "-----Starting epoch 27------\n",
            "-----Starting epoch 28------\n",
            "[[24. 15.]\n",
            " [ 5. 21.]]\n",
            "####################Iteration 1600.#############\n",
            "                       Validation Loss 1.7392199245783. Validation Accuracy 69.23076629638672. \n",
            "                       Validation Precision [84.0, 68.29268292682927, 77.77777777777777, 68.29268292682927, 77.27272727272727, 82.6086956521739, 66.66666666666667, 80.76923076923077]. Validation Recall [58.333333333333336, 77.77777777777777, 58.333333333333336, 77.77777777777777, 47.22222222222222, 52.77777777777778, 72.22222222222223, 58.333333333333336]. \n",
            "                       Validation F1 [68.85245901639344, 72.72727272727272, 66.66666666666666, 72.72727272727272, 58.62068965517242, 64.40677966101696, 69.33333333333333, 67.74193548387096]. Validation class-wise F1 69.1650853889943. \n",
            "                       Time passed -0.04463481903076172###############################\n",
            "[[302.   1.]\n",
            " [  1. 278.]]\n",
            "######################Iteration 1600######################. \n",
            "                      Training Loss 0.006523258687224826. Training Accuracy 99.65635681152344. Training Precision 99.6415770609319. \n",
            "                      Training Recall 99.6415770609319. Training F1 99.64157706093188. Training class-wise F1 99.65577202881578.\n",
            "-----Starting epoch 29------\n",
            "-----Starting epoch 30------\n",
            "Training done for fold 6\n",
            "val_f1:  [68.85245901639344, 72.72727272727272, 66.66666666666666, 72.72727272727272, 58.62068965517242, 64.40677966101696, 69.33333333333333, 67.74193548387096]\n",
            "-----Starting epoch 1------\n",
            "-----Starting epoch 2------\n",
            "-----Starting epoch 3------\n",
            "-----Starting epoch 4------\n",
            "[[25.  7.]\n",
            " [ 9. 24.]]\n",
            "####################Iteration 200.#############\n",
            "                       Validation Loss 0.5185405566142156. Validation Accuracy 75.38461303710938. \n",
            "                       Validation Precision [72.72727272727273]. Validation Recall [77.41935483870968]. \n",
            "                       Validation F1 [75.0]. Validation class-wise F1 75.37878787878788. \n",
            "                       Time passed -0.12783432006835938###############################\n",
            "[[253.  40.]\n",
            " [ 45. 244.]]\n",
            "######################Iteration 200######################. \n",
            "                      Training Loss 0.357290968503739. Training Accuracy 85.39518737792969. Training Precision 84.42906574394463. \n",
            "                      Training Recall 85.91549295774648. Training F1 85.16579406631762. Training class-wise F1 85.39169567952091.\n",
            "-----Starting epoch 5------\n",
            "-----Starting epoch 6------\n",
            "-----Starting epoch 7------\n",
            "[[28. 13.]\n",
            " [ 6. 18.]]\n",
            "####################Iteration 400.#############\n",
            "                       Validation Loss 0.6088407589839056. Validation Accuracy 70.76923370361328. \n",
            "                       Validation Precision [72.72727272727273, 75.0]. Validation Recall [77.41935483870968, 58.064516129032256]. \n",
            "                       Validation F1 [75.0, 65.45454545454545]. Validation class-wise F1 70.06060606060606. \n",
            "                       Time passed -0.26500773429870605###############################\n",
            "[[293.  47.]\n",
            " [  5. 237.]]\n",
            "######################Iteration 400######################. \n",
            "                      Training Loss 0.22352946515089459. Training Accuracy 91.06529235839844. Training Precision 97.93388429752066. \n",
            "                      Training Recall 83.45070422535211. Training F1 90.11406844106465. Training class-wise F1 90.98179911081445.\n",
            "-----Starting epoch 8------\n",
            "-----Starting epoch 9------\n",
            "-----Starting epoch 10------\n",
            "-----Starting epoch 11------\n",
            "[[27. 12.]\n",
            " [ 7. 19.]]\n",
            "####################Iteration 600.#############\n",
            "                       Validation Loss 0.7311690999911382. Validation Accuracy 70.76923370361328. \n",
            "                       Validation Precision [72.72727272727273, 75.0, 73.07692307692308]. Validation Recall [77.41935483870968, 58.064516129032256, 61.29032258064516]. \n",
            "                       Validation F1 [75.0, 65.45454545454545, 66.66666666666666]. Validation class-wise F1 70.31963470319634. \n",
            "                       Time passed -0.06291055679321289###############################\n",
            "[[295.  13.]\n",
            " [  3. 271.]]\n",
            "######################Iteration 600######################. \n",
            "                      Training Loss 0.1043821610318324. Training Accuracy 97.25086212158203. Training Precision 98.9051094890511. \n",
            "                      Training Recall 95.4225352112676. Training F1 97.1326164874552. Training class-wise F1 97.24617623052627.\n",
            "-----Starting epoch 12------\n",
            "-----Starting epoch 13------\n",
            "-----Starting epoch 14------\n",
            "[[26. 12.]\n",
            " [ 8. 19.]]\n",
            "####################Iteration 800.#############\n",
            "                       Validation Loss 1.0883001043246343. Validation Accuracy 69.23076629638672. \n",
            "                       Validation Precision [72.72727272727273, 75.0, 73.07692307692308, 70.37037037037037]. Validation Recall [77.41935483870968, 58.064516129032256, 61.29032258064516, 61.29032258064516]. \n",
            "                       Validation F1 [75.0, 65.45454545454545, 66.66666666666666, 65.51724137931035]. Validation class-wise F1 68.86973180076629. \n",
            "                       Time passed -0.18506622314453125###############################\n",
            "[[298.   5.]\n",
            " [  0. 279.]]\n",
            "######################Iteration 800######################. \n",
            "                      Training Loss 0.026292285325263284. Training Accuracy 99.1408920288086. Training Precision 100.0. \n",
            "                      Training Recall 98.2394366197183. Training F1 99.11190053285968. Training class-wise F1 99.13997688872601.\n",
            "-----Starting epoch 15------\n",
            "-----Starting epoch 16------\n",
            "-----Starting epoch 17------\n",
            "[[22.  6.]\n",
            " [12. 25.]]\n",
            "####################Iteration 1000.#############\n",
            "                       Validation Loss 1.0872866158875136. Validation Accuracy 72.30769348144531. \n",
            "                       Validation Precision [72.72727272727273, 75.0, 73.07692307692308, 70.37037037037037, 67.56756756756756]. Validation Recall [77.41935483870968, 58.064516129032256, 61.29032258064516, 61.29032258064516, 80.64516129032258]. \n",
            "                       Validation F1 [75.0, 65.45454545454545, 66.66666666666666, 65.51724137931035, 73.52941176470588]. Validation class-wise F1 72.24857685009488. \n",
            "                       Time passed -0.3220820426940918###############################\n",
            "[[290.   2.]\n",
            " [  8. 282.]]\n",
            "######################Iteration 1000######################. \n",
            "                      Training Loss 0.04684526750075197. Training Accuracy 98.28179168701172. Training Precision 97.24137931034483. \n",
            "                      Training Recall 99.29577464788733. Training F1 98.25783972125436. Training class-wise F1 98.28146223350853.\n",
            "-----Starting epoch 18------\n",
            "-----Starting epoch 19------\n",
            "-----Starting epoch 20------\n",
            "-----Starting epoch 21------\n",
            "[[25.  8.]\n",
            " [ 9. 23.]]\n",
            "####################Iteration 1200.#############\n",
            "                       Validation Loss 1.139813743531704. Validation Accuracy 73.84615325927734. \n",
            "                       Validation Precision [72.72727272727273, 75.0, 73.07692307692308, 70.37037037037037, 67.56756756756756, 71.875]. Validation Recall [77.41935483870968, 58.064516129032256, 61.29032258064516, 61.29032258064516, 80.64516129032258, 74.19354838709677]. \n",
            "                       Validation F1 [75.0, 65.45454545454545, 66.66666666666666, 65.51724137931035, 73.52941176470588, 73.01587301587301]. Validation class-wise F1 73.8213693437574. \n",
            "                       Time passed -0.11483335494995117###############################\n",
            "[[297.   3.]\n",
            " [  1. 281.]]\n",
            "######################Iteration 1200######################. \n",
            "                      Training Loss 0.019880179362611595. Training Accuracy 99.31271362304688. Training Precision 99.64539007092199. \n",
            "                      Training Recall 98.94366197183099. Training F1 99.29328621908127. Training class-wise F1 99.31219494900552.\n",
            "-----Starting epoch 22------\n",
            "-----Starting epoch 23------\n",
            "-----Starting epoch 24------\n",
            "[[24.  9.]\n",
            " [10. 22.]]\n",
            "####################Iteration 1400.#############\n",
            "                       Validation Loss 1.4423190630399263. Validation Accuracy 70.76923370361328. \n",
            "                       Validation Precision [72.72727272727273, 75.0, 73.07692307692308, 70.37037037037037, 67.56756756756756, 71.875, 68.75]. Validation Recall [77.41935483870968, 58.064516129032256, 61.29032258064516, 61.29032258064516, 80.64516129032258, 74.19354838709677, 70.96774193548387]. \n",
            "                       Validation F1 [75.0, 65.45454545454545, 66.66666666666666, 65.51724137931035, 73.52941176470588, 73.01587301587301, 69.84126984126983]. Validation class-wise F1 70.74153044302298. \n",
            "                       Time passed -0.24886107444763184###############################\n",
            "[[298.   4.]\n",
            " [  0. 280.]]\n",
            "######################Iteration 1400######################. \n",
            "                      Training Loss 0.01938268122371967. Training Accuracy 99.31271362304688. Training Precision 100.0. \n",
            "                      Training Recall 98.59154929577464. Training F1 99.29078014184395. Training class-wise F1 99.31205673758865.\n",
            "-----Starting epoch 25------\n",
            "-----Starting epoch 26------\n",
            "-----Starting epoch 27------\n",
            "-----Starting epoch 28------\n",
            "[[25.  8.]\n",
            " [ 9. 23.]]\n",
            "####################Iteration 1600.#############\n",
            "                       Validation Loss 1.2714391579994788. Validation Accuracy 73.84615325927734. \n",
            "                       Validation Precision [72.72727272727273, 75.0, 73.07692307692308, 70.37037037037037, 67.56756756756756, 71.875, 68.75, 71.875]. Validation Recall [77.41935483870968, 58.064516129032256, 61.29032258064516, 61.29032258064516, 80.64516129032258, 74.19354838709677, 70.96774193548387, 74.19354838709677]. \n",
            "                       Validation F1 [75.0, 65.45454545454545, 66.66666666666666, 65.51724137931035, 73.52941176470588, 73.01587301587301, 69.84126984126983, 73.01587301587301]. Validation class-wise F1 73.8213693437574. \n",
            "                       Time passed -0.04027843475341797###############################\n",
            "[[296.   1.]\n",
            " [  2. 283.]]\n",
            "######################Iteration 1600######################. \n",
            "                      Training Loss 0.012659908176788418. Training Accuracy 99.48453521728516. Training Precision 99.29824561403508. \n",
            "                      Training Recall 99.64788732394366. Training F1 99.47275922671352. Training class-wise F1 99.48427877302063.\n",
            "-----Starting epoch 29------\n",
            "-----Starting epoch 30------\n",
            "Training done for fold 7\n",
            "val_f1:  [75.0, 65.45454545454545, 66.66666666666666, 65.51724137931035, 73.52941176470588, 73.01587301587301, 69.84126984126983, 73.01587301587301]\n",
            "-----Starting epoch 1------\n",
            "-----Starting epoch 2------\n",
            "-----Starting epoch 3------\n",
            "-----Starting epoch 4------\n",
            "[[27.  9.]\n",
            " [ 6. 23.]]\n",
            "####################Iteration 200.#############\n",
            "                       Validation Loss 0.5156527482546293. Validation Accuracy 76.92308044433594. \n",
            "                       Validation Precision [79.3103448275862]. Validation Recall [71.875]. \n",
            "                       Validation F1 [75.40983606557376]. Validation class-wise F1 76.83535281539557. \n",
            "                       Time passed -0.1293013095855713###############################\n",
            "[[267.  56.]\n",
            " [ 32. 227.]]\n",
            "######################Iteration 200######################. \n",
            "                      Training Loss 0.36282791478937026. Training Accuracy 84.87972259521484. Training Precision 87.64478764478764. \n",
            "                      Training Recall 80.21201413427562. Training F1 83.76383763837639. Training class-wise F1 84.80796383526535.\n",
            "-----Starting epoch 5------\n",
            "-----Starting epoch 6------\n",
            "-----Starting epoch 7------\n",
            "[[17.  5.]\n",
            " [16. 27.]]\n",
            "####################Iteration 400.#############\n",
            "                       Validation Loss 0.7915800259663508. Validation Accuracy 67.69230651855469. \n",
            "                       Validation Precision [79.3103448275862, 62.7906976744186]. Validation Recall [71.875, 84.375]. \n",
            "                       Validation F1 [75.40983606557376, 72.0]. Validation class-wise F1 66.9090909090909. \n",
            "                       Time passed -0.26767826080322266###############################\n",
            "[[255.   7.]\n",
            " [ 44. 276.]]\n",
            "######################Iteration 400######################. \n",
            "                      Training Loss 0.21428962218930425. Training Accuracy 91.23711395263672. Training Precision 86.25. \n",
            "                      Training Recall 97.52650176678445. Training F1 91.54228855721392. Training class-wise F1 91.22568973315241.\n",
            "-----Starting epoch 8------\n",
            "-----Starting epoch 9------\n",
            "-----Starting epoch 10------\n",
            "-----Starting epoch 11------\n",
            "[[25.  6.]\n",
            " [ 8. 26.]]\n",
            "####################Iteration 600.#############\n",
            "                       Validation Loss 0.7200585191066449. Validation Accuracy 78.46154022216797. \n",
            "                       Validation Precision [79.3103448275862, 62.7906976744186, 76.47058823529412]. Validation Recall [71.875, 84.375, 81.25]. \n",
            "                       Validation F1 [75.40983606557376, 72.0, 78.78787878787878]. Validation class-wise F1 78.45643939393939. \n",
            "                       Time passed -0.055711984634399414###############################\n",
            "[[267.   4.]\n",
            " [ 32. 279.]]\n",
            "######################Iteration 600######################. \n",
            "                      Training Loss 0.1471536643570089. Training Accuracy 93.81443786621094. Training Precision 89.71061093247589. \n",
            "                      Training Recall 98.58657243816255. Training F1 93.93939393939395. Training class-wise F1 93.81180223285486.\n",
            "-----Starting epoch 12------\n",
            "-----Starting epoch 13------\n",
            "-----Starting epoch 14------\n",
            "[[24.  5.]\n",
            " [ 9. 27.]]\n",
            "####################Iteration 800.#############\n",
            "                       Validation Loss 0.9115430819443785. Validation Accuracy 78.46154022216797. \n",
            "                       Validation Precision [79.3103448275862, 62.7906976744186, 76.47058823529412, 75.0]. Validation Recall [71.875, 84.375, 81.25, 84.375]. \n",
            "                       Validation F1 [75.40983606557376, 72.0, 78.78787878787878, 79.41176470588235]. Validation class-wise F1 78.415559772296. \n",
            "                       Time passed -0.18108320236206055###############################\n",
            "[[294.   3.]\n",
            " [  5. 280.]]\n",
            "######################Iteration 800######################. \n",
            "                      Training Loss 0.040551107364012205. Training Accuracy 98.62542724609375. Training Precision 98.24561403508773. \n",
            "                      Training Recall 98.93992932862191. Training F1 98.59154929577464. Training class-wise F1 98.62463370829.\n",
            "-----Starting epoch 15------\n",
            "-----Starting epoch 16------\n",
            "-----Starting epoch 17------\n",
            "[[14.  6.]\n",
            " [19. 26.]]\n",
            "####################Iteration 1000.#############\n",
            "                       Validation Loss 1.2582813868155847. Validation Accuracy 61.53845977783203. \n",
            "                       Validation Precision [79.3103448275862, 62.7906976744186, 76.47058823529412, 75.0, 57.77777777777778]. Validation Recall [71.875, 84.375, 81.25, 84.375, 81.25]. \n",
            "                       Validation F1 [75.40983606557376, 72.0, 78.78787878787878, 79.41176470588235, 67.53246753246754]. Validation class-wise F1 60.18132810585641. \n",
            "                       Time passed -0.31147265434265137###############################\n",
            "[[274.   2.]\n",
            " [ 25. 281.]]\n",
            "######################Iteration 1000######################. \n",
            "                      Training Loss 0.11330371110438436. Training Accuracy 95.36082458496094. Training Precision 91.83006535947712. \n",
            "                      Training Recall 99.29328621908127. Training F1 95.41595925297113. Training class-wise F1 95.36015353952905.\n",
            "-----Starting epoch 18------\n",
            "-----Starting epoch 19------\n",
            "-----Starting epoch 20------\n",
            "-----Starting epoch 21------\n",
            "[[28.  9.]\n",
            " [ 5. 23.]]\n",
            "####################Iteration 1200.#############\n",
            "                       Validation Loss 1.335055179320849. Validation Accuracy 78.46154022216797. \n",
            "                       Validation Precision [79.3103448275862, 62.7906976744186, 76.47058823529412, 75.0, 57.77777777777778, 82.14285714285714]. Validation Recall [71.875, 84.375, 81.25, 84.375, 81.25, 71.875]. \n",
            "                       Validation F1 [75.40983606557376, 72.0, 78.78787878787878, 79.41176470588235, 67.53246753246754, 76.66666666666667]. Validation class-wise F1 78.33333333333334. \n",
            "                       Time passed -0.11160755157470703###############################\n",
            "[[299.   3.]\n",
            " [  0. 280.]]\n",
            "######################Iteration 1200######################. \n",
            "                      Training Loss 0.02672896808156789. Training Accuracy 99.48453521728516. Training Precision 100.0. \n",
            "                      Training Recall 98.93992932862191. Training F1 99.4671403197158. Training class-wise F1 99.4839861332356.\n",
            "-----Starting epoch 22------\n",
            "-----Starting epoch 23------\n",
            "-----Starting epoch 24------\n",
            "[[28.  9.]\n",
            " [ 5. 23.]]\n",
            "####################Iteration 1400.#############\n",
            "                       Validation Loss 1.4175168940654168. Validation Accuracy 78.46154022216797. \n",
            "                       Validation Precision [79.3103448275862, 62.7906976744186, 76.47058823529412, 75.0, 57.77777777777778, 82.14285714285714, 82.14285714285714]. Validation Recall [71.875, 84.375, 81.25, 84.375, 81.25, 71.875, 71.875]. \n",
            "                       Validation F1 [75.40983606557376, 72.0, 78.78787878787878, 79.41176470588235, 67.53246753246754, 76.66666666666667, 76.66666666666667]. Validation class-wise F1 78.33333333333334. \n",
            "                       Time passed -0.24854707717895508###############################\n",
            "[[298.   2.]\n",
            " [  1. 281.]]\n",
            "######################Iteration 1400######################. \n",
            "                      Training Loss 0.009384753895986803. Training Accuracy 99.48453521728516. Training Precision 99.64539007092199. \n",
            "                      Training Recall 99.29328621908127. Training F1 99.46902654867257. Training class-wise F1 99.48409591206584.\n",
            "-----Starting epoch 25------\n",
            "-----Starting epoch 26------\n",
            "-----Starting epoch 27------\n",
            "-----Starting epoch 28------\n",
            "[[25.  9.]\n",
            " [ 8. 23.]]\n",
            "####################Iteration 1600.#############\n",
            "                       Validation Loss 1.3322257995605469. Validation Accuracy 73.84615325927734. \n",
            "                       Validation Precision [79.3103448275862, 62.7906976744186, 76.47058823529412, 75.0, 57.77777777777778, 82.14285714285714, 82.14285714285714, 74.19354838709677]. Validation Recall [71.875, 84.375, 81.25, 84.375, 81.25, 71.875, 71.875, 71.875]. \n",
            "                       Validation F1 [75.40983606557376, 72.0, 78.78787878787878, 79.41176470588235, 67.53246753246754, 76.66666666666667, 76.66666666666667, 73.01587301587301]. Validation class-wise F1 73.8213693437574. \n",
            "                       Time passed -0.039904117584228516###############################\n",
            "[[299.   1.]\n",
            " [  0. 282.]]\n",
            "######################Iteration 1600######################. \n",
            "                      Training Loss 0.005029600727304812. Training Accuracy 99.82817840576172. Training Precision 100.0. \n",
            "                      Training Recall 99.64664310954063. Training F1 99.82300884955752. Training class-wise F1 99.82803197068861.\n",
            "-----Starting epoch 29------\n",
            "-----Starting epoch 30------\n",
            "Training done for fold 8\n",
            "val_f1:  [75.40983606557376, 72.0, 78.78787878787878, 79.41176470588235, 67.53246753246754, 76.66666666666667, 76.66666666666667, 73.01587301587301]\n",
            "-----Starting epoch 1------\n",
            "-----Starting epoch 2------\n",
            "-----Starting epoch 3------\n",
            "-----Starting epoch 4------\n",
            "[[19.  2.]\n",
            " [18. 23.]]\n",
            "####################Iteration 200.#############\n",
            "                       Validation Loss 0.6911347647828441. Validation Accuracy 67.74193572998047. \n",
            "                       Validation Precision [56.09756097560975]. Validation Recall [92.0]. \n",
            "                       Validation F1 [69.6969696969697]. Validation class-wise F1 67.60710553814002. \n",
            "                       Time passed -0.13325738906860352###############################\n",
            "[[192.  24.]\n",
            " [103. 266.]]\n",
            "######################Iteration 200######################. \n",
            "                      Training Loss 0.4385594305319664. Training Accuracy 78.29059600830078. Training Precision 72.08672086720867. \n",
            "                      Training Recall 91.72413793103448. Training F1 80.72837632776934. Training class-wise F1 77.93757368247566.\n",
            "-----Starting epoch 5------\n",
            "-----Starting epoch 6------\n",
            "-----Starting epoch 7------\n",
            "[[ 7.  1.]\n",
            " [30. 24.]]\n",
            "####################Iteration 400.#############\n",
            "                       Validation Loss 1.4655599767161953. Validation Accuracy 50.0. \n",
            "                       Validation Precision [56.09756097560975, 44.44444444444444]. Validation Recall [92.0, 96.0]. \n",
            "                       Validation F1 [69.6969696969697, 60.75949367088606]. Validation class-wise F1 45.93530239099859. \n",
            "                       Time passed -0.2703683376312256###############################\n",
            "[[136.   2.]\n",
            " [159. 288.]]\n",
            "######################Iteration 400######################. \n",
            "                      Training Loss 0.5488965139429793. Training Accuracy 72.47863006591797. Training Precision 64.42953020134229. \n",
            "                      Training Recall 99.3103448275862. Training F1 78.15468113975577. Training class-wise F1 70.48611655140213.\n",
            "-----Starting epoch 8------\n",
            "-----Starting epoch 9------\n",
            "-----Starting epoch 10------\n",
            "-----Starting epoch 11------\n",
            "[[24.  6.]\n",
            " [13. 19.]]\n",
            "####################Iteration 600.#############\n",
            "                       Validation Loss 0.7441739728373866. Validation Accuracy 69.3548355102539. \n",
            "                       Validation Precision [56.09756097560975, 44.44444444444444, 59.375]. Validation Recall [92.0, 96.0, 76.0]. \n",
            "                       Validation F1 [69.6969696969697, 60.75949367088606, 66.66666666666667]. Validation class-wise F1 69.1542288557214. \n",
            "                       Time passed -0.05539536476135254###############################\n",
            "[[293.   7.]\n",
            " [  2. 283.]]\n",
            "######################Iteration 600######################. \n",
            "                      Training Loss 0.08135104168238294. Training Accuracy 98.46154022216797. Training Precision 99.29824561403508. \n",
            "                      Training Recall 97.58620689655173. Training F1 98.43478260869566. Training class-wise F1 98.46108878333942.\n",
            "-----Starting epoch 12------\n",
            "-----Starting epoch 13------\n",
            "-----Starting epoch 14------\n",
            "[[27.  6.]\n",
            " [10. 19.]]\n",
            "####################Iteration 800.#############\n",
            "                       Validation Loss 0.9688362079567366. Validation Accuracy 74.19354248046875. \n",
            "                       Validation Precision [56.09756097560975, 44.44444444444444, 59.375, 65.51724137931035]. Validation Recall [92.0, 96.0, 76.0, 76.0]. \n",
            "                       Validation F1 [69.6969696969697, 60.75949367088606, 66.66666666666667, 70.37037037037038]. Validation class-wise F1 73.75661375661376. \n",
            "                       Time passed -0.18389248847961426###############################\n",
            "[[295.   2.]\n",
            " [  0. 288.]]\n",
            "######################Iteration 800######################. \n",
            "                      Training Loss 0.014223512825775. Training Accuracy 99.65811920166016. Training Precision 100.0. \n",
            "                      Training Recall 99.3103448275862. Training F1 99.65397923875433. Training class-wise F1 99.65807070045824.\n",
            "-----Starting epoch 15------\n",
            "-----Starting epoch 16------\n",
            "-----Starting epoch 17------\n",
            "[[21.  5.]\n",
            " [16. 20.]]\n",
            "####################Iteration 1000.#############\n",
            "                       Validation Loss 1.8113258596389525. Validation Accuracy 66.1290283203125. \n",
            "                       Validation Precision [56.09756097560975, 44.44444444444444, 59.375, 65.51724137931035, 55.55555555555556]. Validation Recall [92.0, 96.0, 76.0, 76.0, 80.0]. \n",
            "                       Validation F1 [69.6969696969697, 60.75949367088606, 66.66666666666667, 70.37037037037038, 65.57377049180329]. Validation class-wise F1 66.12021857923497. \n",
            "                       Time passed -0.32372498512268066###############################\n",
            "[[295.   0.]\n",
            " [  0. 290.]]\n",
            "######################Iteration 1000######################. \n",
            "                      Training Loss 0.003467288232059218. Training Accuracy 100.0. Training Precision 100.0. \n",
            "                      Training Recall 100.0. Training F1 100.0. Training class-wise F1 100.0.\n",
            "-----Starting epoch 18------\n",
            "-----Starting epoch 19------\n",
            "-----Starting epoch 20------\n",
            "-----Starting epoch 21------\n",
            "[[12.  3.]\n",
            " [25. 22.]]\n",
            "####################Iteration 1200.#############\n",
            "                       Validation Loss 1.653508109431113. Validation Accuracy 54.838706970214844. \n",
            "                       Validation Precision [56.09756097560975, 44.44444444444444, 59.375, 65.51724137931035, 55.55555555555556, 46.808510638297875]. Validation Recall [92.0, 96.0, 76.0, 76.0, 80.0, 88.0]. \n",
            "                       Validation F1 [69.6969696969697, 60.75949367088606, 66.66666666666667, 70.37037037037038, 65.57377049180329, 61.111111111111114]. Validation class-wise F1 53.63247863247864. \n",
            "                       Time passed -0.11402320861816406###############################\n",
            "[[263.   0.]\n",
            " [ 32. 290.]]\n",
            "######################Iteration 1200######################. \n",
            "                      Training Loss 0.12703831079933378. Training Accuracy 94.52991485595703. Training Precision 90.06211180124224. \n",
            "                      Training Recall 100.0. Training F1 94.77124183006538. Training class-wise F1 94.5182374024879.\n",
            "-----Starting epoch 22------\n",
            "-----Starting epoch 23------\n",
            "-----Starting epoch 24------\n",
            "[[27.  9.]\n",
            " [10. 16.]]\n",
            "####################Iteration 1400.#############\n",
            "                       Validation Loss 1.3327619923699288. Validation Accuracy 69.3548355102539. \n",
            "                       Validation Precision [56.09756097560975, 44.44444444444444, 59.375, 65.51724137931035, 55.55555555555556, 46.808510638297875, 61.53846153846154]. Validation Recall [92.0, 96.0, 76.0, 76.0, 80.0, 88.0, 64.0]. \n",
            "                       Validation F1 [69.6969696969697, 60.75949367088606, 66.66666666666667, 70.37037037037038, 65.57377049180329, 61.111111111111114, 62.745098039215684]. Validation class-wise F1 68.35885038947086. \n",
            "                       Time passed -0.24573659896850586###############################\n",
            "[[295.   1.]\n",
            " [  0. 289.]]\n",
            "######################Iteration 1400######################. \n",
            "                      Training Loss 0.004858512745928378. Training Accuracy 99.82906341552734. Training Precision 100.0. \n",
            "                      Training Recall 99.65517241379311. Training F1 99.8272884283247. Training class-wise F1 99.82904184529602.\n",
            "-----Starting epoch 25------\n",
            "-----Starting epoch 26------\n",
            "-----Starting epoch 27------\n",
            "-----Starting epoch 28------\n",
            "[[24.  4.]\n",
            " [13. 21.]]\n",
            "####################Iteration 1600.#############\n",
            "                       Validation Loss 1.3242536242750864. Validation Accuracy 72.58064270019531. \n",
            "                       Validation Precision [56.09756097560975, 44.44444444444444, 59.375, 65.51724137931035, 55.55555555555556, 46.808510638297875, 61.53846153846154, 61.76470588235294]. Validation Recall [92.0, 96.0, 76.0, 76.0, 80.0, 88.0, 64.0, 84.0]. \n",
            "                       Validation F1 [69.6969696969697, 60.75949367088606, 66.66666666666667, 70.37037037037038, 65.57377049180329, 61.111111111111114, 62.745098039215684, 71.1864406779661]. Validation class-wise F1 72.51629726205998. \n",
            "                       Time passed -0.04122471809387207###############################\n",
            "[[295.   0.]\n",
            " [  0. 290.]]\n",
            "######################Iteration 1600######################. \n",
            "                      Training Loss 0.0018277970532206101. Training Accuracy 100.0. Training Precision 100.0. \n",
            "                      Training Recall 100.0. Training F1 100.0. Training class-wise F1 100.0.\n",
            "-----Starting epoch 29------\n",
            "-----Starting epoch 30------\n",
            "Training done for fold 9\n",
            "val_f1:  [69.6969696969697, 60.75949367088606, 66.66666666666667, 70.37037037037038, 65.57377049180329, 61.111111111111114, 62.745098039215684, 71.1864406779661]\n",
            "F1 on MOH-X by 10-fold =  [72.22222222222223, 72.22222222222223, 75.00000000000001, 75.00000000000001, 77.61194029850748, 77.61194029850748, 78.125, 78.125, 84.21052631578947, 84.21052631578947, 72.41379310344827, 72.41379310344827, 72.72727272727272, 72.72727272727272, 75.0, 75.0, 79.41176470588235, 79.41176470588235, 71.1864406779661, 71.1864406779661]\n",
            "F1 on MOH-X =  75.79089600510888\n",
            "precisions on MOH-X =  74.12076006045552\n",
            "recalls on MOH-X =  78.2918499841707\n",
            "accuracies on MOH-X =  75.56575622558594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gao_results = [75.3, 84.3, 79.1, 78.5]\n",
        "our_results = [round(np.mean(np.array(precisions)), 2),\n",
        "               round(np.mean(np.array(recalls)), 2),\n",
        "               round(np.mean(np.array(optimal_f1s)), 2),\n",
        "               round(np.mean(np.array(accuracies)), 2)]"
      ],
      "metadata": {
        "id": "lRS1H1-tAyRh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame([gao_results, our_results], \n",
        "                       columns = ['P', \"R\", \"F1\", \"Acc\"],\n",
        "                       index = [\"GAO\", \"US\"])"
      ],
      "metadata": {
        "id": "lak7BE0dB1tz"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "PbngdCnnB2XM",
        "outputId": "ae4ded2a-100f-4846-dc17-f1f48b900af1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5cfab950-bcfc-4341-9da0-f3dfa04fad8c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>P</th>\n",
              "      <th>R</th>\n",
              "      <th>F1</th>\n",
              "      <th>Acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>GAO</th>\n",
              "      <td>75.30</td>\n",
              "      <td>84.30</td>\n",
              "      <td>79.10</td>\n",
              "      <td>78.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>US</th>\n",
              "      <td>74.12</td>\n",
              "      <td>78.29</td>\n",
              "      <td>75.79</td>\n",
              "      <td>75.57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cfab950-bcfc-4341-9da0-f3dfa04fad8c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5cfab950-bcfc-4341-9da0-f3dfa04fad8c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5cfab950-bcfc-4341-9da0-f3dfa04fad8c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         P      R     F1    Acc\n",
              "GAO  75.30  84.30  79.10  78.50\n",
              "US   74.12  78.29  75.79  75.57"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bVMvNJkkCIg8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}